{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "e3e7a6bf",
      "metadata": {
        "id": "e3e7a6bf"
      },
      "source": [
        "# Agentic Framework ‚Äî Fully Automatic Google Colab Deployment\n",
        "\n",
        "**One-click deployment**: Just click **Runtime ‚Üí Run all** (or `Ctrl+F9`) and everything will start automatically.\n",
        "\n",
        "### What this does\n",
        "1. Verifies GPU (H100/A100) and system resources\n",
        "2. Installs system dependencies (PostgreSQL, Redis, Node.js 22, MinIO)\n",
        "3. Installs Ollama + pulls DeepSeek R1 14B (GPU-accelerated)\n",
        "4. Clones the repo and installs Python packages\n",
        "5. Starts all infrastructure (PostgreSQL, Redis, ChromaDB, MinIO)\n",
        "6. Starts all 5 microservices + dashboard\n",
        "7. Creates ngrok tunnels for external access\n",
        "8. Runs health checks\n",
        "9. Keeps the session alive so Colab doesn't disconnect\n",
        "\n",
        "### Prerequisites\n",
        "- Google Colab **Pro** account (for GPU access)\n",
        "- Runtime set to **GPU** (Runtime ‚Üí Change runtime type ‚Üí T4/A100/H100)\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "4c70cab1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4c70cab1",
        "outputId": "1c374c1a-5361-48b4-f7de-4c6bbd2e1fcc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Configuration loaded.\n"
          ]
        }
      ],
      "source": [
        "# ‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n",
        "# ‚ïë  CONFIGURATION                                               ‚ïë\n",
        "# ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n",
        "\n",
        "# GitHub repo\n",
        "REPO_URL = \"https://github.com/landonking-gif/ai_final.git\"\n",
        "\n",
        "# Ngrok Token (Get one free at https://dashboard.ngrok.com/signup)\n",
        "# Required for public URLs\n",
        "NGROK_AUTH_TOKEN = \"39MaIP07IiJMHPNDgd3raMEOL6r_2KyacFVXP68bbxBu9s8E8\"\n",
        "\n",
        "# Models (Pulled via Ollama)\n",
        "PRIMARY_MODEL = \"deepseek-r1:14b\"\n",
        "FALLBACK_MODEL = \"llama3.2:3b\"\n",
        "\n",
        "# Feature Flags\n",
        "START_DASHBOARD = True\n",
        "ENABLE_NGROK = True\n",
        "\n",
        "print(\"‚úÖ Configuration loaded.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "66186129",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "66186129",
        "outputId": "c1988b7f-6e3e-451e-b7c0-86067f34f54a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "PHASE 1: SYSTEM CHECK & DEPENDENCY INSTALL\n",
            "============================================================\n",
            "  [GPU] Tesla T4, 15360 MiB, 550.54.15\n",
            "  [RAM] 12.7 GB\n",
            "  [Disk] 178.6 GB free\n",
            "  [Python] 3.12.12\n",
            "\n",
            "  Installing system packages...\n",
            "  [apt update] OK\n",
            "  [PostgreSQL + Redis + build tools + zstd] OK\n",
            "  [Node.js 22 repo] OK\n",
            "  [Node.js 22] OK\n",
            "  [MinIO] OK\n",
            "  [Node.js] v22.22.0\n",
            "\n",
            "  Phase 1 complete.\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# ‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n",
        "# ‚ïë  PHASE 1: System Check & Dependencies                      ‚ïë\n",
        "# ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n",
        "import subprocess, os, sys, shutil, time\n",
        "\n",
        "def run_cmd(cmd, desc=\"\", check=False):\n",
        "    \"\"\"Run a shell command with status output.\"\"\"\n",
        "    if desc:\n",
        "        print(f\"  [{desc}]\", end=\" \", flush=True)\n",
        "    result = subprocess.run(cmd, shell=True, capture_output=True, text=True)\n",
        "    if desc:\n",
        "        print(\"OK\" if result.returncode == 0 else f\"WARN ({result.stderr[:120]})\")\n",
        "    if check and result.returncode != 0:\n",
        "        raise RuntimeError(f\"{desc} failed: {result.stderr[:300]}\")\n",
        "    return result\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"PHASE 1: SYSTEM CHECK & DEPENDENCY INSTALL\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# --- GPU Check ---\n",
        "gpu_check = subprocess.run(\n",
        "    [\"nvidia-smi\", \"--query-gpu=name,memory.total,driver_version\", \"--format=csv,noheader\"],\n",
        "    capture_output=True, text=True\n",
        ")\n",
        "if gpu_check.returncode == 0:\n",
        "    print(f\"  [GPU] {gpu_check.stdout.strip()}\")\n",
        "else:\n",
        "    print(\"  [GPU] No GPU detected ‚Äî LLM inference will be slow on CPU!\")\n",
        "    print(\"         Go to Runtime > Change runtime type > GPU\")\n",
        "\n",
        "# --- RAM & Disk ---\n",
        "try:\n",
        "    import psutil\n",
        "    ram_gb = psutil.virtual_memory().total / (1024**3)\n",
        "    print(f\"  [RAM] {ram_gb:.1f} GB\")\n",
        "except ImportError:\n",
        "    pass\n",
        "disk = shutil.disk_usage(\"/\")\n",
        "print(f\"  [Disk] {disk.free / (1024**3):.1f} GB free\")\n",
        "print(f\"  [Python] {sys.version.split()[0]}\")\n",
        "\n",
        "# --- Install System Dependencies ---\n",
        "print(\"\\n  Installing system packages...\")\n",
        "run_cmd(\"apt-get update -qq 2>/dev/null\", \"apt update\")\n",
        "run_cmd(\"apt-get install -y -qq postgresql postgresql-client redis-server build-essential libpq-dev zstd > /dev/null 2>&1\", \"PostgreSQL + Redis + build tools + zstd\")\n",
        "\n",
        "# Node.js 22\n",
        "run_cmd(\"curl -fsSL https://deb.nodesource.com/setup_22.x | bash - > /dev/null 2>&1\", \"Node.js 22 repo\")\n",
        "run_cmd(\"apt-get install -y -qq nodejs > /dev/null 2>&1\", \"Node.js 22\")\n",
        "\n",
        "# MinIO binary\n",
        "run_cmd(\"wget -q https://dl.min.io/server/minio/release/linux-amd64/minio -O /usr/local/bin/minio && chmod +x /usr/local/bin/minio\", \"MinIO\")\n",
        "\n",
        "node_ver = subprocess.run(\"node --version\", shell=True, capture_output=True, text=True)\n",
        "print(f\"  [Node.js] {node_ver.stdout.strip()}\")\n",
        "print(\"\\n  Phase 1 complete.\")\n",
        "print(\"=\" * 60)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "8960bca3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8960bca3",
        "outputId": "7902b88f-3315-47a7-993f-363d3b6dc1a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "PHASE 2: OLLAMA + LLM MODEL SETUP\n",
            "============================================================\n",
            "  Installing Ollama... OK\n",
            "  Starting Ollama server... OK\n",
            "  Pulling deepseek-r1:14b (this may take 2-8 min)...\n",
            "  Pulling llama3.2:3b...\n",
            "\n",
            "  Available models:\n",
            "\n",
            "  Phase 2 complete.\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# ‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n",
        "# ‚ïë  PHASE 2: Ollama + LLM Models (GPU-Accelerated)            ‚ïë\n",
        "# ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n",
        "import subprocess, os, time\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"PHASE 2: OLLAMA + LLM MODEL SETUP\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Install Ollama\n",
        "print(\"  Installing Ollama...\", end=\" \", flush=True)\n",
        "\n",
        "# Download the install script\n",
        "subprocess.run(\"wget -q https://ollama.com/install.sh -O /tmp/ollama_install.sh\", shell=True, check=True)\n",
        "subprocess.run(\"chmod +x /tmp/ollama_install.sh\", shell=True, check=True)\n",
        "\n",
        "# Run the install script with sudo, capturing output\n",
        "install_command = \"sudo /tmp/ollama_install.sh\"\n",
        "install_process = subprocess.Popen(install_command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
        "stdout, stderr = install_process.communicate()\n",
        "\n",
        "if install_process.returncode == 0:\n",
        "    print(\"OK\")\n",
        "else:\n",
        "    print(f\"WARN: Ollama installation script returned non-zero exit code ({install_process.returncode}).\")\n",
        "    print(f\"Installation STDOUT:\\n{stdout}\")\n",
        "    print(f\"Installation STDERR:\\n{stderr}\")\n",
        "\n",
        "# Verify Ollama executable exists\n",
        "OLLAMA_BIN_PATH = \"/usr/local/bin/ollama\"\n",
        "if not os.path.exists(OLLAMA_BIN_PATH):\n",
        "    print(f\"  [ERROR] Ollama executable not found at {OLLAMA_BIN_PATH}. Installation might have failed or installed elsewhere.\")\n",
        "    print(\"  Attempting to locate ollama binary...\")\n",
        "    find_ollama_result = subprocess.run(\"find / -name ollama 2>/dev/null\", shell=True, capture_output=True, text=True)\n",
        "    found_paths = find_ollama_result.stdout.strip().split('\\n')\n",
        "    if found_paths and found_paths[0]: # If anything was found\n",
        "        print(f\"  Found ollama at: {found_paths[0]}. Please check this path.\")\n",
        "    else:\n",
        "        print(\"  Ollama not found anywhere on the system after installation attempt.\")\n",
        "    raise FileNotFoundError(f\"Ollama executable not found at {OLLAMA_BIN_PATH}\")\n",
        "\n",
        "# Start Ollama server in background\n",
        "print(\"  Starting Ollama server...\", end=\" \", flush=True)\n",
        "os.environ[\"OLLAMA_HOST\"] = \"0.0.0.0:11434\"\n",
        "subprocess.Popen(\n",
        "    [OLLAMA_BIN_PATH, \"serve\"],\n",
        "    stdout=open(\"/tmp/ollama.log\", \"w\"),\n",
        "    stderr=subprocess.STDOUT,\n",
        "    env={**os.environ, \"OLLAMA_HOST\": \"0.0.0.0:11434\"}\n",
        ")\n",
        "time.sleep(5)\n",
        "print(\"OK\")\n",
        "\n",
        "# Pull primary model\n",
        "print(f\"  Pulling {PRIMARY_MODEL} (this may take 2-8 min)...\")\n",
        "subprocess.run([OLLAMA_BIN_PATH, \"pull\", PRIMARY_MODEL], capture_output=False, text=True)\n",
        "\n",
        "# Pull fallback model\n",
        "print(f\"  Pulling {FALLBACK_MODEL}...\")\n",
        "subprocess.run([OLLAMA_BIN_PATH, \"pull\", FALLBACK_MODEL], capture_output=False, text=True)\n",
        "\n",
        "# Verify\n",
        "print(\"\\n  Available models:\")\n",
        "subprocess.run([OLLAMA_BIN_PATH, \"list\"], capture_output=False, text=True)\n",
        "\n",
        "print(\"\\n  Phase 2 complete.\")\n",
        "print(\"=\" * 60)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "b7b9f665",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b7b9f665",
        "outputId": "fb00f23b-ec81-4492-82ef-59a5a89972c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "PHASE 3: SETUP\n",
            "============================================================\n",
            "  [System] Checking GPU... OK (NVIDIA GPU detected)\n",
            "  [Repo] Updating... OK\n",
            "  [Setup] Configuring symlinks... OK\n",
            "  [Deps] Installing Python packages (2-3 min)... OK\n",
            "  [Deps] Installing OpenClaw... OK\n",
            "\n",
            "  Phase 3 complete.\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# ‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n",
        "# ‚ïë  PHASE 3: System Setup, Repo & Dependencies                ‚ïë\n",
        "# ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n",
        "import subprocess, os, sys, shutil\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"PHASE 3: SETUP\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# ‚îÄ‚îÄ‚îÄ SYSTEM CHECKS ‚îÄ‚îÄ‚îÄ\n",
        "print(\"  [System] Checking GPU...\", end=\" \", flush=True)\n",
        "gpu = subprocess.run(\"nvidia-smi\", shell=True, capture_output=True)\n",
        "if gpu.returncode == 0:\n",
        "    print(\"OK (NVIDIA GPU detected)\")\n",
        "else:\n",
        "    print(\"WARN (No GPU detected - Inference will be slow)\")\n",
        "\n",
        "# ‚îÄ‚îÄ‚îÄ REPOSITORY ‚îÄ‚îÄ‚îÄ\n",
        "INSTALL_DIR = \"/content/ai_final\"\n",
        "FRAMEWORK_DIR = f\"{INSTALL_DIR}/agentic-framework-main\"\n",
        "\n",
        "if os.path.exists(INSTALL_DIR):\n",
        "    print(\"  [Repo] Updating...\", end=\" \", flush=True)\n",
        "    subprocess.run([\"git\", \"-C\", INSTALL_DIR, \"pull\"], capture_output=False)\n",
        "    print(\"OK\")\n",
        "else:\n",
        "    print(f\"  [Repo] Cloning {REPO_URL}...\", end=\" \", flush=True)\n",
        "    subprocess.run([\"git\", \"clone\", REPO_URL, INSTALL_DIR], capture_output=False)\n",
        "    print(\"OK\")\n",
        "\n",
        "os.chdir(FRAMEWORK_DIR)\n",
        "\n",
        "# ‚îÄ‚îÄ‚îÄ SYMLINKS ‚îÄ‚îÄ‚îÄ\n",
        "print(\"  [Setup] Configuring symlinks...\", end=\" \", flush=True)\n",
        "symlinks = {\n",
        "    \"memory_service\": \"memory-service\",\n",
        "    \"subagent_manager\": \"subagent-manager\",\n",
        "    \"mcp_gateway\": \"mcp-gateway\",\n",
        "    \"code_exec\": \"code-exec\",\n",
        "}\n",
        "for link_name, target in symlinks.items():\n",
        "    if not os.path.exists(link_name) and os.path.exists(target):\n",
        "        os.symlink(target, link_name)\n",
        "print(\"OK\")\n",
        "\n",
        "# ‚îÄ‚îÄ‚îÄ DEPENDENCIES ‚îÄ‚îÄ‚îÄ\n",
        "print(\"  [Deps] Installing Python packages (2-3 min)...\", end=\" \", flush=True)\n",
        "subprocess.run(\n",
        "    [sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"-r\", f\"{FRAMEWORK_DIR}/requirements.txt\"],\n",
        "    capture_output=False\n",
        ")\n",
        "subprocess.run(\n",
        "    [sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"pyngrok\", \"asyncpg\", \"aiofiles\", \"psutil\"],\n",
        "    capture_output=False\n",
        ")\n",
        "print(\"OK\")\n",
        "\n",
        "print(\"  [Deps] Installing OpenClaw...\", end=\" \", flush=True)\n",
        "subprocess.run([\"npm\", \"install\", \"-g\", \"openclaw@latest\"], capture_output=True)\n",
        "print(\"OK\")\n",
        "\n",
        "# PYTHONPATH\n",
        "if FRAMEWORK_DIR not in sys.path:\n",
        "    sys.path.insert(0, FRAMEWORK_DIR)\n",
        "os.environ[\"PYTHONPATH\"] = FRAMEWORK_DIR\n",
        "\n",
        "print(\"\\n  Phase 3 complete.\")\n",
        "print(\"=\" * 60)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "78fdaf2a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "78fdaf2a",
        "outputId": "e9b2eab3-07c8-42e1-cb04-a7a9299a797e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "PHASE 4: INFRASTRUCTURE & SERVICES\n",
            "============================================================\n",
            "  [System] Verifying binaries... OK\n",
            "\n",
            "‚îÄ‚îÄ Cleanup ‚îÄ‚îÄ\n",
            "\n",
            "‚îÄ‚îÄ Infrastructure ‚îÄ‚îÄ\n",
            "  Starting PostgreSQL... OK\n",
            "  Waiting for Redis (:6379)... OK\n",
            "  Waiting for ChromaDB (:8001)... OK\n",
            "  Waiting for MinIO (:9005)... OK\n",
            "  Waiting for Ollama (:11434)... OK\n",
            "\n",
            "‚îÄ‚îÄ Microservices ‚îÄ‚îÄ\n",
            "  Starting Code Executor... OK\n",
            "  Starting Memory Service... OK\n",
            "  Starting SubAgent Manager... OK\n",
            "  Starting MCP Gateway... OK\n",
            "  Starting Orchestrator... OK\n",
            "\n",
            "‚îÄ‚îÄ Dashboard ‚îÄ‚îÄ\n",
            "  Installing & Starting... OK\n",
            "\n",
            "  Waiting 20s for services to initialize...\n",
            "\n",
            "‚îÄ‚îÄ Status ‚îÄ‚îÄ\n",
            "  ‚úÖ Orchestrator : ONLINE\n",
            "  ‚úÖ Memory       : ONLINE\n",
            "  ‚úÖ SubAgents    : ONLINE\n",
            "  ‚úÖ MCP (8082)   : ONLINE\n",
            "  ‚úÖ CodeExec     : ONLINE\n",
            "  ‚úÖ Ollama       : ONLINE\n",
            "\n",
            "üöÄ ALL SYSTEMS GO!\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# ‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n",
        "# ‚ïë  PHASE 4: Start Infrastructure + All Services               ‚ïë\n",
        "# ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n",
        "import subprocess, os, sys, time, urllib.request, json, socket\n",
        "\n",
        "# ‚îÄ‚îÄ‚îÄ CONFIGURATION ‚îÄ‚îÄ‚îÄ\n",
        "# Load globals if defined, else defaults\n",
        "if \"PRIMARY_MODEL\" not in locals(): PRIMARY_MODEL = \"deepseek-r1:14b\"\n",
        "if \"FALLBACK_MODEL\" not in locals(): FALLBACK_MODEL = \"llama3.2:3b\"\n",
        "if \"START_DASHBOARD\" not in locals(): START_DASHBOARD = True\n",
        "if \"ENABLE_NGROK\" not in locals(): ENABLE_NGROK = True\n",
        "\n",
        "FRAMEWORK_DIR = \"/content/ai_final/agentic-framework-main\"\n",
        "os.chdir(FRAMEWORK_DIR)\n",
        "\n",
        "# ‚îÄ‚îÄ‚îÄ AUTO-REPAIR ‚îÄ‚îÄ‚îÄ\n",
        "def check_system():\n",
        "    print(\"  [System] Verifying binaries...\", end=\" \", flush=True)\n",
        "    missing = []\n",
        "    if not os.path.exists(\"/usr/local/bin/minio\"): missing.append(\"minio\")\n",
        "    if subprocess.run(\"which redis-server\", shell=True).returncode != 0: missing.append(\"redis\")\n",
        "    if subprocess.run(\"which ollama\", shell=True).returncode != 0: missing.append(\"ollama\")\n",
        "\n",
        "    if missing:\n",
        "        print(f\"Fixing: {missing}\")\n",
        "        if \"minio\" in missing:\n",
        "            subprocess.run(\"wget -q https://dl.min.io/server/minio/release/linux-amd64/minio -O /usr/local/bin/minio && chmod +x /usr/local/bin/minio\", shell=True)\n",
        "        if \"redis\" in missing:\n",
        "            subprocess.run(\"apt-get update -qq && apt-get install -y -qq redis-server postgresql postgresql-client > /dev/null\", shell=True)\n",
        "        if \"ollama\" in missing:\n",
        "            subprocess.run(\"curl -fsSL https://ollama.com/install.sh | sh\", shell=True)\n",
        "    else:\n",
        "        print(\"OK\")\n",
        "\n",
        "def wait_for_service(port, name, timeout=60):\n",
        "    print(f\"  Waiting for {name} (:{port})...\", end=\" \", flush=True)\n",
        "    start = time.time()\n",
        "    while time.time() - start < timeout:\n",
        "        try:\n",
        "            with socket.create_connection((\"localhost\", port), timeout=1):\n",
        "                print(\"OK\")\n",
        "                return True\n",
        "        except: time.sleep(1)\n",
        "    print(\"TIMEOUT\")\n",
        "    return False\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"PHASE 4: INFRASTRUCTURE & SERVICES\")\n",
        "print(\"=\" * 60)\n",
        "check_system()\n",
        "\n",
        "# ‚îÄ‚îÄ‚îÄ CLEANUP ‚îÄ‚îÄ‚îÄ\n",
        "print(\"\\n‚îÄ‚îÄ Cleanup ‚îÄ‚îÄ\")\n",
        "subprocess.run(\"pkill -f uvicorn; pkill -f 'chroma run'; pkill -f minio\", shell=True)\n",
        "time.sleep(2)\n",
        "\n",
        "# ‚îÄ‚îÄ‚îÄ INFRASTRUCTURE ‚îÄ‚îÄ‚îÄ\n",
        "print(\"\\n‚îÄ‚îÄ Infrastructure ‚îÄ‚îÄ\")\n",
        "# 1. PostgreSQL\n",
        "print(\"  Starting PostgreSQL...\", end=\" \")\n",
        "subprocess.run(\"service postgresql start\", shell=True, capture_output=True)\n",
        "time.sleep(2)\n",
        "subprocess.run([\"sudo\", \"-u\", \"postgres\", \"psql\", \"-c\", \"CREATE USER agent_user WITH PASSWORD 'agent_pass' CREATEDB;\"], capture_output=True)\n",
        "subprocess.run([\"sudo\", \"-u\", \"postgres\", \"psql\", \"-c\", \"CREATE DATABASE agentic_framework OWNER agent_user;\"], capture_output=True)\n",
        "subprocess.run([\"sudo\", \"-u\", \"postgres\", \"psql\", \"-c\", \"GRANT ALL PRIVILEGES ON DATABASE agentic_framework TO agent_user;\"], capture_output=True)\n",
        "print(\"OK\")\n",
        "# 2. Redis\n",
        "subprocess.run(\"redis-server --daemonize yes --port 6379\", shell=True)\n",
        "wait_for_service(6379, \"Redis\", 10)\n",
        "# 3. ChromaDB\n",
        "os.makedirs(\"/tmp/chroma_data\", exist_ok=True)\n",
        "subprocess.Popen([\"chroma\", \"run\", \"--host\", \"0.0.0.0\", \"--port\", \"8001\", \"--path\", \"/tmp/chroma_data\"], stdout=open(\"/tmp/chroma.log\", \"w\"), stderr=subprocess.STDOUT)\n",
        "wait_for_service(8001, \"ChromaDB\")\n",
        "# 4. MinIO (Port 9005)\n",
        "os.makedirs(\"/tmp/minio_data\", exist_ok=True)\n",
        "subprocess.Popen([\"/usr/local/bin/minio\", \"server\", \"/tmp/minio_data\", \"--address\", \":9005\", \"--console-address\", \":9001\"], stdout=open(\"/tmp/minio.log\", \"w\"), stderr=subprocess.STDOUT, env={**os.environ, \"MINIO_ROOT_USER\": \"minioadmin\", \"MINIO_ROOT_PASSWORD\": \"minioadmin\"})\n",
        "if not wait_for_service(9005, \"MinIO\", 90): print(\"\\n[ERROR] MinIO Failed. Check /tmp/minio.log\")\n",
        "# 5. Ollama\n",
        "if not wait_for_service(11434, \"Ollama\", 2):\n",
        "    print(\"  Starting Ollama...\", end=\" \")\n",
        "    subprocess.Popen([\"ollama\", \"serve\"], stdout=open(\"/tmp/ollama.log\", \"w\"), stderr=subprocess.STDOUT, env={**os.environ, \"OLLAMA_HOST\": \"0.0.0.0:11434\"})\n",
        "    wait_for_service(11434, \"Ollama\", 20)\n",
        "\n",
        "# ‚îÄ‚îÄ‚îÄ MODEL CHECK ‚îÄ‚îÄ‚îÄ\n",
        "res = subprocess.run([\"ollama\", \"list\"], capture_output=True, text=True)\n",
        "if PRIMARY_MODEL not in res.stdout:\n",
        "    print(f\"\\n  ‚ö†Ô∏è Model {PRIMARY_MODEL} missing. Pulling... (5-10m)\")\n",
        "    subprocess.run([\"ollama\", \"pull\", PRIMARY_MODEL], check=True)\n",
        "    print(\"  ‚úÖ Model pulled.\")\n",
        "\n",
        "# ‚îÄ‚îÄ‚îÄ ENVIRONMENT ‚îÄ‚îÄ‚îÄ\n",
        "env_vars = {\n",
        "    \"POSTGRES_URL\": \"postgresql://agent_user:agent_pass@localhost:5432/agentic_framework\",\n",
        "    \"REDIS_URL\": \"redis://localhost:6379/0\",\n",
        "    \"MCP_GATEWAY_URL\": \"http://localhost:8082\", \"MEMORY_SERVICE_URL\": \"http://localhost:8002\",\n",
        "    \"SUBAGENT_MANAGER_URL\": \"http://localhost:8003\", \"CODE_EXECUTOR_URL\": \"http://localhost:8004\",\n",
        "    \"CODE_EXECUTION_MODE\": \"local\", \"OLLAMA_ENDPOINT\": \"http://localhost:11434\",\n",
        "    \"OLLAMA_BASE_URL\": \"http://localhost:11434\", \"LOCAL_MODEL\": PRIMARY_MODEL, \"FALLBACK_MODEL\": FALLBACK_MODEL,\n",
        "    \"DEFAULT_LLM_PROVIDER\": \"local\", \"LLM_PROVIDER\": \"local\", \"USE_OPENCLAW\": \"false\",\n",
        "    \"CHROMA_URL\": \"http://localhost:8001\", \"MINIO_ENDPOINT\": \"localhost:9005\",\n",
        "    \"MINIO_ACCESS_KEY\": \"minioadmin\", \"MINIO_SECRET_KEY\": \"minioadmin\", \"JWT_SECRET_KEY\": \"colab-secret\",\n",
        "    \"ENVIRONMENT\": \"development\", \"PYTHONPATH\": FRAMEWORK_DIR,\n",
        "    \"WORKSPACE_ROOT\": f\"{FRAMEWORK_DIR}/workspace\", \"WEBSOCKET_ENABLED\": \"true\", \"INDEX_CODEBASE\": \"true\",\n",
        "}\n",
        "for k, v in env_vars.items(): os.environ[k] = v\n",
        "if os.path.exists(f\"{FRAMEWORK_DIR}/.env\"): os.remove(f\"{FRAMEWORK_DIR}/.env\")\n",
        "for d in [\"workspace/.copilot/memory/diary\", \"workspace/.copilot/memory/reflections\", \"workspace/ralph-work\"]: os.makedirs(f\"{FRAMEWORK_DIR}/{d}\", exist_ok=True)\n",
        "\n",
        "# ‚îÄ‚îÄ‚îÄ MICROSERVICES ‚îÄ‚îÄ‚îÄ\n",
        "print(\"\\n‚îÄ‚îÄ Microservices ‚îÄ‚îÄ\")\n",
        "base_env = {**os.environ}\n",
        "services = [\n",
        "    {\"name\": \"Code Executor\",    \"module\": \"code_exec.service.main:app\",        \"port\": 8004, \"log\": \"/tmp/code_exec.log\",        \"env\": {\"REDIS_URL\": \"redis://localhost:6379/4\"}},\n",
        "    {\"name\": \"Memory Service\",   \"module\": \"memory_service.service.main:app\",   \"port\": 8002, \"log\": \"/tmp/memory_service.log\",   \"env\": {\"REDIS_URL\": \"redis://localhost:6379/2\"}},\n",
        "    {\"name\": \"SubAgent Manager\", \"module\": \"subagent_manager.service.main:app\", \"port\": 8003, \"log\": \"/tmp/subagent_manager.log\", \"env\": {\"REDIS_URL\": \"redis://localhost:6379/1\"}},\n",
        "    {\"name\": \"MCP Gateway\",      \"module\": \"mcp_gateway.service.main:app\",      \"port\": 8082, \"log\": \"/tmp/mcp_gateway.log\",      \"env\": {\"REDIS_URL\": \"redis://localhost:6379/3\"}},\n",
        "    {\"name\": \"Orchestrator\",     \"module\": \"orchestrator.service.main:app\",     \"port\": 8000, \"log\": \"/tmp/orchestrator.log\",     \"env\": {}},\n",
        "]\n",
        "\n",
        "for svc in services:\n",
        "    print(f\"  Starting {svc['name']}...\", end=\" \")\n",
        "    svc_env = base_env.copy()\n",
        "    if svc[\"name\"] == \"Code Executor\":\n",
        "        for k in ['MINIO_ENDPOINT', 'MINIO_ACCESS_KEY', 'MINIO_SECRET_KEY', 'JWT_SECRET_KEY', 'ENVIRONMENT', 'WORKSPACE_ROOT', 'WEBSOCKET_ENABLED', 'INDEX_CODEBASE', 'PYTHONPATH']:\n",
        "            if k in svc_env: del svc_env[k]\n",
        "        svc_env[\"REDIS_URL\"] = svc[\"env\"][\"REDIS_URL\"]\n",
        "        svc_env[\"CODE_EXECUTION_MODE\"] = \"local\"\n",
        "    else:\n",
        "        svc_env.update(svc[\"env\"])\n",
        "    subprocess.Popen([sys.executable, \"-m\", \"uvicorn\", svc[\"module\"], \"--host\", \"0.0.0.0\", \"--port\", str(svc[\"port\"])], cwd=FRAMEWORK_DIR, stdout=open(svc[\"log\"], \"w\"), stderr=subprocess.STDOUT, env=svc_env)\n",
        "    print(\"OK\")\n",
        "    time.sleep(1)\n",
        "\n",
        "# ‚îÄ‚îÄ‚îÄ DASHBOARD ‚îÄ‚îÄ‚îÄ\n",
        "if START_DASHBOARD:\n",
        "    print(\"\\n‚îÄ‚îÄ Dashboard ‚îÄ‚îÄ\")\n",
        "    dash_dir = f\"{FRAMEWORK_DIR}/dashboard\"\n",
        "    if os.path.exists(f\"{dash_dir}/package.json\"):\n",
        "        print(\"  Installing & Starting...\", end=\" \")\n",
        "        subprocess.run([\"npm\", \"install\"], cwd=dash_dir, capture_output=True)\n",
        "        subprocess.Popen([\"npm\", \"start\"], cwd=dash_dir, stdout=open(\"/tmp/dashboard.log\", \"w\"), stderr=subprocess.STDOUT, env={**os.environ, \"PORT\": \"3000\", \"BROWSER\": \"none\"})\n",
        "        print(\"OK\")\n",
        "\n",
        "print(\"\\n  Waiting 20s for services to initialize...\")\n",
        "time.sleep(20)\n",
        "\n",
        "# ‚îÄ‚îÄ‚îÄ HEALTH ‚îÄ‚îÄ‚îÄ\n",
        "print(\"\\n‚îÄ‚îÄ Status ‚îÄ‚îÄ\")\n",
        "checks = [(\"Orchestrator\", 8000), (\"Memory\", 8002), (\"SubAgents\", 8003), (\"MCP (8082)\", 8082), (\"CodeExec\", 8004), (\"Ollama\", 11434)]\n",
        "passed = 0\n",
        "for name, port in checks:\n",
        "    try:\n",
        "        urllib.request.urlopen(f\"http://localhost:{port}/\" + (\"api/tags\" if port==11434 else \"health\"), timeout=2)\n",
        "        print(f\"  ‚úÖ {name:<12} : ONLINE\")\n",
        "        passed += 1\n",
        "    except: print(f\"  ‚ùå {name:<12} : OFFLINE\")\n",
        "\n",
        "if passed == len(checks): print(\"\\nüöÄ ALL SYSTEMS GO!\")\n",
        "else: print(\"\\n‚ö†Ô∏è Some services failed. Check logs.\")\n",
        "print(\"=\" * 60)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b56bd990"
      },
      "source": [
        "import subprocess, os, sys, time, urllib.request, socket\n",
        "\n",
        "print(\"=== FINAL SYSTEM CHECK ===\")\n",
        "FRAMEWORK_DIR = \"/content/ai_final/agentic-framework-main\"\n",
        "os.chdir(FRAMEWORK_DIR)\n",
        "\n",
        "# Services to ensure are running\n",
        "services = [\n",
        "    {\"name\": \"Redis\",            \"port\": 6379,  \"cmd\": \"redis-server --daemonize yes --port 6379\"},\n",
        "    {\"name\": \"MinIO\",            \"port\": 9005,  \"cmd\": \"/usr/local/bin/minio server /tmp/minio_data --address :9005 --console-address :9001\"},\n",
        "    {\"name\": \"Ollama\",           \"port\": 11434, \"cmd\": \"ollama serve\"},\n",
        "    {\"name\": \"Memory Service\",   \"port\": 8002,  \"module\": \"memory_service.service.main:app\", \"env\": {\"REDIS_URL\": \"redis://localhost:6379/2\"}},\n",
        "    {\"name\": \"SubAgent Manager\", \"port\": 8003,  \"module\": \"subagent_manager.service.main:app\", \"env\": {\"REDIS_URL\": \"redis://localhost:6379/1\"}},\n",
        "    {\"name\": \"Code Executor\",    \"port\": 8004,  \"module\": \"code_exec.service.main:app\", \"env\": {\"REDIS_URL\": \"redis://localhost:6379/4\", \"CODE_EXECUTION_MODE\": \"local\"}},\n",
        "    {\"name\": \"MCP Gateway\",      \"port\": 8082,  \"module\": \"mcp_gateway.service.main:app\", \"env\": {\"REDIS_URL\": \"redis://localhost:6379/3\"}}\n",
        "]\n",
        "\n",
        "def is_port_open(port):\n",
        "    with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:\n",
        "        return s.connect_ex(('localhost', port)) == 0\n",
        "\n",
        "print(\"Checking services...\")\n",
        "base_env = {**os.environ, \"PYTHONPATH\": FRAMEWORK_DIR}\n",
        "\n",
        "# 1. Start Infrastructure if missing\n",
        "if not is_port_open(6379):\n",
        "    print(\"  Starting Redis...\", end=\" \")\n",
        "    subprocess.run(\"redis-server --daemonize yes --port 6379\", shell=True)\n",
        "    time.sleep(1)\n",
        "    print(\"OK\")\n",
        "\n",
        "if not is_port_open(9005):\n",
        "    print(\"  Starting MinIO...\", end=\" \")\n",
        "    os.makedirs(\"/tmp/minio_data\", exist_ok=True)\n",
        "    subprocess.Popen(services[1][\"cmd\"].split(), stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL,\n",
        "                     env={**os.environ, \"MINIO_ROOT_USER\": \"minioadmin\", \"MINIO_ROOT_PASSWORD\": \"minioadmin\"})\n",
        "    print(\"OK\")\n",
        "\n",
        "if not is_port_open(11434):\n",
        "    print(\"  Starting Ollama...\", end=\" \")\n",
        "    subprocess.Popen([\"ollama\", \"serve\"], stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL, env={**os.environ, \"OLLAMA_HOST\": \"0.0.0.0:11434\"})\n",
        "    print(\"OK\")\n",
        "\n",
        "# 2. Start Microservices if missing\n",
        "for svc in services[3:]:\n",
        "    if not is_port_open(svc[\"port\"]):\n",
        "        print(f\"  Starting {svc['name']}...\", end=\" \")\n",
        "        env_vars = {**base_env, **svc[\"env\"]}\n",
        "        # Clean env for Code Exec\n",
        "        if svc['name'] == \"Code Executor\":\n",
        "            for k in ['MINIO_ENDPOINT', 'MINIO_SECRET_KEY']:\n",
        "                if k in env_vars: del env_vars[k]\n",
        "\n",
        "        subprocess.Popen([sys.executable, \"-m\", \"uvicorn\", svc[\"module\"], \"--host\", \"0.0.0.0\", \"--port\", str(svc[\"port\"])],\n",
        "                         cwd=FRAMEWORK_DIR, stdout=open(f\"/tmp/{svc['module'].split('.')[0]}.log\", \"w\"), stderr=subprocess.STDOUT, env=env_vars)\n",
        "        print(\"OK\")\n",
        "    else:\n",
        "        print(f\"  {svc['name']} is running.\")\n",
        "\n",
        "print(\"\\n‚úÖ All backend services verified.\")\n",
        "print(\"üëâ You can now access the Dashboard at the Ngrok link above!\")"
      ],
      "id": "b56bd990",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f06f2b78",
        "outputId": "dbebbc18-3728-411f-e885-80ab7bc683a3"
      },
      "source": [
        "import os, subprocess, sys\n",
        "\n",
        "print(\"=== POST-RECOVERY CHECK ===\")\n",
        "\n",
        "# 1. Kill Stale Services\n",
        "print(\"  [1/3] Cleaning up old processes...\", end=\" \", flush=True)\n",
        "subprocess.run(\"pkill -f uvicorn\", shell=True)\n",
        "subprocess.run(\"pkill -f 'npm start'\", shell=True)\n",
        "subprocess.run(\"pkill -f react-scripts\", shell=True)\n",
        "print(\"OK\")\n",
        "\n",
        "# 2. Verify Dashboard Build\n",
        "print(\"  [2/3] Verifying Dashboard build...\", end=\" \", flush=True)\n",
        "build_index = \"/content/ai_final/agentic-framework-main/dashboard/build/index.html\"\n",
        "if os.path.exists(build_index):\n",
        "    print(\"‚úÖ Success (Build found)\")\n",
        "else:\n",
        "    print(\"‚ùå FAIL (Build missing)\")\n",
        "    print(\"    -> Try running the Recovery cell again or check logs.\")\n",
        "\n",
        "# 3. Check Models\n",
        "print(\"  [3/3] Checking AI Models...\", end=\" \", flush=True)\n",
        "try:\n",
        "    res = subprocess.run([\"ollama\", \"list\"], capture_output=True, text=True)\n",
        "    if \"deepseek-r1:14b\" in res.stdout:\n",
        "        print(\"‚úÖ Models Present\")\n",
        "    else:\n",
        "        print(\"‚ö†Ô∏è Models Missing (Runtime was reset)\")\n",
        "        print(\"    -> Phase 4 will automatically pull them (takes 5-10m).\")\n",
        "except:\n",
        "    print(\"‚ö†Ô∏è Ollama not running (Normal if runtime reset)\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*40)\n",
        "print(\"üëâ READY. Please run **PHASE 4** (Infrastructure) now.\")\n",
        "print(\"=\"*40)"
      ],
      "id": "f06f2b78",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== POST-RECOVERY CHECK ===\n",
            "  [1/3] Cleaning up old processes... OK\n",
            "  [2/3] Verifying Dashboard build... ‚ùå FAIL (Build missing)\n",
            "    -> Try running the Recovery cell again or check logs.\n",
            "  [3/3] Checking AI Models... ‚ö†Ô∏è Ollama not running (Normal if runtime reset)\n",
            "\n",
            "========================================\n",
            "üëâ READY. Please run **PHASE 4** (Infrastructure) now.\n",
            "========================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d2bd55c6",
        "outputId": "a52aa6f0-4d72-4414-c6d7-eb69338f2550"
      },
      "source": [
        "import os, subprocess, sys\n",
        "\n",
        "REPO_URL = \"https://github.com/landonking-gif/ai_final.git\"\n",
        "INSTALL_DIR = \"/content/ai_final\"\n",
        "FRAMEWORK_DIR = f\"{INSTALL_DIR}/agentic-framework-main\"\n",
        "DASH_DIR = f\"{FRAMEWORK_DIR}/dashboard\"\n",
        "ORCH_FILE = f\"{FRAMEWORK_DIR}/orchestrator/service/main.py\"\n",
        "\n",
        "print(\"=== üöë SYSTEM RECOVERY & DASHBOARD FIX ===\")\n",
        "print(\"It appears the runtime files were lost. Restoring...\")\n",
        "\n",
        "# 1. Clone Repo\n",
        "if not os.path.exists(INSTALL_DIR):\n",
        "    print(f\"  [1/4] Cloning {REPO_URL}...\", end=\" \", flush=True)\n",
        "    subprocess.run([\"git\", \"clone\", REPO_URL, INSTALL_DIR], capture_output=True)\n",
        "    print(\"OK\")\n",
        "else:\n",
        "    print(\"  [1/4] Repo exists.\")\n",
        "\n",
        "# 2. Dependencies\n",
        "print(\"  [2/4] Installing dependencies...\", end=\" \", flush=True)\n",
        "subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"-r\", f\"{FRAMEWORK_DIR}/requirements.txt\"], capture_output=True)\n",
        "subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"pyngrok\", \"asyncpg\", \"aiofiles\", \"psutil\"], capture_output=True)\n",
        "print(\"OK\")\n",
        "\n",
        "# 3. Build Dashboard (Single Port Fix)\n",
        "print(\"  [3/4] Building Dashboard for Single-Port Access (1-2 min)...\")\n",
        "build_env = {**os.environ, \"REACT_APP_API_URL\": \"\", \"homepage\": \".\"}\n",
        "\n",
        "# Install\n",
        "inst = subprocess.run([\"npm\", \"install\"], cwd=DASH_DIR, capture_output=True, text=True)\n",
        "if inst.returncode != 0:\n",
        "    print(f\"\\n[WARN] npm install had issues:\\n{inst.stderr[-500:]}\")\n",
        "\n",
        "# Fix Permissions (Critical Step)\n",
        "subprocess.run([\"chmod\", \"-R\", \"+x\", \"node_modules/.bin\"], cwd=DASH_DIR)\n",
        "\n",
        "# Build\n",
        "res = subprocess.run([\"npm\", \"run\", \"build\"], cwd=DASH_DIR, env=build_env, capture_output=True, text=True)\n",
        "if res.returncode == 0:\n",
        "    print(\"      ‚úÖ Build Success\")\n",
        "else:\n",
        "    print(f\"      ‚ùå Build Failed: {res.stderr[-500:]}\")\n",
        "\n",
        "# 4. Patch Orchestrator\n",
        "print(\"  [4/4] Patching Orchestrator to serve Dashboard...\", end=\" \", flush=True)\n",
        "if os.path.exists(ORCH_FILE):\n",
        "    with open(ORCH_FILE, \"r\") as f: code = f.read()\n",
        "    if \"fastapi.staticfiles\" not in code:\n",
        "        patch = f\"\"\"\n",
        "# ‚îÄ‚îÄ‚îÄ INJECTED: DASHBOARD SERVING ‚îÄ‚îÄ‚îÄ\n",
        "from fastapi.staticfiles import StaticFiles\n",
        "from fastapi.responses import FileResponse\n",
        "import os\n",
        "build_dir = \\\"{DASH_DIR}/build\\\"\n",
        "if os.path.exists(build_dir):\n",
        "    app.mount(\\\"/static\\\", StaticFiles(directory=f\\\"{{build_dir}}/static\\\"), name=\\\"static\\\")\n",
        "\n",
        "@app.get(\\\"/{{full_path:path}}\\\")\n",
        "async def serve_react(full_path: str):\n",
        "    # Don't intercept API\n",
        "    if full_path.startswith(\\\"api\\\") or full_path.startswith(\\\"health\\\") or full_path.startswith(\\\"docs\\\"):\n",
        "        return {{\"error\": \"Not Found\"}}\n",
        "\n",
        "    # Serve Index\n",
        "    idx = f\\\"{{build_dir}}/index.html\\\"\n",
        "    if os.path.exists(idx): return FileResponse(idx)\n",
        "    return {{\"error\": \"Dashboard not built\"}}\n",
        "\"\"\"\n",
        "        with open(ORCH_FILE, \"a\") as f: f.write(patch)\n",
        "        print(\"OK\")\n",
        "    else:\n",
        "        print(\"Already Patched\")\n",
        "else:\n",
        "    print(\"FAIL (File missing)\")\n",
        "\n",
        "print(\"\\n‚úÖ RECOVERY COMPLETE.\")\n",
        "print(\"üëâ NOW RUN **PHASE 4** (Infrastructure) to start the services.\")"
      ],
      "id": "d2bd55c6",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== üöë SYSTEM RECOVERY & DASHBOARD FIX ===\n",
            "It appears the runtime files were lost. Restoring...\n",
            "  [1/4] Repo exists.\n",
            "  [2/4] Installing dependencies... OK\n",
            "  [3/4] Building Dashboard for Single-Port Access (1-2 min)...\n",
            "      ‚úÖ Build Success\n",
            "  [4/4] Patching Orchestrator to serve Dashboard... Already Patched\n",
            "\n",
            "‚úÖ RECOVERY COMPLETE.\n",
            "üëâ NOW RUN **PHASE 4** (Infrastructure) to start the services.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8810e849",
        "outputId": "8c53ba76-05d7-4a6e-a8dc-152f2bc014ba"
      },
      "source": [
        "import urllib.request, json\n",
        "\n",
        "print(\"=== CHECKING OLLAMA MODELS ===\")\n",
        "try:\n",
        "    resp = urllib.request.urlopen(\"http://localhost:11434/api/tags\")\n",
        "    data = json.loads(resp.read().decode())\n",
        "    models = [m['name'] for m in data.get('models', [])]\n",
        "    if models:\n",
        "        print(f\"‚úÖ Found {len(models)} models: {models}\")\n",
        "    else:\n",
        "        print(\"‚ùå No models found! (They were likely wiped by the runtime reset)\")\n",
        "except Exception as e:\n",
        "    print(f\"Error checking models: {e}\")"
      ],
      "id": "8810e849",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== CHECKING OLLAMA MODELS ===\n",
            "‚úÖ Found 2 models: ['llama3.2:3b', 'deepseek-r1:14b']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "35219627",
        "outputId": "63f0ac7c-39fe-4d2d-ed63-e8c113f04568"
      },
      "source": [
        "import os, subprocess\n",
        "\n",
        "FRAMEWORK_DIR = \"/content/ai_final/agentic-framework-main\"\n",
        "\n",
        "print(\"=== FILE STRUCTURE DIAGNOSTIC ===\")\n",
        "print(f\"Framework Dir: {FRAMEWORK_DIR}\")\n",
        "\n",
        "# List root to see symlinks\n",
        "subprocess.run(f\"ls -la {FRAMEWORK_DIR}\", shell=True)\n",
        "\n",
        "print(\"\\n--- Checking for __init__.py in services ---\")\n",
        "services_dirs = [\"memory-service\", \"subagent-manager\", \"code-exec\", \"mcp-gateway\"]\n",
        "for d in services_dirs:\n",
        "    path = os.path.join(FRAMEWORK_DIR, d)\n",
        "    if os.path.exists(path):\n",
        "        init_path = os.path.join(path, \"__init__.py\")\n",
        "        has_init = os.path.exists(init_path)\n",
        "        print(f\"{d}: exists={'YES' if os.path.exists(path) else 'NO'}, has_init={'YES' if has_init else 'NO'}\")\n",
        "        if os.path.exists(path):\n",
        "             subprocess.run(f\"ls -F {path}\", shell=True)\n",
        "    else:\n",
        "        print(f\"{d}: MISSING\")\n",
        "\n",
        "print(\"\\n=== FULL LOGS FOR FAILURES ===\")\n",
        "logs = [\"/tmp/code_exec.log\", \"/tmp/subagent_manager.log\"]\n",
        "for log in logs:\n",
        "    print(f\"\\n--- {log} ---\")\n",
        "    if os.path.exists(log):\n",
        "        # Print last 100 lines\n",
        "        subprocess.run(f\"tail -n 100 {log}\", shell=True)\n",
        "    else:\n",
        "        print(\"(File not found)\")"
      ],
      "id": "35219627",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== FILE STRUCTURE DIAGNOSTIC ===\n",
            "Framework Dir: /content/ai_final/agentic-framework-main\n",
            "\n",
            "--- Checking for __init__.py in services ---\n",
            "memory-service: exists=YES, has_init=YES\n",
            "subagent-manager: exists=YES, has_init=YES\n",
            "code-exec: exists=YES, has_init=YES\n",
            "mcp-gateway: exists=YES, has_init=YES\n",
            "\n",
            "=== FULL LOGS FOR FAILURES ===\n",
            "\n",
            "--- /tmp/code_exec.log ---\n",
            "\n",
            "--- /tmp/subagent_manager.log ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "88f85fc8",
        "outputId": "aca26b33-1530-4ac5-ee34-1c4cfbdaf882"
      },
      "source": [
        "import subprocess\n",
        "\n",
        "print(\"=== CHECKING SERVICE LOGS FOR ERRORS ===\")\n",
        "services = [\n",
        "    \"/tmp/orchestrator.log\",\n",
        "    \"/tmp/memory_service.log\",\n",
        "    \"/tmp/code_exec.log\",\n",
        "    \"/tmp/subagent_manager.log\"\n",
        "]\n",
        "\n",
        "for log in services:\n",
        "    print(f\"\\n--- {log} ---\")\n",
        "    # Check if file exists first\n",
        "    try:\n",
        "        # Print last 30 lines of the log\n",
        "        result = subprocess.run([\"tail\", \"-n\", \"30\", log], capture_output=True, text=True)\n",
        "        print(result.stdout)\n",
        "        if result.stderr:\n",
        "            print(\"STDERR:\", result.stderr)\n",
        "    except Exception as e:\n",
        "        print(f\"Could not read log: {e}\")"
      ],
      "id": "88f85fc8",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== CHECKING SERVICE LOGS FOR ERRORS ===\n",
            "\n",
            "--- /tmp/orchestrator.log ---\n",
            "INFO:     Started server process [36820]\n",
            "INFO:     Waiting for application startup.\n",
            "2026-02-08 04:26:56,070 - orchestrator.service.main - INFO - Starting Lead Agent/Orchestrator service...\n",
            "2026-02-08 04:26:56,076 - orchestrator.service.main - INFO - Configuration: LLM Provider=local\n",
            "2026-02-08 04:26:56,076 - orchestrator.service.main - INFO - MCP Gateway URL: http://localhost:8082\n",
            "2026-02-08 04:26:56,076 - orchestrator.service.main - INFO - Memory Service URL: http://localhost:8002\n",
            "2026-02-08 04:26:56,319 - orchestrator.service.main - INFO - WebSocket manager initialized\n",
            "2026-02-08 04:26:56,323 - orchestrator.service.session_storage - INFO - Connected to Redis at redis://localhost:6379/0\n",
            "2026-02-08 04:26:56,324 - orchestrator.service.agent - INFO - Session storage initialized\n",
            "2026-02-08 04:26:56,324 - orchestrator.service.memory_learning - INFO - MemoryLearningClient initialized: memory_dir=/content/ai_final/agentic-framework-main/workspace/.copilot/memory\n",
            "2026-02-08 04:26:56,324 - orchestrator.service.agent_manager - INFO - Memory learning client initialized\n",
            "2026-02-08 04:26:56,324 - orchestrator.service.agent_manager - INFO - Agent manager started\n",
            "2026-02-08 04:26:56,324 - orchestrator.service.agent - INFO - Agent manager initialized\n",
            "2026-02-08 04:26:56,324 - orchestrator.service.agent - INFO - OrchestratorAgent fully initialized\n",
            "2026-02-08 04:26:56,324 - orchestrator.service.main - INFO - Orchestrator agent initialized with persistent storage\n",
            "2026-02-08 04:26:56,324 - orchestrator.service.main - INFO - Orchestrator service started successfully\n",
            "INFO:     Application startup complete.\n",
            "INFO:     Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit)\n",
            "2026-02-08 04:27:20,207 - httpx - INFO - HTTP Request: GET http://localhost:8082/health \"HTTP/1.1 200 OK\"\n",
            "2026-02-08 04:27:20,210 - httpx - INFO - HTTP Request: GET http://localhost:8002/health \"HTTP/1.1 200 OK\"\n",
            "2026-02-08 04:27:20,213 - httpx - INFO - HTTP Request: GET http://localhost:8003/health \"HTTP/1.1 200 OK\"\n",
            "INFO:     127.0.0.1:48688 - \"GET /health HTTP/1.1\" 200 OK\n",
            "\n",
            "\n",
            "--- /tmp/memory_service.log ---\n",
            "INFO:httpx:HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/modules.json \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/sentence_bert_config.json \"HTTP/1.1 307 Temporary Redirect\"\n",
            "INFO:httpx:HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/sentence_bert_config.json \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/adapter_config.json \"HTTP/1.1 404 Not Found\"\n",
            "INFO:httpx:HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/config.json \"HTTP/1.1 307 Temporary Redirect\"\n",
            "INFO:httpx:HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config.json \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/config.json \"HTTP/1.1 307 Temporary Redirect\"\n",
            "INFO:httpx:HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config.json \"HTTP/1.1 200 OK\"\n",
            "\n",
            "Loading weights:   0%|          | 0/103 [00:00<?, ?it/s]\n",
            "Loading weights:   1%|          | 1/103 [00:00<00:00, 29959.31it/s, Materializing param=embeddings.LayerNorm.bias]\n",
            "Loading weights:   1%|          | 1/103 [00:00<00:00, 6887.20it/s, Materializing param=embeddings.LayerNorm.bias] \n",
            "Loading weights:   2%|‚ñè         | 2/103 [00:00<00:00, 5440.08it/s, Materializing param=embeddings.LayerNorm.weight]\n",
            "Loading weights:   2%|‚ñè         | 2/103 [00:00<00:00, 4146.62it/s, Materializing param=embeddings.LayerNorm.weight]\n",
            "Loading weights:   3%|‚ñé         | 3/103 [00:00<00:00, 4482.69it/s, Materializing param=embeddings.position_embeddings.weight]\n",
            "Loading weights:   3%|‚ñé         | 3/103 [00:00<00:00, 3960.63it/s, Materializing param=embeddings.position_embeddings.weight]\n",
            "Loading weights:   4%|‚ñç         | 4/103 [00:00<00:00, 4447.83it/s, Materializing param=embeddings.token_type_embeddings.weight]\n",
            "Loading weights:   4%|‚ñç         | 4/103 [00:00<00:00, 4027.18it/s, Materializing param=embeddings.token_type_embeddings.weight]\n",
            "Loading weights:   5%|‚ñç         | 5/103 [00:00<00:00, 4362.70it/s, Materializing param=embeddings.word_embeddings.weight]      \n",
            "Loading weights:   5%|‚ñç         | 5/103 [00:00<00:00, 4068.19it/s, Materializing param=embeddings.word_embeddings.weight]\n",
            "Loading weights:   6%|‚ñå         | 6/103 [00:00<00:00, 4402.70it/s, Materializing param=encoder.layer.0.attention.output.LayerNorm.bias]\n",
            "Loading weights:   6%|‚ñå         | 6/103 [00:00<00:00, 4152.78it/s, Materializing param=encoder.layer.0.attention.output.LayerNorm.bias]\n",
            "Loading weights:   7%|‚ñã         | 7/103 [00:00<00:00, 922.11it/s, Materializing param=encoder.layer.0.attention.output.LayerNorm.weight]\n",
            "Loading weights:   7%|‚ñã         | 7/103 [00:00<00:00, 906.79it/s, Materializing param=encoder.layer.0.attention.output.LayerNorm.weight]\n",
            "Loading weights:   8%|‚ñä         | 8/103 [00:00<00:00, 1014.68it/s, Materializing param=encoder.layer.0.attention.output.dense.bias]     \n",
            "Loading weights:   8%|‚ñä         | 8/103 [00:00<00:00, 1001.62it/s, Materializing param=encoder.layer.0.attention.output.dense.bias]\n",
            "Loading weights:   9%|‚ñä         | 9/103 [00:00<00:00, 1103.34it/s, Materializing param=encoder.layer.0.attention.output.dense.weight]\n",
            "Loading weights:   9%|‚ñä         | 9/103 [00:00<00:00, 1092.14it/s, Materializing param=encoder.layer.0.attention.output.dense.weight]\n",
            "Loading weights:  10%|‚ñâ         | 10/103 [00:00<00:00, 1192.21it/s, Materializing param=encoder.layer.0.attention.self.key.bias]     \n",
            "Loading weights:  10%|‚ñâ         | 10/103 [00:00<00:00, 1178.84it/s, Materializing param=encoder.layer.0.attention.self.key.bias]\n",
            "Loading weights:  11%|‚ñà         | 11/103 [00:00<00:00, 1272.75it/s, Materializing param=encoder.layer.0.attention.self.key.weight]\n",
            "Loading weights:  11%|‚ñà         | 11/103 [00:00<00:00, 1261.00it/s, Materializing param=encoder.layer.0.attention.self.key.weight]\n",
            "Loading weights:  12%|‚ñà‚ñè        | 12/103 [00:00<00:00, 1353.77it/s, Materializing param=encoder.layer.0.attention.self.query.bias]\n",
            "Loading weights:  12%|‚ñà‚ñè        | 12/103 [00:00<00:00, 1341.93it/s, Materializing param=encoder.layer.0.attention.self.query.bias]\n",
            "Loading weights:  13%|‚ñà‚ñé        | 13/103 [00:00<00:00, 1430.68it/s, Materializing param=encoder.layer.0.attention.self.query.weight]\n",
            "Loading weights:  13%|‚ñà‚ñé        | 13/103 [00:00<00:00, 1416.88it/s, Materializing param=encoder.layer.0.attention.self.query.weight]\n",
            "Loading weights:  14%|‚ñà‚ñé        | 14/103 [00:00<00:00, 1500.84it/s, Materializing param=encoder.layer.0.attention.self.value.bias]  \n",
            "Loading weights:  14%|‚ñà‚ñé        | 14/103 [00:00<00:00, 1487.94it/s, Materializing param=encoder.layer.0.attention.self.value.bias]\n",
            "Loading weights:  15%|‚ñà‚ñç        | 15/103 [00:00<00:00, 986.46it/s, Materializing param=encoder.layer.0.attention.self.value.weight]\n",
            "Loading weights:  15%|‚ñà‚ñç        | 15/103 [00:00<00:00, 978.38it/s, Materializing param=encoder.layer.0.attention.self.value.weight]\n",
            "Loading weights:  16%|‚ñà‚ñå        | 16/103 [00:00<00:00, 1029.91it/s, Materializing param=encoder.layer.0.intermediate.dense.bias]   \n",
            "Loading weights:  16%|‚ñà‚ñå        | 16/103 [00:00<00:00, 1023.56it/s, Materializing param=encoder.layer.0.intermediate.dense.bias]\n",
            "Loading weights:  17%|‚ñà‚ñã        | 17/103 [00:00<00:00, 1076.97it/s, Materializing param=encoder.layer.0.intermediate.dense.weight]\n",
            "Loading weights:  17%|‚ñà‚ñã        | 17/103 [00:00<00:00, 1071.31it/s, Materializing param=encoder.layer.0.intermediate.dense.weight]\n",
            "Loading weights:  17%|‚ñà‚ñã        | 18/103 [00:00<00:00, 1123.99it/s, Materializing param=encoder.layer.0.output.LayerNorm.bias]    \n",
            "Loading weights:  17%|‚ñà‚ñã        | 18/103 [00:00<00:00, 1118.41it/s, Materializing param=encoder.layer.0.output.LayerNorm.bias]\n",
            "Loading weights:  18%|‚ñà‚ñä        | 19/103 [00:00<00:00, 1169.36it/s, Materializing param=encoder.layer.0.output.LayerNorm.weight]\n",
            "Loading weights:  18%|‚ñà‚ñä        | 19/103 [00:00<00:00, 1163.06it/s, Materializing param=encoder.layer.0.output.LayerNorm.weight]\n",
            "Loading weights:  19%|‚ñà‚ñâ        | 20/103 [00:00<00:00, 906.02it/s, Materializing param=encoder.layer.0.output.dense.bias]       \n",
            "Loading weights:  19%|‚ñà‚ñâ        | 20/103 [00:00<00:00, 900.59it/s, Materializing param=encoder.layer.0.output.dense.bias]\n",
            "Loading weights:  20%|‚ñà‚ñà        | 21/103 [00:00<00:00, 937.54it/s, Materializing param=encoder.layer.0.output.dense.weight]\n",
            "Loading weights:  20%|‚ñà‚ñà        | 21/103 [00:00<00:00, 932.35it/s, Materializing param=encoder.layer.0.output.dense.weight]\n",
            "Loading weights:  21%|‚ñà‚ñà‚ñè       | 22/103 [00:00<00:00, 969.49it/s, Materializing param=encoder.layer.1.attention.output.LayerNorm.bias]\n",
            "Loading weights:  21%|‚ñà‚ñà‚ñè       | 22/103 [00:00<00:00, 965.89it/s, Materializing param=encoder.layer.1.attention.output.LayerNorm.bias]\n",
            "Loading weights:  22%|‚ñà‚ñà‚ñè       | 23/103 [00:00<00:00, 1003.09it/s, Materializing param=encoder.layer.1.attention.output.LayerNorm.weight]\n",
            "Loading weights:  22%|‚ñà‚ñà‚ñè       | 23/103 [00:00<00:00, 999.42it/s, Materializing param=encoder.layer.1.attention.output.LayerNorm.weight] \n",
            "Loading weights:  23%|‚ñà‚ñà‚ñé       | 24/103 [00:00<00:00, 1036.00it/s, Materializing param=encoder.layer.1.attention.output.dense.bias]     \n",
            "Loading weights:  23%|‚ñà‚ñà‚ñé       | 24/103 [00:00<00:00, 1032.34it/s, Materializing param=encoder.layer.1.attention.output.dense.bias]\n",
            "Loading weights:  24%|‚ñà‚ñà‚ñç       | 25/103 [00:00<00:00, 1068.87it/s, Materializing param=encoder.layer.1.attention.output.dense.weight]\n",
            "Loading weights:  24%|‚ñà‚ñà‚ñç       | 25/103 [00:00<00:00, 1063.89it/s, Materializing param=encoder.layer.1.attention.output.dense.weight]\n",
            "Loading weights:  25%|‚ñà‚ñà‚ñå       | 26/103 [00:00<00:00, 866.72it/s, Materializing param=encoder.layer.1.attention.self.key.bias]       \n",
            "Loading weights:  25%|‚ñà‚ñà‚ñå       | 26/103 [00:00<00:00, 863.18it/s, Materializing param=encoder.layer.1.attention.self.key.bias]\n",
            "Loading weights:  26%|‚ñà‚ñà‚ñå       | 27/103 [00:00<00:00, 890.99it/s, Materializing param=encoder.layer.1.attention.self.key.weight]\n",
            "Loading weights:  26%|‚ñà‚ñà‚ñå       | 27/103 [00:00<00:00, 888.49it/s, Materializing param=encoder.layer.1.attention.self.key.weight]\n",
            "Loading weights:  27%|‚ñà‚ñà‚ñã       | 28/103 [00:00<00:00, 915.78it/s, Materializing param=encoder.layer.1.attention.self.query.bias]\n",
            "Loading weights:  27%|‚ñà‚ñà‚ñã       | 28/103 [00:00<00:00, 913.07it/s, Materializing param=encoder.layer.1.attention.self.query.bias]\n",
            "Loading weights:  28%|‚ñà‚ñà‚ñä       | 29/103 [00:00<00:00, 940.85it/s, Materializing param=encoder.layer.1.attention.self.query.weight]\n",
            "Loading weights:  28%|‚ñà‚ñà‚ñä       | 29/103 [00:00<00:00, 938.31it/s, Materializing param=encoder.layer.1.attention.self.query.weight]\n",
            "Loading weights:  29%|‚ñà‚ñà‚ñâ       | 30/103 [00:00<00:00, 966.08it/s, Materializing param=encoder.layer.1.attention.self.value.bias]  \n",
            "Loading weights:  29%|‚ñà‚ñà‚ñâ       | 30/103 [00:00<00:00, 963.69it/s, Materializing param=encoder.layer.1.attention.self.value.bias]\n",
            "Loading weights:  30%|‚ñà‚ñà‚ñà       | 31/103 [00:00<00:00, 991.09it/s, Materializing param=encoder.layer.1.attention.self.value.weight]\n",
            "Loading weights:  30%|‚ñà‚ñà‚ñà       | 31/103 [00:00<00:00, 988.64it/s, Materializing param=encoder.layer.1.attention.self.value.weight]\n",
            "Loading weights:  31%|‚ñà‚ñà‚ñà       | 32/103 [00:00<00:00, 832.39it/s, Materializing param=encoder.layer.1.intermediate.dense.bias]    \n",
            "Loading weights:  31%|‚ñà‚ñà‚ñà       | 32/103 [00:00<00:00, 829.40it/s, Materializing param=encoder.layer.1.intermediate.dense.bias]\n",
            "Loading weights:  32%|‚ñà‚ñà‚ñà‚ñè      | 33/103 [00:00<00:00, 851.30it/s, Materializing param=encoder.layer.1.intermediate.dense.weight]\n",
            "Loading weights:  32%|‚ñà‚ñà‚ñà‚ñè      | 33/103 [00:00<00:00, 849.40it/s, Materializing param=encoder.layer.1.intermediate.dense.weight]\n",
            "Loading weights:  33%|‚ñà‚ñà‚ñà‚ñé      | 34/103 [00:00<00:00, 871.79it/s, Materializing param=encoder.layer.1.output.LayerNorm.bias]    \n",
            "Loading weights:  33%|‚ñà‚ñà‚ñà‚ñé      | 34/103 [00:00<00:00, 869.53it/s, Materializing param=encoder.layer.1.output.LayerNorm.bias]\n",
            "Loading weights:  34%|‚ñà‚ñà‚ñà‚ñç      | 35/103 [00:00<00:00, 891.39it/s, Materializing param=encoder.layer.1.output.LayerNorm.weight]\n",
            "Loading weights:  34%|‚ñà‚ñà‚ñà‚ñç      | 35/103 [00:00<00:00, 889.58it/s, Materializing param=encoder.layer.1.output.LayerNorm.weight]\n",
            "Loading weights:  35%|‚ñà‚ñà‚ñà‚ñç      | 36/103 [00:00<00:00, 911.45it/s, Materializing param=encoder.layer.1.output.dense.bias]      \n",
            "Loading weights:  35%|‚ñà‚ñà‚ñà‚ñç      | 36/103 [00:00<00:00, 909.47it/s, Materializing param=encoder.layer.1.output.dense.bias]\n",
            "Loading weights:  36%|‚ñà‚ñà‚ñà‚ñå      | 37/103 [00:00<00:00, 931.39it/s, Materializing param=encoder.layer.1.output.dense.weight]\n",
            "Loading weights:  36%|‚ñà‚ñà‚ñà‚ñå      | 37/103 [00:00<00:00, 929.61it/s, Materializing param=encoder.layer.1.output.dense.weight]\n",
            "Loading weights:  37%|‚ñà‚ñà‚ñà‚ñã      | 38/103 [00:00<00:00, 951.50it/s, Materializing param=encoder.layer.2.attention.output.LayerNorm.bias]\n",
            "Loading weights:  37%|‚ñà‚ñà‚ñà‚ñã      | 38/103 [00:00<00:00, 949.59it/s, Materializing param=encoder.layer.2.attention.output.LayerNorm.bias]\n",
            "Loading weights:  38%|‚ñà‚ñà‚ñà‚ñä      | 39/103 [00:00<00:00, 833.77it/s, Materializing param=encoder.layer.2.attention.output.LayerNorm.weight]\n",
            "Loading weights:  38%|‚ñà‚ñà‚ñà‚ñä      | 39/103 [00:00<00:00, 831.41it/s, Materializing param=encoder.layer.2.attention.output.LayerNorm.weight]\n",
            "Loading weights:  39%|‚ñà‚ñà‚ñà‚ñâ      | 40/103 [00:00<00:00, 849.55it/s, Materializing param=encoder.layer.2.attention.output.dense.bias]      \n",
            "Loading weights:  39%|‚ñà‚ñà‚ñà‚ñâ      | 40/103 [00:00<00:00, 847.82it/s, Materializing param=encoder.layer.2.attention.output.dense.bias]\n",
            "Loading weights:  40%|‚ñà‚ñà‚ñà‚ñâ      | 41/103 [00:00<00:00, 866.24it/s, Materializing param=encoder.layer.2.attention.output.dense.weight]\n",
            "Loading weights:  40%|‚ñà‚ñà‚ñà‚ñâ      | 41/103 [00:00<00:00, 864.54it/s, Materializing param=encoder.layer.2.attention.output.dense.weight]\n",
            "Loading weights:  41%|‚ñà‚ñà‚ñà‚ñà      | 42/103 [00:00<00:00, 882.31it/s, Materializing param=encoder.layer.2.attention.self.key.bias]      \n",
            "Loading weights:  41%|‚ñà‚ñà‚ñà‚ñà      | 42/103 [00:00<00:00, 880.80it/s, Materializing param=encoder.layer.2.attention.self.key.bias]\n",
            "Loading weights:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 43/103 [00:00<00:00, 899.08it/s, Materializing param=encoder.layer.2.attention.self.key.weight]\n",
            "Loading weights:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 43/103 [00:00<00:00, 897.61it/s, Materializing param=encoder.layer.2.attention.self.key.weight]\n",
            "Loading weights:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 44/103 [00:00<00:00, 915.63it/s, Materializing param=encoder.layer.2.attention.self.query.bias]\n",
            "Loading weights:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 44/103 [00:00<00:00, 914.16it/s, Materializing param=encoder.layer.2.attention.self.query.bias]\n",
            "Loading weights:  44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 45/103 [00:00<00:00, 829.77it/s, Materializing param=encoder.layer.2.attention.self.query.weight]\n",
            "Loading weights:  44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 45/103 [00:00<00:00, 827.84it/s, Materializing param=encoder.layer.2.attention.self.query.weight]\n",
            "Loading weights:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 46/103 [00:00<00:00, 843.30it/s, Materializing param=encoder.layer.2.attention.self.value.bias]  \n",
            "Loading weights:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 46/103 [00:00<00:00, 841.85it/s, Materializing param=encoder.layer.2.attention.self.value.bias]\n",
            "Loading weights:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 47/103 [00:00<00:00, 857.57it/s, Materializing param=encoder.layer.2.attention.self.value.weight]\n",
            "Loading weights:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 47/103 [00:00<00:00, 856.30it/s, Materializing param=encoder.layer.2.attention.self.value.weight]\n",
            "Loading weights:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 48/103 [00:00<00:00, 872.20it/s, Materializing param=encoder.layer.2.intermediate.dense.bias]    \n",
            "Loading weights:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 48/103 [00:00<00:00, 870.94it/s, Materializing param=encoder.layer.2.intermediate.dense.bias]\n",
            "Loading weights:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 49/103 [00:00<00:00, 789.30it/s, Materializing param=encoder.layer.2.intermediate.dense.weight]\n",
            "Loading weights:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 49/103 [00:00<00:00, 787.57it/s, Materializing param=encoder.layer.2.intermediate.dense.weight]\n",
            "Loading weights:  49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 50/103 [00:00<00:00, 801.32it/s, Materializing param=encoder.layer.2.output.LayerNorm.bias]    \n",
            "Loading weights:  49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 50/103 [00:00<00:00, 799.66it/s, Materializing param=encoder.layer.2.output.LayerNorm.bias]\n",
            "Loading weights:  50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 51/103 [00:00<00:00, 813.18it/s, Materializing param=encoder.layer.2.output.LayerNorm.weight]\n",
            "Loading weights:  50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 51/103 [00:00<00:00, 811.99it/s, Materializing param=encoder.layer.2.output.LayerNorm.weight]\n",
            "Loading weights:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 52/103 [00:00<00:00, 825.72it/s, Materializing param=encoder.layer.2.output.dense.bias]      \n",
            "Loading weights:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 52/103 [00:00<00:00, 824.55it/s, Materializing param=encoder.layer.2.output.dense.bias]\n",
            "Loading weights:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 53/103 [00:00<00:00, 838.14it/s, Materializing param=encoder.layer.2.output.dense.weight]\n",
            "Loading weights:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 53/103 [00:00<00:00, 836.95it/s, Materializing param=encoder.layer.2.output.dense.weight]\n",
            "Loading weights:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 54/103 [00:00<00:00, 766.51it/s, Materializing param=encoder.layer.3.attention.output.LayerNorm.bias]\n",
            "Loading weights:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 54/103 [00:00<00:00, 764.59it/s, Materializing param=encoder.layer.3.attention.output.LayerNorm.bias]\n",
            "Loading weights:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 55/103 [00:00<00:00, 775.79it/s, Materializing param=encoder.layer.3.attention.output.LayerNorm.weight]\n",
            "Loading weights:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 55/103 [00:00<00:00, 774.55it/s, Materializing param=encoder.layer.3.attention.output.LayerNorm.weight]\n",
            "Loading weights:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 56/103 [00:00<00:00, 786.20it/s, Materializing param=encoder.layer.3.attention.output.dense.bias]      \n",
            "Loading weights:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 56/103 [00:00<00:00, 785.03it/s, Materializing param=encoder.layer.3.attention.output.dense.bias]\n",
            "Loading weights:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 57/103 [00:00<00:00, 736.84it/s, Materializing param=encoder.layer.3.attention.output.dense.weight]\n",
            "Loading weights:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 57/103 [00:00<00:00, 735.40it/s, Materializing param=encoder.layer.3.attention.output.dense.weight]\n",
            "Loading weights:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 58/103 [00:00<00:00, 746.37it/s, Materializing param=encoder.layer.3.attention.self.key.bias]      \n",
            "Loading weights:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 58/103 [00:00<00:00, 745.53it/s, Materializing param=encoder.layer.3.attention.self.key.bias]\n",
            "Loading weights:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 59/103 [00:00<00:00, 756.86it/s, Materializing param=encoder.layer.3.attention.self.key.weight]\n",
            "Loading weights:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 59/103 [00:00<00:00, 756.06it/s, Materializing param=encoder.layer.3.attention.self.key.weight]\n",
            "Loading weights:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 60/103 [00:00<00:00, 767.20it/s, Materializing param=encoder.layer.3.attention.self.query.bias]\n",
            "Loading weights:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 60/103 [00:00<00:00, 766.37it/s, Materializing param=encoder.layer.3.attention.self.query.bias]\n",
            "Loading weights:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 61/103 [00:00<00:00, 777.71it/s, Materializing param=encoder.layer.3.attention.self.query.weight]\n",
            "Loading weights:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 61/103 [00:00<00:00, 714.87it/s, Materializing param=encoder.layer.3.attention.self.query.weight]\n",
            "Loading weights:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 62/103 [00:00<00:00, 724.30it/s, Materializing param=encoder.layer.3.attention.self.value.bias]  \n",
            "Loading weights:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 62/103 [00:00<00:00, 723.26it/s, Materializing param=encoder.layer.3.attention.self.value.bias]\n",
            "Loading weights:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 63/103 [00:00<00:00, 733.26it/s, Materializing param=encoder.layer.3.attention.self.value.weight]\n",
            "Loading weights:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 63/103 [00:00<00:00, 732.42it/s, Materializing param=encoder.layer.3.attention.self.value.weight]\n",
            "Loading weights:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 64/103 [00:00<00:00, 742.63it/s, Materializing param=encoder.layer.3.intermediate.dense.bias]    \n",
            "Loading weights:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 64/103 [00:00<00:00, 741.92it/s, Materializing param=encoder.layer.3.intermediate.dense.bias]\n",
            "Loading weights:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 65/103 [00:00<00:00, 752.27it/s, Materializing param=encoder.layer.3.intermediate.dense.weight]\n",
            "Loading weights:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 65/103 [00:00<00:00, 751.27it/s, Materializing param=encoder.layer.3.intermediate.dense.weight]\n",
            "Loading weights:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 66/103 [00:00<00:00, 761.47it/s, Materializing param=encoder.layer.3.output.LayerNorm.bias]    \n",
            "Loading weights:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 66/103 [00:00<00:00, 760.78it/s, Materializing param=encoder.layer.3.output.LayerNorm.bias]\n",
            "Loading weights:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 67/103 [00:00<00:00, 771.08it/s, Materializing param=encoder.layer.3.output.LayerNorm.weight]\n",
            "Loading weights:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 67/103 [00:00<00:00, 770.37it/s, Materializing param=encoder.layer.3.output.LayerNorm.weight]\n",
            "Loading weights:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 68/103 [00:00<00:00, 780.68it/s, Materializing param=encoder.layer.3.output.dense.bias]      \n",
            "Loading weights:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 68/103 [00:00<00:00, 779.93it/s, Materializing param=encoder.layer.3.output.dense.bias]\n",
            "Loading weights:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 69/103 [00:00<00:00, 790.17it/s, Materializing param=encoder.layer.3.output.dense.weight]\n",
            "Loading weights:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 69/103 [00:00<00:00, 789.49it/s, Materializing param=encoder.layer.3.output.dense.weight]\n",
            "Loading weights:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 70/103 [00:00<00:00, 744.98it/s, Materializing param=encoder.layer.4.attention.output.LayerNorm.bias]\n",
            "Loading weights:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 70/103 [00:00<00:00, 744.01it/s, Materializing param=encoder.layer.4.attention.output.LayerNorm.bias]\n",
            "Loading weights:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 71/103 [00:00<00:00, 753.14it/s, Materializing param=encoder.layer.4.attention.output.LayerNorm.weight]\n",
            "Loading weights:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 71/103 [00:00<00:00, 752.36it/s, Materializing param=encoder.layer.4.attention.output.LayerNorm.weight]\n",
            "Loading weights:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 72/103 [00:00<00:00, 761.29it/s, Materializing param=encoder.layer.4.attention.output.dense.bias]      \n",
            "Loading weights:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 72/103 [00:00<00:00, 760.54it/s, Materializing param=encoder.layer.4.attention.output.dense.bias]\n",
            "Loading weights:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 73/103 [00:00<00:00, 769.85it/s, Materializing param=encoder.layer.4.attention.output.dense.weight]\n",
            "Loading weights:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 73/103 [00:00<00:00, 769.16it/s, Materializing param=encoder.layer.4.attention.output.dense.weight]\n",
            "Loading weights:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 74/103 [00:00<00:00, 778.38it/s, Materializing param=encoder.layer.4.attention.self.key.bias]      \n",
            "Loading weights:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 74/103 [00:00<00:00, 777.64it/s, Materializing param=encoder.layer.4.attention.self.key.bias]\n",
            "Loading weights:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 75/103 [00:00<00:00, 786.95it/s, Materializing param=encoder.layer.4.attention.self.key.weight]\n",
            "Loading weights:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 75/103 [00:00<00:00, 786.33it/s, Materializing param=encoder.layer.4.attention.self.key.weight]\n",
            "Loading weights:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 76/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.4.attention.self.key.weight]\n",
            "Loading weights:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 76/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.4.attention.self.query.bias]\n",
            "Loading weights:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 76/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.4.attention.self.query.bias]\n",
            "Loading weights:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 77/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.4.attention.self.query.weight]\n",
            "Loading weights:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 77/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.4.attention.self.query.weight]\n",
            "Loading weights:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 78/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.4.attention.self.value.bias]  \n",
            "Loading weights:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 78/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.4.attention.self.value.bias]\n",
            "Loading weights:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 79/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.4.attention.self.value.weight]\n",
            "Loading weights:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 79/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.4.attention.self.value.weight]\n",
            "Loading weights:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 80/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.4.intermediate.dense.bias]    \n",
            "Loading weights:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 80/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.4.intermediate.dense.bias]\n",
            "Loading weights:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 81/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.4.intermediate.dense.weight]\n",
            "Loading weights:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 81/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.4.intermediate.dense.weight]\n",
            "Loading weights:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 82/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.4.output.LayerNorm.bias]    \n",
            "Loading weights:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 82/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.4.output.LayerNorm.bias]\n",
            "Loading weights:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 83/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.4.output.LayerNorm.weight]\n",
            "Loading weights:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 83/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.4.output.LayerNorm.weight]\n",
            "Loading weights:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 84/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.4.output.dense.bias]      \n",
            "Loading weights:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 84/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.4.output.dense.bias]\n",
            "Loading weights:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 85/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.4.output.dense.weight]\n",
            "Loading weights:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 85/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.4.output.dense.weight]\n",
            "Loading weights:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 86/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.5.attention.output.LayerNorm.bias]\n",
            "Loading weights:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 86/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.5.attention.output.LayerNorm.bias]\n",
            "Loading weights:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 87/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.5.attention.output.LayerNorm.weight]\n",
            "Loading weights:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 87/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.5.attention.output.LayerNorm.weight]\n",
            "Loading weights:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 88/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.5.attention.output.dense.bias]      \n",
            "Loading weights:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 88/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.5.attention.output.dense.bias]\n",
            "Loading weights:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 89/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.5.attention.output.dense.weight]\n",
            "Loading weights:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 89/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.5.attention.output.dense.weight]\n",
            "Loading weights:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 90/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.5.attention.self.key.bias]      \n",
            "Loading weights:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 90/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.5.attention.self.key.bias]\n",
            "Loading weights:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 91/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.5.attention.self.key.weight]\n",
            "Loading weights:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 91/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.5.attention.self.key.weight]\n",
            "Loading weights:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 92/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.5.attention.self.query.bias]\n",
            "Loading weights:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 92/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.5.attention.self.query.bias]\n",
            "Loading weights:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 93/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.5.attention.self.query.weight]\n",
            "Loading weights:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 93/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.5.attention.self.query.weight]\n",
            "Loading weights:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 94/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.5.attention.self.value.bias]  \n",
            "Loading weights:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 94/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.5.attention.self.value.bias]\n",
            "Loading weights:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 95/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.5.attention.self.value.weight]\n",
            "Loading weights:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 95/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.5.attention.self.value.weight]\n",
            "Loading weights:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 96/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.5.intermediate.dense.bias]    \n",
            "Loading weights:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 96/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.5.intermediate.dense.bias]\n",
            "Loading weights:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 97/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.5.intermediate.dense.weight]\n",
            "Loading weights:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 97/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.5.intermediate.dense.weight]\n",
            "Loading weights:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 98/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.5.output.LayerNorm.bias]    \n",
            "Loading weights:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 98/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.5.output.LayerNorm.bias]\n",
            "Loading weights:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 99/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.5.output.LayerNorm.weight]\n",
            "Loading weights:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 99/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.5.output.LayerNorm.weight]\n",
            "Loading weights:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 100/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.5.output.dense.bias]     \n",
            "Loading weights:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 100/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.5.output.dense.bias]\n",
            "Loading weights:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 101/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.5.output.dense.weight]\n",
            "Loading weights:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 101/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.5.output.dense.weight]\n",
            "Loading weights:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 102/103 [00:00<00:00, 748.11it/s, Materializing param=pooler.dense.bias]                  \n",
            "Loading weights:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 102/103 [00:00<00:00, 748.11it/s, Materializing param=pooler.dense.bias]\n",
            "Loading weights: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 103/103 [00:00<00:00, 748.11it/s, Materializing param=pooler.dense.weight]\n",
            "Loading weights: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 103/103 [00:00<00:00, 748.11it/s, Materializing param=pooler.dense.weight]\n",
            "Loading weights: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 103/103 [00:00<00:00, 782.15it/s, Materializing param=pooler.dense.weight]\n",
            "BertModel LOAD REPORT from: sentence-transformers/all-MiniLM-L6-v2\n",
            "Key                     | Status     |  | \n",
            "------------------------+------------+--+-\n",
            "embeddings.position_ids | UNEXPECTED |  | \n",
            "\n",
            "Notes:\n",
            "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n",
            "INFO:httpx:HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/config.json \"HTTP/1.1 307 Temporary Redirect\"\n",
            "INFO:httpx:HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config.json \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/tokenizer_config.json \"HTTP/1.1 307 Temporary Redirect\"\n",
            "INFO:httpx:HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/tokenizer_config.json \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: GET https://huggingface.co/api/models/sentence-transformers/all-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=false&expand=false \"HTTP/1.1 404 Not Found\"\n",
            "INFO:httpx:HTTP Request: GET https://huggingface.co/api/models/sentence-transformers/all-MiniLM-L6-v2/tree/main?recursive=true&expand=false \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/1_Pooling/config.json \"HTTP/1.1 307 Temporary Redirect\"\n",
            "INFO:httpx:HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/1_Pooling%2Fconfig.json \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: GET https://huggingface.co/api/models/sentence-transformers/all-MiniLM-L6-v2 \"HTTP/1.1 200 OK\"\n",
            "INFO:     Application startup complete.\n",
            "INFO:     Uvicorn running on http://0.0.0.0:8002 (Press CTRL+C to quit)\n",
            "Memory service started on 0.0.0.0:8001\n",
            "INFO:     127.0.0.1:53380 - \"GET /health HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:53382 - \"GET /health HTTP/1.1\" 200 OK\n",
            "\n",
            "\n",
            "--- /tmp/code_exec.log ---\n",
            "INFO:     Started server process [36793]\n",
            "INFO:     Waiting for application startup.\n",
            "2026-02-08 04:26:51,538 - code_exec.service.main - INFO - Starting Code Executor Service\n",
            "2026-02-08 04:26:51,538 - code_exec.service.main - INFO - Skills directory: /Users/paragpradhan/Projects/Agent framework/agent-framework/code-exec/skills\n",
            "2026-02-08 04:26:51,543 - code_exec.service.registry - INFO - Loading skills from: /Users/paragpradhan/Projects/Agent framework/agent-framework/code-exec/skills\n",
            "2026-02-08 04:26:51,544 - code_exec.service.registry - INFO - Loaded 0 skills successfully\n",
            "2026-02-08 04:26:51,544 - code_exec.service.main - INFO - Loaded 0 skills\n",
            "2026-02-08 04:26:51,544 - code_exec.service.main - INFO - Service ready on 0.0.0.0:8002\n",
            "INFO:     Application startup complete.\n",
            "INFO:     Uvicorn running on http://0.0.0.0:8004 (Press CTRL+C to quit)\n",
            "INFO:     127.0.0.1:55428 - \"GET /health HTTP/1.1\" 200 OK\n",
            "\n",
            "\n",
            "--- /tmp/subagent_manager.log ---\n",
            "INFO:     Started server process [36805]\n",
            "INFO:     Waiting for application startup.\n",
            "INFO:     Application startup complete.\n",
            "INFO:     Uvicorn running on http://0.0.0.0:8003 (Press CTRL+C to quit)\n",
            "INFO:     127.0.0.1:49356 - \"GET /health HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:49372 - \"GET /health HTTP/1.1\" 200 OK\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ed8a78b8",
        "outputId": "240d673c-9aa7-4715-fd11-3921694d9d11"
      },
      "source": [
        "import subprocess, os\n",
        "\n",
        "print(\"=== PORT DIAGNOSTICS ===\")\n",
        "# Check what's listening on ports 9000 (MinIO) and 8004 (Code Exec)\n",
        "for port in [9000, 9001, 8004]:\n",
        "    print(f\"\\nChecking Port {port}...\")\n",
        "    # lsof -i :port\n",
        "    res = subprocess.run(f\"lsof -i :{port}\", shell=True, capture_output=True, text=True)\n",
        "    if res.stdout.strip():\n",
        "        print(res.stdout)\n",
        "    else:\n",
        "        print(\"  (No process found listening)\")\n",
        "\n",
        "print(\"\\n=== SERVICE LOGS (Last 50 lines) ===\")\n",
        "logs = [\"/tmp/minio.log\", \"/tmp/code_exec.log\", \"/tmp/memory_service.log\"]\n",
        "for log in logs:\n",
        "    print(f\"\\n--- {log} ---\")\n",
        "    if os.path.exists(log):\n",
        "        # check file size\n",
        "        size = os.path.getsize(log)\n",
        "        print(f\"  Size: {size} bytes\")\n",
        "        if size > 0:\n",
        "            subprocess.run(f\"tail -n 50 {log}\", shell=True)\n",
        "        else:\n",
        "            print(\"  (Empty file)\")\n",
        "    else:\n",
        "        print(\"  (File does not exist)\")"
      ],
      "id": "ed8a78b8",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== PORT DIAGNOSTICS ===\n",
            "\n",
            "Checking Port 9000...\n",
            "COMMAND   PID USER   FD   TYPE DEVICE SIZE/OFF NODE NAME\n",
            "kernel_ma  12 root    9u  IPv4 549882      0t0  TCP b2412b48cfa2:57236->b2412b48cfa2:9000 (ESTABLISHED)\n",
            "kernel_ma  12 root   10u  IPv4 550931      0t0  TCP b2412b48cfa2:57244->b2412b48cfa2:9000 (ESTABLISHED)\n",
            "jupyter-s 101 root    7u  IPv4 549865      0t0  TCP b2412b48cfa2:9000 (LISTEN)\n",
            "jupyter-s 101 root    8u  IPv4 549883      0t0  TCP b2412b48cfa2:9000->b2412b48cfa2:57236 (ESTABLISHED)\n",
            "jupyter-s 101 root   16u  IPv4 550932      0t0  TCP b2412b48cfa2:9000->b2412b48cfa2:57244 (ESTABLISHED)\n",
            "\n",
            "\n",
            "Checking Port 9001...\n",
            "COMMAND   PID USER   FD   TYPE  DEVICE SIZE/OFF NODE NAME\n",
            "minio   36767 root    6u  IPv6 1369528      0t0  TCP *:9001 (LISTEN)\n",
            "\n",
            "\n",
            "Checking Port 8004...\n",
            "COMMAND   PID USER   FD   TYPE  DEVICE SIZE/OFF NODE NAME\n",
            "python3 36793 root   13u  IPv4 1369748      0t0  TCP *:8004 (LISTEN)\n",
            "\n",
            "\n",
            "=== SERVICE LOGS (Last 50 lines) ===\n",
            "\n",
            "--- /tmp/minio.log ---\n",
            "  Size: 496 bytes\n",
            "\n",
            "--- /tmp/code_exec.log ---\n",
            "  Size: 911 bytes\n",
            "\n",
            "--- /tmp/memory_service.log ---\n",
            "  Size: 34767 bytes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "94b7a06a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "94b7a06a",
        "outputId": "6d08d464-c49d-4f31-c7fc-f13d7e2d6160"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "PHASE 5: EXTERNAL ACCESS\n",
            "============================================================\n",
            "\n",
            "‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n",
            "‚ïë  üöÄ SYSTEM READY - ACCESS LINKS                         ‚ïë\n",
            "‚ï†‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï£\n",
            "‚ïë  üìä Dashboard: https://unliquid-blithely-glenda.ngrok-free.dev‚ïë\n",
            "‚ïë  üîå API:       https://unliquid-blithely-glenda.ngrok-free.dev‚ïë\n",
            "‚ïë  üìÑ Docs:      https://unliquid-blithely-glenda.ngrok-free.dev/docs‚ïë\n",
            "‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# ‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n",
        "# ‚ïë  PHASE 5: External Access (ngrok Tunnels)                   ‚ïë\n",
        "# ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n",
        "import os, time\n",
        "from pyngrok import ngrok, conf\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"PHASE 5: EXTERNAL ACCESS\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Configuration\n",
        "NGROK_AUTH_TOKEN = \"39MaIP07IiJMHPNDgd3raMEOL6r_2KyacFVXP68bbxBu9s8E8\"\n",
        "\n",
        "if NGROK_AUTH_TOKEN:\n",
        "    ngrok.set_auth_token(NGROK_AUTH_TOKEN)\n",
        "    ngrok.kill()\n",
        "    time.sleep(1)\n",
        "\n",
        "    # Main Tunnel (API + Dashboard on 8000)\n",
        "    public_tunnel = ngrok.connect(8000, \"http\")\n",
        "    public_url = public_tunnel.public_url\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\")\n",
        "    print(\"‚ïë  üöÄ SYSTEM READY - ACCESS LINKS                         ‚ïë\")\n",
        "    print(\"‚ï†‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï£\")\n",
        "    print(f\"‚ïë  üìä Dashboard: {public_url:<41s}‚ïë\")\n",
        "    print(f\"‚ïë  üîå API:       {public_url:<41s}‚ïë\")\n",
        "    print(f\"‚ïë  üìÑ Docs:      {public_url + '/docs':<41s}‚ïë\")\n",
        "    print(\"‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\")\n",
        "else:\n",
        "    print(\"‚ùå No ngrok token found. Services available locally only.\")\n",
        "\n",
        "print(\"=\" * 60)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4658f5ae",
        "outputId": "c5d7874a-159f-4099-c22d-ca47dd98518a"
      },
      "source": [
        "import subprocess, os\n",
        "\n",
        "print(\"=== PORT CHECK ===\")\n",
        "# Check ports 3000 (Dashboard) and 8080 (MCP)\n",
        "for port in [3000, 8080]:\n",
        "    res = subprocess.run(f\"lsof -i :{port}\", shell=True, capture_output=True, text=True)\n",
        "    print(f\"\\n[:{port}] {'OPEN' if res.stdout.strip() else 'CLOSED'}\")\n",
        "    if res.stdout.strip():\n",
        "        print(res.stdout)\n",
        "\n",
        "print(\"\\n=== LOGS ===\")\n",
        "logs = [\"/tmp/dashboard.log\", \"/tmp/mcp_gateway.log\"]\n",
        "for log in logs:\n",
        "    print(f\"\\n--- {log} ---\")\n",
        "    if os.path.exists(log):\n",
        "        subprocess.run(f\"tail -n 50 {log}\", shell=True)\n",
        "    else:\n",
        "        print(\"(File not found)\")"
      ],
      "id": "4658f5ae",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== PORT CHECK ===\n",
            "\n",
            "[:3000] CLOSED\n",
            "\n",
            "[:8080] OPEN\n",
            "COMMAND PID USER   FD   TYPE  DEVICE SIZE/OFF NODE NAME\n",
            "node      7 root   21u  IPv6  549965      0t0  TCP *:http-alt (LISTEN)\n",
            "node      7 root   26u  IPv6  550927      0t0  TCP b2412b48cfa2:http-alt->172.28.0.1:49222 (ESTABLISHED)\n",
            "node      7 root   28u  IPv6 1373854      0t0  TCP b2412b48cfa2:http-alt->172.28.0.1:51090 (ESTABLISHED)\n",
            "\n",
            "\n",
            "=== LOGS ===\n",
            "\n",
            "--- /tmp/dashboard.log ---\n",
            "\n",
            "--- /tmp/mcp_gateway.log ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "b927a8c7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b927a8c7",
        "outputId": "4753d152-8811-4c78-c6f3-58b494e2fe24"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "PHASE 6: SMOKE TEST\n",
            "============================================================\n",
            "  [PASS] Orchestrator (200)\n",
            "  [PASS] MCP Gateway (200)\n",
            "  [PASS] Code Exec (200)\n",
            "\n",
            "  Testing AI Inference... OK (54.4s)\n",
            "\n",
            "  ‚úÖ ALL SYSTEMS GO!\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# ‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n",
        "# ‚ïë  PHASE 6: Quick Smoke Test                                  ‚ïë\n",
        "# ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n",
        "import json, urllib.request, time\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"PHASE 6: SMOKE TEST\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Verify Health\n",
        "checks = [\n",
        "    (\"Orchestrator\", \"http://localhost:8000/health\"),\n",
        "    (\"MCP Gateway\",  \"http://localhost:8082/health\"),\n",
        "    (\"Code Exec\",    \"http://localhost:8004/health\")\n",
        "]\n",
        "for name, url in checks:\n",
        "    try:\n",
        "        code = urllib.request.urlopen(url, timeout=5).getcode()\n",
        "        print(f\"  [PASS] {name} ({code})\")\n",
        "    except Exception as e:\n",
        "        print(f\"  [WARN] {name} ({e})\")\n",
        "\n",
        "# Verify Inference\n",
        "print(\"\\n  Testing AI Inference...\", end=\" \", flush=True)\n",
        "try:\n",
        "    t0 = time.time()\n",
        "    data = json.dumps({\"model\": \"deepseek-r1:14b\", \"prompt\": \"Hello!\", \"stream\": False}).encode()\n",
        "    req = urllib.request.Request(\"http://localhost:11434/api/generate\", data=data, headers={\"Content-Type\": \"application/json\"})\n",
        "    urllib.request.urlopen(req, timeout=120)\n",
        "    print(f\"OK ({time.time()-t0:.1f}s)\")\n",
        "    print(\"\\n  ‚úÖ ALL SYSTEMS GO!\")\n",
        "except Exception as e:\n",
        "    print(f\"FAIL ({e})\")\n",
        "print(\"=\" * 60)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bc99dfa4",
        "outputId": "3122fbe2-ac14-4941-c871-1e092a62ff04"
      },
      "source": [
        "import subprocess\n",
        "\n",
        "print(\"=== CHECKING SERVICE LOGS FOR ERRORS ===\")\n",
        "services = [\n",
        "    \"/tmp/orchestrator.log\",\n",
        "    \"/tmp/memory_service.log\",\n",
        "    \"/tmp/code_exec.log\",\n",
        "    \"/tmp/mcp_gateway.log\"\n",
        "]\n",
        "\n",
        "for log in services:\n",
        "    print(f\"\\n--- {log} ---\")\n",
        "    # Check if file exists first\n",
        "    try:\n",
        "        # Print last 30 lines of the log\n",
        "        result = subprocess.run([\"tail\", \"-n\", \"30\", log], capture_output=True, text=True)\n",
        "        print(result.stdout)\n",
        "        if result.stderr:\n",
        "            print(\"STDERR:\", result.stderr)\n",
        "    except Exception as e:\n",
        "        print(f\"Could not read log: {e}\")\n"
      ],
      "id": "bc99dfa4",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== CHECKING SERVICE LOGS FOR ERRORS ===\n",
            "\n",
            "--- /tmp/orchestrator.log ---\n",
            "INFO:     Started server process [36820]\n",
            "INFO:     Waiting for application startup.\n",
            "2026-02-08 04:26:56,070 - orchestrator.service.main - INFO - Starting Lead Agent/Orchestrator service...\n",
            "2026-02-08 04:26:56,076 - orchestrator.service.main - INFO - Configuration: LLM Provider=local\n",
            "2026-02-08 04:26:56,076 - orchestrator.service.main - INFO - MCP Gateway URL: http://localhost:8082\n",
            "2026-02-08 04:26:56,076 - orchestrator.service.main - INFO - Memory Service URL: http://localhost:8002\n",
            "2026-02-08 04:26:56,319 - orchestrator.service.main - INFO - WebSocket manager initialized\n",
            "2026-02-08 04:26:56,323 - orchestrator.service.session_storage - INFO - Connected to Redis at redis://localhost:6379/0\n",
            "2026-02-08 04:26:56,324 - orchestrator.service.agent - INFO - Session storage initialized\n",
            "2026-02-08 04:26:56,324 - orchestrator.service.memory_learning - INFO - MemoryLearningClient initialized: memory_dir=/content/ai_final/agentic-framework-main/workspace/.copilot/memory\n",
            "2026-02-08 04:26:56,324 - orchestrator.service.agent_manager - INFO - Memory learning client initialized\n",
            "2026-02-08 04:26:56,324 - orchestrator.service.agent_manager - INFO - Agent manager started\n",
            "2026-02-08 04:26:56,324 - orchestrator.service.agent - INFO - Agent manager initialized\n",
            "2026-02-08 04:26:56,324 - orchestrator.service.agent - INFO - OrchestratorAgent fully initialized\n",
            "2026-02-08 04:26:56,324 - orchestrator.service.main - INFO - Orchestrator agent initialized with persistent storage\n",
            "2026-02-08 04:26:56,324 - orchestrator.service.main - INFO - Orchestrator service started successfully\n",
            "INFO:     Application startup complete.\n",
            "INFO:     Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit)\n",
            "2026-02-08 04:27:20,207 - httpx - INFO - HTTP Request: GET http://localhost:8082/health \"HTTP/1.1 200 OK\"\n",
            "2026-02-08 04:27:20,210 - httpx - INFO - HTTP Request: GET http://localhost:8002/health \"HTTP/1.1 200 OK\"\n",
            "2026-02-08 04:27:20,213 - httpx - INFO - HTTP Request: GET http://localhost:8003/health \"HTTP/1.1 200 OK\"\n",
            "INFO:     127.0.0.1:48688 - \"GET /health HTTP/1.1\" 200 OK\n",
            "2026-02-08 04:27:22,836 - httpx - INFO - HTTP Request: GET http://localhost:8082/health \"HTTP/1.1 200 OK\"\n",
            "2026-02-08 04:27:22,839 - httpx - INFO - HTTP Request: GET http://localhost:8002/health \"HTTP/1.1 200 OK\"\n",
            "2026-02-08 04:27:22,843 - httpx - INFO - HTTP Request: GET http://localhost:8003/health \"HTTP/1.1 200 OK\"\n",
            "INFO:     127.0.0.1:48702 - \"GET /health HTTP/1.1\" 200 OK\n",
            "\n",
            "\n",
            "--- /tmp/memory_service.log ---\n",
            "INFO:httpx:HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/sentence_bert_config.json \"HTTP/1.1 307 Temporary Redirect\"\n",
            "INFO:httpx:HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/sentence_bert_config.json \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/adapter_config.json \"HTTP/1.1 404 Not Found\"\n",
            "INFO:httpx:HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/config.json \"HTTP/1.1 307 Temporary Redirect\"\n",
            "INFO:httpx:HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config.json \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/config.json \"HTTP/1.1 307 Temporary Redirect\"\n",
            "INFO:httpx:HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config.json \"HTTP/1.1 200 OK\"\n",
            "\n",
            "Loading weights:   0%|          | 0/103 [00:00<?, ?it/s]\n",
            "Loading weights:   1%|          | 1/103 [00:00<00:00, 29959.31it/s, Materializing param=embeddings.LayerNorm.bias]\n",
            "Loading weights:   1%|          | 1/103 [00:00<00:00, 6887.20it/s, Materializing param=embeddings.LayerNorm.bias] \n",
            "Loading weights:   2%|‚ñè         | 2/103 [00:00<00:00, 5440.08it/s, Materializing param=embeddings.LayerNorm.weight]\n",
            "Loading weights:   2%|‚ñè         | 2/103 [00:00<00:00, 4146.62it/s, Materializing param=embeddings.LayerNorm.weight]\n",
            "Loading weights:   3%|‚ñé         | 3/103 [00:00<00:00, 4482.69it/s, Materializing param=embeddings.position_embeddings.weight]\n",
            "Loading weights:   3%|‚ñé         | 3/103 [00:00<00:00, 3960.63it/s, Materializing param=embeddings.position_embeddings.weight]\n",
            "Loading weights:   4%|‚ñç         | 4/103 [00:00<00:00, 4447.83it/s, Materializing param=embeddings.token_type_embeddings.weight]\n",
            "Loading weights:   4%|‚ñç         | 4/103 [00:00<00:00, 4027.18it/s, Materializing param=embeddings.token_type_embeddings.weight]\n",
            "Loading weights:   5%|‚ñç         | 5/103 [00:00<00:00, 4362.70it/s, Materializing param=embeddings.word_embeddings.weight]      \n",
            "Loading weights:   5%|‚ñç         | 5/103 [00:00<00:00, 4068.19it/s, Materializing param=embeddings.word_embeddings.weight]\n",
            "Loading weights:   6%|‚ñå         | 6/103 [00:00<00:00, 4402.70it/s, Materializing param=encoder.layer.0.attention.output.LayerNorm.bias]\n",
            "Loading weights:   6%|‚ñå         | 6/103 [00:00<00:00, 4152.78it/s, Materializing param=encoder.layer.0.attention.output.LayerNorm.bias]\n",
            "Loading weights:   7%|‚ñã         | 7/103 [00:00<00:00, 922.11it/s, Materializing param=encoder.layer.0.attention.output.LayerNorm.weight]\n",
            "Loading weights:   7%|‚ñã         | 7/103 [00:00<00:00, 906.79it/s, Materializing param=encoder.layer.0.attention.output.LayerNorm.weight]\n",
            "Loading weights:   8%|‚ñä         | 8/103 [00:00<00:00, 1014.68it/s, Materializing param=encoder.layer.0.attention.output.dense.bias]     \n",
            "Loading weights:   8%|‚ñä         | 8/103 [00:00<00:00, 1001.62it/s, Materializing param=encoder.layer.0.attention.output.dense.bias]\n",
            "Loading weights:   9%|‚ñä         | 9/103 [00:00<00:00, 1103.34it/s, Materializing param=encoder.layer.0.attention.output.dense.weight]\n",
            "Loading weights:   9%|‚ñä         | 9/103 [00:00<00:00, 1092.14it/s, Materializing param=encoder.layer.0.attention.output.dense.weight]\n",
            "Loading weights:  10%|‚ñâ         | 10/103 [00:00<00:00, 1192.21it/s, Materializing param=encoder.layer.0.attention.self.key.bias]     \n",
            "Loading weights:  10%|‚ñâ         | 10/103 [00:00<00:00, 1178.84it/s, Materializing param=encoder.layer.0.attention.self.key.bias]\n",
            "Loading weights:  11%|‚ñà         | 11/103 [00:00<00:00, 1272.75it/s, Materializing param=encoder.layer.0.attention.self.key.weight]\n",
            "Loading weights:  11%|‚ñà         | 11/103 [00:00<00:00, 1261.00it/s, Materializing param=encoder.layer.0.attention.self.key.weight]\n",
            "Loading weights:  12%|‚ñà‚ñè        | 12/103 [00:00<00:00, 1353.77it/s, Materializing param=encoder.layer.0.attention.self.query.bias]\n",
            "Loading weights:  12%|‚ñà‚ñè        | 12/103 [00:00<00:00, 1341.93it/s, Materializing param=encoder.layer.0.attention.self.query.bias]\n",
            "Loading weights:  13%|‚ñà‚ñé        | 13/103 [00:00<00:00, 1430.68it/s, Materializing param=encoder.layer.0.attention.self.query.weight]\n",
            "Loading weights:  13%|‚ñà‚ñé        | 13/103 [00:00<00:00, 1416.88it/s, Materializing param=encoder.layer.0.attention.self.query.weight]\n",
            "Loading weights:  14%|‚ñà‚ñé        | 14/103 [00:00<00:00, 1500.84it/s, Materializing param=encoder.layer.0.attention.self.value.bias]  \n",
            "Loading weights:  14%|‚ñà‚ñé        | 14/103 [00:00<00:00, 1487.94it/s, Materializing param=encoder.layer.0.attention.self.value.bias]\n",
            "Loading weights:  15%|‚ñà‚ñç        | 15/103 [00:00<00:00, 986.46it/s, Materializing param=encoder.layer.0.attention.self.value.weight]\n",
            "Loading weights:  15%|‚ñà‚ñç        | 15/103 [00:00<00:00, 978.38it/s, Materializing param=encoder.layer.0.attention.self.value.weight]\n",
            "Loading weights:  16%|‚ñà‚ñå        | 16/103 [00:00<00:00, 1029.91it/s, Materializing param=encoder.layer.0.intermediate.dense.bias]   \n",
            "Loading weights:  16%|‚ñà‚ñå        | 16/103 [00:00<00:00, 1023.56it/s, Materializing param=encoder.layer.0.intermediate.dense.bias]\n",
            "Loading weights:  17%|‚ñà‚ñã        | 17/103 [00:00<00:00, 1076.97it/s, Materializing param=encoder.layer.0.intermediate.dense.weight]\n",
            "Loading weights:  17%|‚ñà‚ñã        | 17/103 [00:00<00:00, 1071.31it/s, Materializing param=encoder.layer.0.intermediate.dense.weight]\n",
            "Loading weights:  17%|‚ñà‚ñã        | 18/103 [00:00<00:00, 1123.99it/s, Materializing param=encoder.layer.0.output.LayerNorm.bias]    \n",
            "Loading weights:  17%|‚ñà‚ñã        | 18/103 [00:00<00:00, 1118.41it/s, Materializing param=encoder.layer.0.output.LayerNorm.bias]\n",
            "Loading weights:  18%|‚ñà‚ñä        | 19/103 [00:00<00:00, 1169.36it/s, Materializing param=encoder.layer.0.output.LayerNorm.weight]\n",
            "Loading weights:  18%|‚ñà‚ñä        | 19/103 [00:00<00:00, 1163.06it/s, Materializing param=encoder.layer.0.output.LayerNorm.weight]\n",
            "Loading weights:  19%|‚ñà‚ñâ        | 20/103 [00:00<00:00, 906.02it/s, Materializing param=encoder.layer.0.output.dense.bias]       \n",
            "Loading weights:  19%|‚ñà‚ñâ        | 20/103 [00:00<00:00, 900.59it/s, Materializing param=encoder.layer.0.output.dense.bias]\n",
            "Loading weights:  20%|‚ñà‚ñà        | 21/103 [00:00<00:00, 937.54it/s, Materializing param=encoder.layer.0.output.dense.weight]\n",
            "Loading weights:  20%|‚ñà‚ñà        | 21/103 [00:00<00:00, 932.35it/s, Materializing param=encoder.layer.0.output.dense.weight]\n",
            "Loading weights:  21%|‚ñà‚ñà‚ñè       | 22/103 [00:00<00:00, 969.49it/s, Materializing param=encoder.layer.1.attention.output.LayerNorm.bias]\n",
            "Loading weights:  21%|‚ñà‚ñà‚ñè       | 22/103 [00:00<00:00, 965.89it/s, Materializing param=encoder.layer.1.attention.output.LayerNorm.bias]\n",
            "Loading weights:  22%|‚ñà‚ñà‚ñè       | 23/103 [00:00<00:00, 1003.09it/s, Materializing param=encoder.layer.1.attention.output.LayerNorm.weight]\n",
            "Loading weights:  22%|‚ñà‚ñà‚ñè       | 23/103 [00:00<00:00, 999.42it/s, Materializing param=encoder.layer.1.attention.output.LayerNorm.weight] \n",
            "Loading weights:  23%|‚ñà‚ñà‚ñé       | 24/103 [00:00<00:00, 1036.00it/s, Materializing param=encoder.layer.1.attention.output.dense.bias]     \n",
            "Loading weights:  23%|‚ñà‚ñà‚ñé       | 24/103 [00:00<00:00, 1032.34it/s, Materializing param=encoder.layer.1.attention.output.dense.bias]\n",
            "Loading weights:  24%|‚ñà‚ñà‚ñç       | 25/103 [00:00<00:00, 1068.87it/s, Materializing param=encoder.layer.1.attention.output.dense.weight]\n",
            "Loading weights:  24%|‚ñà‚ñà‚ñç       | 25/103 [00:00<00:00, 1063.89it/s, Materializing param=encoder.layer.1.attention.output.dense.weight]\n",
            "Loading weights:  25%|‚ñà‚ñà‚ñå       | 26/103 [00:00<00:00, 866.72it/s, Materializing param=encoder.layer.1.attention.self.key.bias]       \n",
            "Loading weights:  25%|‚ñà‚ñà‚ñå       | 26/103 [00:00<00:00, 863.18it/s, Materializing param=encoder.layer.1.attention.self.key.bias]\n",
            "Loading weights:  26%|‚ñà‚ñà‚ñå       | 27/103 [00:00<00:00, 890.99it/s, Materializing param=encoder.layer.1.attention.self.key.weight]\n",
            "Loading weights:  26%|‚ñà‚ñà‚ñå       | 27/103 [00:00<00:00, 888.49it/s, Materializing param=encoder.layer.1.attention.self.key.weight]\n",
            "Loading weights:  27%|‚ñà‚ñà‚ñã       | 28/103 [00:00<00:00, 915.78it/s, Materializing param=encoder.layer.1.attention.self.query.bias]\n",
            "Loading weights:  27%|‚ñà‚ñà‚ñã       | 28/103 [00:00<00:00, 913.07it/s, Materializing param=encoder.layer.1.attention.self.query.bias]\n",
            "Loading weights:  28%|‚ñà‚ñà‚ñä       | 29/103 [00:00<00:00, 940.85it/s, Materializing param=encoder.layer.1.attention.self.query.weight]\n",
            "Loading weights:  28%|‚ñà‚ñà‚ñä       | 29/103 [00:00<00:00, 938.31it/s, Materializing param=encoder.layer.1.attention.self.query.weight]\n",
            "Loading weights:  29%|‚ñà‚ñà‚ñâ       | 30/103 [00:00<00:00, 966.08it/s, Materializing param=encoder.layer.1.attention.self.value.bias]  \n",
            "Loading weights:  29%|‚ñà‚ñà‚ñâ       | 30/103 [00:00<00:00, 963.69it/s, Materializing param=encoder.layer.1.attention.self.value.bias]\n",
            "Loading weights:  30%|‚ñà‚ñà‚ñà       | 31/103 [00:00<00:00, 991.09it/s, Materializing param=encoder.layer.1.attention.self.value.weight]\n",
            "Loading weights:  30%|‚ñà‚ñà‚ñà       | 31/103 [00:00<00:00, 988.64it/s, Materializing param=encoder.layer.1.attention.self.value.weight]\n",
            "Loading weights:  31%|‚ñà‚ñà‚ñà       | 32/103 [00:00<00:00, 832.39it/s, Materializing param=encoder.layer.1.intermediate.dense.bias]    \n",
            "Loading weights:  31%|‚ñà‚ñà‚ñà       | 32/103 [00:00<00:00, 829.40it/s, Materializing param=encoder.layer.1.intermediate.dense.bias]\n",
            "Loading weights:  32%|‚ñà‚ñà‚ñà‚ñè      | 33/103 [00:00<00:00, 851.30it/s, Materializing param=encoder.layer.1.intermediate.dense.weight]\n",
            "Loading weights:  32%|‚ñà‚ñà‚ñà‚ñè      | 33/103 [00:00<00:00, 849.40it/s, Materializing param=encoder.layer.1.intermediate.dense.weight]\n",
            "Loading weights:  33%|‚ñà‚ñà‚ñà‚ñé      | 34/103 [00:00<00:00, 871.79it/s, Materializing param=encoder.layer.1.output.LayerNorm.bias]    \n",
            "Loading weights:  33%|‚ñà‚ñà‚ñà‚ñé      | 34/103 [00:00<00:00, 869.53it/s, Materializing param=encoder.layer.1.output.LayerNorm.bias]\n",
            "Loading weights:  34%|‚ñà‚ñà‚ñà‚ñç      | 35/103 [00:00<00:00, 891.39it/s, Materializing param=encoder.layer.1.output.LayerNorm.weight]\n",
            "Loading weights:  34%|‚ñà‚ñà‚ñà‚ñç      | 35/103 [00:00<00:00, 889.58it/s, Materializing param=encoder.layer.1.output.LayerNorm.weight]\n",
            "Loading weights:  35%|‚ñà‚ñà‚ñà‚ñç      | 36/103 [00:00<00:00, 911.45it/s, Materializing param=encoder.layer.1.output.dense.bias]      \n",
            "Loading weights:  35%|‚ñà‚ñà‚ñà‚ñç      | 36/103 [00:00<00:00, 909.47it/s, Materializing param=encoder.layer.1.output.dense.bias]\n",
            "Loading weights:  36%|‚ñà‚ñà‚ñà‚ñå      | 37/103 [00:00<00:00, 931.39it/s, Materializing param=encoder.layer.1.output.dense.weight]\n",
            "Loading weights:  36%|‚ñà‚ñà‚ñà‚ñå      | 37/103 [00:00<00:00, 929.61it/s, Materializing param=encoder.layer.1.output.dense.weight]\n",
            "Loading weights:  37%|‚ñà‚ñà‚ñà‚ñã      | 38/103 [00:00<00:00, 951.50it/s, Materializing param=encoder.layer.2.attention.output.LayerNorm.bias]\n",
            "Loading weights:  37%|‚ñà‚ñà‚ñà‚ñã      | 38/103 [00:00<00:00, 949.59it/s, Materializing param=encoder.layer.2.attention.output.LayerNorm.bias]\n",
            "Loading weights:  38%|‚ñà‚ñà‚ñà‚ñä      | 39/103 [00:00<00:00, 833.77it/s, Materializing param=encoder.layer.2.attention.output.LayerNorm.weight]\n",
            "Loading weights:  38%|‚ñà‚ñà‚ñà‚ñä      | 39/103 [00:00<00:00, 831.41it/s, Materializing param=encoder.layer.2.attention.output.LayerNorm.weight]\n",
            "Loading weights:  39%|‚ñà‚ñà‚ñà‚ñâ      | 40/103 [00:00<00:00, 849.55it/s, Materializing param=encoder.layer.2.attention.output.dense.bias]      \n",
            "Loading weights:  39%|‚ñà‚ñà‚ñà‚ñâ      | 40/103 [00:00<00:00, 847.82it/s, Materializing param=encoder.layer.2.attention.output.dense.bias]\n",
            "Loading weights:  40%|‚ñà‚ñà‚ñà‚ñâ      | 41/103 [00:00<00:00, 866.24it/s, Materializing param=encoder.layer.2.attention.output.dense.weight]\n",
            "Loading weights:  40%|‚ñà‚ñà‚ñà‚ñâ      | 41/103 [00:00<00:00, 864.54it/s, Materializing param=encoder.layer.2.attention.output.dense.weight]\n",
            "Loading weights:  41%|‚ñà‚ñà‚ñà‚ñà      | 42/103 [00:00<00:00, 882.31it/s, Materializing param=encoder.layer.2.attention.self.key.bias]      \n",
            "Loading weights:  41%|‚ñà‚ñà‚ñà‚ñà      | 42/103 [00:00<00:00, 880.80it/s, Materializing param=encoder.layer.2.attention.self.key.bias]\n",
            "Loading weights:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 43/103 [00:00<00:00, 899.08it/s, Materializing param=encoder.layer.2.attention.self.key.weight]\n",
            "Loading weights:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 43/103 [00:00<00:00, 897.61it/s, Materializing param=encoder.layer.2.attention.self.key.weight]\n",
            "Loading weights:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 44/103 [00:00<00:00, 915.63it/s, Materializing param=encoder.layer.2.attention.self.query.bias]\n",
            "Loading weights:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 44/103 [00:00<00:00, 914.16it/s, Materializing param=encoder.layer.2.attention.self.query.bias]\n",
            "Loading weights:  44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 45/103 [00:00<00:00, 829.77it/s, Materializing param=encoder.layer.2.attention.self.query.weight]\n",
            "Loading weights:  44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 45/103 [00:00<00:00, 827.84it/s, Materializing param=encoder.layer.2.attention.self.query.weight]\n",
            "Loading weights:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 46/103 [00:00<00:00, 843.30it/s, Materializing param=encoder.layer.2.attention.self.value.bias]  \n",
            "Loading weights:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 46/103 [00:00<00:00, 841.85it/s, Materializing param=encoder.layer.2.attention.self.value.bias]\n",
            "Loading weights:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 47/103 [00:00<00:00, 857.57it/s, Materializing param=encoder.layer.2.attention.self.value.weight]\n",
            "Loading weights:  46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 47/103 [00:00<00:00, 856.30it/s, Materializing param=encoder.layer.2.attention.self.value.weight]\n",
            "Loading weights:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 48/103 [00:00<00:00, 872.20it/s, Materializing param=encoder.layer.2.intermediate.dense.bias]    \n",
            "Loading weights:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 48/103 [00:00<00:00, 870.94it/s, Materializing param=encoder.layer.2.intermediate.dense.bias]\n",
            "Loading weights:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 49/103 [00:00<00:00, 789.30it/s, Materializing param=encoder.layer.2.intermediate.dense.weight]\n",
            "Loading weights:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 49/103 [00:00<00:00, 787.57it/s, Materializing param=encoder.layer.2.intermediate.dense.weight]\n",
            "Loading weights:  49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 50/103 [00:00<00:00, 801.32it/s, Materializing param=encoder.layer.2.output.LayerNorm.bias]    \n",
            "Loading weights:  49%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 50/103 [00:00<00:00, 799.66it/s, Materializing param=encoder.layer.2.output.LayerNorm.bias]\n",
            "Loading weights:  50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 51/103 [00:00<00:00, 813.18it/s, Materializing param=encoder.layer.2.output.LayerNorm.weight]\n",
            "Loading weights:  50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 51/103 [00:00<00:00, 811.99it/s, Materializing param=encoder.layer.2.output.LayerNorm.weight]\n",
            "Loading weights:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 52/103 [00:00<00:00, 825.72it/s, Materializing param=encoder.layer.2.output.dense.bias]      \n",
            "Loading weights:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 52/103 [00:00<00:00, 824.55it/s, Materializing param=encoder.layer.2.output.dense.bias]\n",
            "Loading weights:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 53/103 [00:00<00:00, 838.14it/s, Materializing param=encoder.layer.2.output.dense.weight]\n",
            "Loading weights:  51%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 53/103 [00:00<00:00, 836.95it/s, Materializing param=encoder.layer.2.output.dense.weight]\n",
            "Loading weights:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 54/103 [00:00<00:00, 766.51it/s, Materializing param=encoder.layer.3.attention.output.LayerNorm.bias]\n",
            "Loading weights:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 54/103 [00:00<00:00, 764.59it/s, Materializing param=encoder.layer.3.attention.output.LayerNorm.bias]\n",
            "Loading weights:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 55/103 [00:00<00:00, 775.79it/s, Materializing param=encoder.layer.3.attention.output.LayerNorm.weight]\n",
            "Loading weights:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 55/103 [00:00<00:00, 774.55it/s, Materializing param=encoder.layer.3.attention.output.LayerNorm.weight]\n",
            "Loading weights:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 56/103 [00:00<00:00, 786.20it/s, Materializing param=encoder.layer.3.attention.output.dense.bias]      \n",
            "Loading weights:  54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 56/103 [00:00<00:00, 785.03it/s, Materializing param=encoder.layer.3.attention.output.dense.bias]\n",
            "Loading weights:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 57/103 [00:00<00:00, 736.84it/s, Materializing param=encoder.layer.3.attention.output.dense.weight]\n",
            "Loading weights:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 57/103 [00:00<00:00, 735.40it/s, Materializing param=encoder.layer.3.attention.output.dense.weight]\n",
            "Loading weights:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 58/103 [00:00<00:00, 746.37it/s, Materializing param=encoder.layer.3.attention.self.key.bias]      \n",
            "Loading weights:  56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 58/103 [00:00<00:00, 745.53it/s, Materializing param=encoder.layer.3.attention.self.key.bias]\n",
            "Loading weights:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 59/103 [00:00<00:00, 756.86it/s, Materializing param=encoder.layer.3.attention.self.key.weight]\n",
            "Loading weights:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 59/103 [00:00<00:00, 756.06it/s, Materializing param=encoder.layer.3.attention.self.key.weight]\n",
            "Loading weights:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 60/103 [00:00<00:00, 767.20it/s, Materializing param=encoder.layer.3.attention.self.query.bias]\n",
            "Loading weights:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 60/103 [00:00<00:00, 766.37it/s, Materializing param=encoder.layer.3.attention.self.query.bias]\n",
            "Loading weights:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 61/103 [00:00<00:00, 777.71it/s, Materializing param=encoder.layer.3.attention.self.query.weight]\n",
            "Loading weights:  59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 61/103 [00:00<00:00, 714.87it/s, Materializing param=encoder.layer.3.attention.self.query.weight]\n",
            "Loading weights:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 62/103 [00:00<00:00, 724.30it/s, Materializing param=encoder.layer.3.attention.self.value.bias]  \n",
            "Loading weights:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 62/103 [00:00<00:00, 723.26it/s, Materializing param=encoder.layer.3.attention.self.value.bias]\n",
            "Loading weights:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 63/103 [00:00<00:00, 733.26it/s, Materializing param=encoder.layer.3.attention.self.value.weight]\n",
            "Loading weights:  61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 63/103 [00:00<00:00, 732.42it/s, Materializing param=encoder.layer.3.attention.self.value.weight]\n",
            "Loading weights:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 64/103 [00:00<00:00, 742.63it/s, Materializing param=encoder.layer.3.intermediate.dense.bias]    \n",
            "Loading weights:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 64/103 [00:00<00:00, 741.92it/s, Materializing param=encoder.layer.3.intermediate.dense.bias]\n",
            "Loading weights:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 65/103 [00:00<00:00, 752.27it/s, Materializing param=encoder.layer.3.intermediate.dense.weight]\n",
            "Loading weights:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 65/103 [00:00<00:00, 751.27it/s, Materializing param=encoder.layer.3.intermediate.dense.weight]\n",
            "Loading weights:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 66/103 [00:00<00:00, 761.47it/s, Materializing param=encoder.layer.3.output.LayerNorm.bias]    \n",
            "Loading weights:  64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 66/103 [00:00<00:00, 760.78it/s, Materializing param=encoder.layer.3.output.LayerNorm.bias]\n",
            "Loading weights:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 67/103 [00:00<00:00, 771.08it/s, Materializing param=encoder.layer.3.output.LayerNorm.weight]\n",
            "Loading weights:  65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 67/103 [00:00<00:00, 770.37it/s, Materializing param=encoder.layer.3.output.LayerNorm.weight]\n",
            "Loading weights:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 68/103 [00:00<00:00, 780.68it/s, Materializing param=encoder.layer.3.output.dense.bias]      \n",
            "Loading weights:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 68/103 [00:00<00:00, 779.93it/s, Materializing param=encoder.layer.3.output.dense.bias]\n",
            "Loading weights:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 69/103 [00:00<00:00, 790.17it/s, Materializing param=encoder.layer.3.output.dense.weight]\n",
            "Loading weights:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 69/103 [00:00<00:00, 789.49it/s, Materializing param=encoder.layer.3.output.dense.weight]\n",
            "Loading weights:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 70/103 [00:00<00:00, 744.98it/s, Materializing param=encoder.layer.4.attention.output.LayerNorm.bias]\n",
            "Loading weights:  68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 70/103 [00:00<00:00, 744.01it/s, Materializing param=encoder.layer.4.attention.output.LayerNorm.bias]\n",
            "Loading weights:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 71/103 [00:00<00:00, 753.14it/s, Materializing param=encoder.layer.4.attention.output.LayerNorm.weight]\n",
            "Loading weights:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 71/103 [00:00<00:00, 752.36it/s, Materializing param=encoder.layer.4.attention.output.LayerNorm.weight]\n",
            "Loading weights:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 72/103 [00:00<00:00, 761.29it/s, Materializing param=encoder.layer.4.attention.output.dense.bias]      \n",
            "Loading weights:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 72/103 [00:00<00:00, 760.54it/s, Materializing param=encoder.layer.4.attention.output.dense.bias]\n",
            "Loading weights:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 73/103 [00:00<00:00, 769.85it/s, Materializing param=encoder.layer.4.attention.output.dense.weight]\n",
            "Loading weights:  71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 73/103 [00:00<00:00, 769.16it/s, Materializing param=encoder.layer.4.attention.output.dense.weight]\n",
            "Loading weights:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 74/103 [00:00<00:00, 778.38it/s, Materializing param=encoder.layer.4.attention.self.key.bias]      \n",
            "Loading weights:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 74/103 [00:00<00:00, 777.64it/s, Materializing param=encoder.layer.4.attention.self.key.bias]\n",
            "Loading weights:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 75/103 [00:00<00:00, 786.95it/s, Materializing param=encoder.layer.4.attention.self.key.weight]\n",
            "Loading weights:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 75/103 [00:00<00:00, 786.33it/s, Materializing param=encoder.layer.4.attention.self.key.weight]\n",
            "Loading weights:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 76/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.4.attention.self.key.weight]\n",
            "Loading weights:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 76/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.4.attention.self.query.bias]\n",
            "Loading weights:  74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 76/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.4.attention.self.query.bias]\n",
            "Loading weights:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 77/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.4.attention.self.query.weight]\n",
            "Loading weights:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 77/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.4.attention.self.query.weight]\n",
            "Loading weights:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 78/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.4.attention.self.value.bias]  \n",
            "Loading weights:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 78/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.4.attention.self.value.bias]\n",
            "Loading weights:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 79/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.4.attention.self.value.weight]\n",
            "Loading weights:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 79/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.4.attention.self.value.weight]\n",
            "Loading weights:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 80/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.4.intermediate.dense.bias]    \n",
            "Loading weights:  78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 80/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.4.intermediate.dense.bias]\n",
            "Loading weights:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 81/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.4.intermediate.dense.weight]\n",
            "Loading weights:  79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 81/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.4.intermediate.dense.weight]\n",
            "Loading weights:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 82/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.4.output.LayerNorm.bias]    \n",
            "Loading weights:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 82/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.4.output.LayerNorm.bias]\n",
            "Loading weights:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 83/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.4.output.LayerNorm.weight]\n",
            "Loading weights:  81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 83/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.4.output.LayerNorm.weight]\n",
            "Loading weights:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 84/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.4.output.dense.bias]      \n",
            "Loading weights:  82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 84/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.4.output.dense.bias]\n",
            "Loading weights:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 85/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.4.output.dense.weight]\n",
            "Loading weights:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 85/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.4.output.dense.weight]\n",
            "Loading weights:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 86/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.5.attention.output.LayerNorm.bias]\n",
            "Loading weights:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 86/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.5.attention.output.LayerNorm.bias]\n",
            "Loading weights:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 87/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.5.attention.output.LayerNorm.weight]\n",
            "Loading weights:  84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 87/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.5.attention.output.LayerNorm.weight]\n",
            "Loading weights:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 88/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.5.attention.output.dense.bias]      \n",
            "Loading weights:  85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 88/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.5.attention.output.dense.bias]\n",
            "Loading weights:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 89/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.5.attention.output.dense.weight]\n",
            "Loading weights:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 89/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.5.attention.output.dense.weight]\n",
            "Loading weights:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 90/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.5.attention.self.key.bias]      \n",
            "Loading weights:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 90/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.5.attention.self.key.bias]\n",
            "Loading weights:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 91/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.5.attention.self.key.weight]\n",
            "Loading weights:  88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 91/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.5.attention.self.key.weight]\n",
            "Loading weights:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 92/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.5.attention.self.query.bias]\n",
            "Loading weights:  89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 92/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.5.attention.self.query.bias]\n",
            "Loading weights:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 93/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.5.attention.self.query.weight]\n",
            "Loading weights:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 93/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.5.attention.self.query.weight]\n",
            "Loading weights:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 94/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.5.attention.self.value.bias]  \n",
            "Loading weights:  91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 94/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.5.attention.self.value.bias]\n",
            "Loading weights:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 95/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.5.attention.self.value.weight]\n",
            "Loading weights:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 95/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.5.attention.self.value.weight]\n",
            "Loading weights:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 96/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.5.intermediate.dense.bias]    \n",
            "Loading weights:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 96/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.5.intermediate.dense.bias]\n",
            "Loading weights:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 97/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.5.intermediate.dense.weight]\n",
            "Loading weights:  94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 97/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.5.intermediate.dense.weight]\n",
            "Loading weights:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 98/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.5.output.LayerNorm.bias]    \n",
            "Loading weights:  95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 98/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.5.output.LayerNorm.bias]\n",
            "Loading weights:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 99/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.5.output.LayerNorm.weight]\n",
            "Loading weights:  96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 99/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.5.output.LayerNorm.weight]\n",
            "Loading weights:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 100/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.5.output.dense.bias]     \n",
            "Loading weights:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 100/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.5.output.dense.bias]\n",
            "Loading weights:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 101/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.5.output.dense.weight]\n",
            "Loading weights:  98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 101/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.5.output.dense.weight]\n",
            "Loading weights:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 102/103 [00:00<00:00, 748.11it/s, Materializing param=pooler.dense.bias]                  \n",
            "Loading weights:  99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 102/103 [00:00<00:00, 748.11it/s, Materializing param=pooler.dense.bias]\n",
            "Loading weights: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 103/103 [00:00<00:00, 748.11it/s, Materializing param=pooler.dense.weight]\n",
            "Loading weights: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 103/103 [00:00<00:00, 748.11it/s, Materializing param=pooler.dense.weight]\n",
            "Loading weights: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 103/103 [00:00<00:00, 782.15it/s, Materializing param=pooler.dense.weight]\n",
            "BertModel LOAD REPORT from: sentence-transformers/all-MiniLM-L6-v2\n",
            "Key                     | Status     |  | \n",
            "------------------------+------------+--+-\n",
            "embeddings.position_ids | UNEXPECTED |  | \n",
            "\n",
            "Notes:\n",
            "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n",
            "INFO:httpx:HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/config.json \"HTTP/1.1 307 Temporary Redirect\"\n",
            "INFO:httpx:HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config.json \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/tokenizer_config.json \"HTTP/1.1 307 Temporary Redirect\"\n",
            "INFO:httpx:HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/tokenizer_config.json \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: GET https://huggingface.co/api/models/sentence-transformers/all-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=false&expand=false \"HTTP/1.1 404 Not Found\"\n",
            "INFO:httpx:HTTP Request: GET https://huggingface.co/api/models/sentence-transformers/all-MiniLM-L6-v2/tree/main?recursive=true&expand=false \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/1_Pooling/config.json \"HTTP/1.1 307 Temporary Redirect\"\n",
            "INFO:httpx:HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/1_Pooling%2Fconfig.json \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: GET https://huggingface.co/api/models/sentence-transformers/all-MiniLM-L6-v2 \"HTTP/1.1 200 OK\"\n",
            "INFO:     Application startup complete.\n",
            "INFO:     Uvicorn running on http://0.0.0.0:8002 (Press CTRL+C to quit)\n",
            "Memory service started on 0.0.0.0:8001\n",
            "INFO:     127.0.0.1:53380 - \"GET /health HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:53382 - \"GET /health HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:53384 - \"GET /health HTTP/1.1\" 200 OK\n",
            "\n",
            "\n",
            "--- /tmp/code_exec.log ---\n",
            "INFO:     Started server process [36793]\n",
            "INFO:     Waiting for application startup.\n",
            "2026-02-08 04:26:51,538 - code_exec.service.main - INFO - Starting Code Executor Service\n",
            "2026-02-08 04:26:51,538 - code_exec.service.main - INFO - Skills directory: /Users/paragpradhan/Projects/Agent framework/agent-framework/code-exec/skills\n",
            "2026-02-08 04:26:51,543 - code_exec.service.registry - INFO - Loading skills from: /Users/paragpradhan/Projects/Agent framework/agent-framework/code-exec/skills\n",
            "2026-02-08 04:26:51,544 - code_exec.service.registry - INFO - Loaded 0 skills successfully\n",
            "2026-02-08 04:26:51,544 - code_exec.service.main - INFO - Loaded 0 skills\n",
            "2026-02-08 04:26:51,544 - code_exec.service.main - INFO - Service ready on 0.0.0.0:8002\n",
            "INFO:     Application startup complete.\n",
            "INFO:     Uvicorn running on http://0.0.0.0:8004 (Press CTRL+C to quit)\n",
            "INFO:     127.0.0.1:55428 - \"GET /health HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:55440 - \"GET /health HTTP/1.1\" 200 OK\n",
            "\n",
            "\n",
            "--- /tmp/mcp_gateway.log ---\n",
            "/content/ai_final/agentic-framework-main/mcp_gateway/service/models.py:209: UserWarning: Field name \"schema\" in \"ToolSchemaResponse\" shadows an attribute in parent \"BaseModel\"\n",
            "  class ToolSchemaResponse(BaseModel):\n",
            "INFO:     Started server process [36813]\n",
            "INFO:     Waiting for application startup.\n",
            "INFO:     Application startup complete.\n",
            "INFO:     Uvicorn running on http://0.0.0.0:8082 (Press CTRL+C to quit)\n",
            "Starting mcp-gateway v1.0.0\n",
            "Initialized sample tools in catalog\n",
            "INFO:     127.0.0.1:58622 - \"GET /health HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58630 - \"GET /health HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58638 - \"GET /health HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58648 - \"GET /health HTTP/1.1\" 200 OK\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "737c2ece",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "737c2ece",
        "outputId": "86c3e124-4083-42a6-da8d-83bdb45531c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "KEEP-ALIVE WATCHDOG STARTED\n",
            "  Monitoring services... Stop with Ctrl+M I\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:pyngrok.process.ngrok:t=2026-02-08T04:29:52+0000 lvl=warn msg=\"failed to open private leg\" id=c144c49e8c42 privaddr=localhost:3000 err=\"dial tcp [::1]:3000: connect: connection refused\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [04:32] System OK\n",
            "  [04:37] System OK\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:pyngrok.process.ngrok:t=2026-02-08T04:38:44+0000 lvl=warn msg=\"failed to open private leg\" id=2ec97571209a privaddr=localhost:3000 err=\"dial tcp [::1]:3000: connect: connection refused\"\n",
            "WARNING:pyngrok.process.ngrok:t=2026-02-08T04:38:49+0000 lvl=warn msg=\"failed to open private leg\" id=be5df1e1617b privaddr=localhost:3000 err=\"dial tcp [::1]:3000: connect: connection refused\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [04:42] System OK\n",
            "  [04:47] System OK\n",
            "  [04:52] System OK\n",
            "  [04:57] System OK\n",
            "  [05:02] System OK\n",
            "  [05:07] System OK\n",
            "  [05:12] System OK\n"
          ]
        }
      ],
      "source": [
        "# ‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n",
        "# ‚ïë  PHASE 7: Keep-Alive (prevents Colab from disconnecting)    ‚ïë\n",
        "# ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n",
        "import subprocess, os, sys, time, urllib.request, datetime\n",
        "\n",
        "FRAMEWORK_DIR = \"/content/ai_final/agentic-framework-main\"\n",
        "\n",
        "service_defs = [\n",
        "    {\"name\": \"MCP Gateway\",      \"module\": \"mcp_gateway.service.main:app\",      \"port\": 8082, \"log\": \"/tmp/mcp_gateway.log\",      \"env\": {\"REDIS_URL\": \"redis://localhost:6379/3\"}},\n",
        "    {\"name\": \"Memory Service\",   \"module\": \"memory_service.service.main:app\",   \"port\": 8002, \"log\": \"/tmp/memory_service.log\",   \"env\": {\"REDIS_URL\": \"redis://localhost:6379/2\"}},\n",
        "    {\"name\": \"SubAgent Manager\", \"module\": \"subagent_manager.service.main:app\", \"port\": 8003, \"log\": \"/tmp/subagent_manager.log\", \"env\": {\"REDIS_URL\": \"redis://localhost:6379/1\"}},\n",
        "    {\"name\": \"Code Executor\",    \"module\": \"code_exec.service.main:app\",        \"port\": 8004, \"log\": \"/tmp/code_exec.log\",        \"env\": {\"REDIS_URL\": \"redis://localhost:6379/4\"}},\n",
        "    {\"name\": \"Orchestrator\",     \"module\": \"orchestrator.service.main:app\",     \"port\": 8000, \"log\": \"/tmp/orchestrator.log\",     \"env\": {}},\n",
        "]\n",
        "\n",
        "def is_alive(port):\n",
        "    try:\n",
        "        url = f\"http://localhost:{port}/health\" if port != 11434 else f\"http://localhost:{port}/api/tags\"\n",
        "        urllib.request.urlopen(url, timeout=5)\n",
        "        return True\n",
        "    except: return False\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"KEEP-ALIVE WATCHDOG STARTED\")\n",
        "print(\"  Monitoring services... Stop with Ctrl+M I\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "cycle = 0\n",
        "while True:\n",
        "    cycle += 1\n",
        "    restarts = 0\n",
        "    for svc in service_defs:\n",
        "        if not is_alive(svc[\"port\"]):\n",
        "            print(f\"  Restarting {svc['name']}...\", end=\" \", flush=True)\n",
        "            # Special env handling for Code Executor\n",
        "            svc_env = {**os.environ}\n",
        "            if svc['name'] == \"Code Executor\":\n",
        "                svc_env[\"CODE_EXECUTION_MODE\"] = \"local\"\n",
        "                # Remove potential conflict keys\n",
        "                for k in ['MINIO_ENDPOINT', 'MINIO_SECRET_KEY', 'JWT_SECRET_KEY']:\n",
        "                    if k in svc_env: del svc_env[k]\n",
        "            else:\n",
        "                svc_env.update(svc['env'])\n",
        "\n",
        "            subprocess.Popen([sys.executable, \"-m\", \"uvicorn\", svc[\"module\"], \"--host\", \"0.0.0.0\", \"--port\", str(svc[\"port\"])],\n",
        "                             cwd=FRAMEWORK_DIR, stdout=open(svc[\"log\"], \"a\"), stderr=subprocess.STDOUT, env=svc_env)\n",
        "            print(\"OK\")\n",
        "            restarts += 1\n",
        "\n",
        "    if cycle % 5 == 0:\n",
        "        print(f\"  [{datetime.datetime.now().strftime('%H:%M')}] System OK\")\n",
        "    time.sleep(60)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e199e12f"
      },
      "source": [
        "import subprocess\n",
        "\n",
        "logs = [\"/tmp/minio.log\", \"/tmp/code_exec.log\", \"/tmp/mcp_gateway.log\"]\n",
        "\n",
        "print(\"=== SERVICE LOGS ===\")\n",
        "for log in logs:\n",
        "    print(f\"\\n--- {log} ---\")\n",
        "    try:\n",
        "        # Check if file exists and has content\n",
        "        if os.path.exists(log):\n",
        "            with open(log, 'r') as f:\n",
        "                content = f.read().strip()\n",
        "                if content:\n",
        "                    print(content[-2000:]) # Print last 2000 chars\n",
        "                else:\n",
        "                    print(\"(Empty file)\")\n",
        "        else:\n",
        "            print(\"(File not found)\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error reading {log}: {e}\")"
      ],
      "id": "e199e12f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1799502a"
      },
      "source": [
        "# ‚îÄ‚îÄ Repair & Restart Services ‚îÄ‚îÄ\n",
        "import subprocess, time, sys, os, urllib.request\n",
        "\n",
        "# Detect correct framework directory\n",
        "POSSIBLE_DIRS = [\n",
        "    \"/content/ai_final/agentic-framework-main\",\n",
        "    \"/content/ai_final\"\n",
        "]\n",
        "FRAMEWORK_DIR = \"/content/ai_final\"\n",
        "for d in POSSIBLE_DIRS:\n",
        "    if os.path.exists(d) and os.path.exists(os.path.join(d, \"orchestrator\")):\n",
        "        FRAMEWORK_DIR = d\n",
        "        break\n",
        "\n",
        "print(f\"Using Framework Directory: {FRAMEWORK_DIR}\")\n",
        "\n",
        "services = [\n",
        "    {\"name\": \"Code Executor\",    \"module\": \"code_exec.service.main:app\",        \"port\": 8004, \"log\": \"/tmp/code_exec.log\",        \"env\": {\"REDIS_URL\": \"redis://localhost:6379/4\"}},\n",
        "    {\"name\": \"Memory Service\",   \"module\": \"memory_service.service.main:app\",   \"port\": 8002, \"log\": \"/tmp/memory_service.log\",   \"env\": {\"REDIS_URL\": \"redis://localhost:6379/2\"}},\n",
        "    {\"name\": \"SubAgent Manager\", \"module\": \"subagent_manager.service.main:app\", \"port\": 8003, \"log\": \"/tmp/subagent_manager.log\", \"env\": {\"REDIS_URL\": \"redis://localhost:6379/1\"}},\n",
        "    {\"name\": \"MCP Gateway\",      \"module\": \"mcp_gateway.service.main:app\",      \"port\": 8080, \"log\": \"/tmp/mcp_gateway.log\",      \"env\": {\"REDIS_URL\": \"redis://localhost:6379/3\"}},\n",
        "    {\"name\": \"Orchestrator\",     \"module\": \"orchestrator.service.main:app\",     \"port\": 8000, \"log\": \"/tmp/orchestrator.log\",     \"env\": {}},\n",
        "]\n",
        "\n",
        "def check_port(port):\n",
        "    try:\n",
        "        urllib.request.urlopen(f\"http://localhost:{port}/health\", timeout=2)\n",
        "        return True\n",
        "    except:\n",
        "        return False\n",
        "\n",
        "print(\"Stopping any stuck services...\")\n",
        "subprocess.run([\"pkill\", \"-f\", \"uvicorn\"])\n",
        "time.sleep(2)\n",
        "\n",
        "print(\"Restarting services with log inspection...\")\n",
        "service_env = {**os.environ, \"PYTHONPATH\": FRAMEWORK_DIR}\n",
        "\n",
        "for svc in services:\n",
        "    print(f\"Starting {svc['name']} (:{svc['port']})...\", end=\" \", flush=True)\n",
        "    svc_env = {**service_env, **svc[\"env\"]}\n",
        "\n",
        "    # Start process\n",
        "    subprocess.Popen(\n",
        "        [sys.executable, \"-m\", \"uvicorn\", svc[\"module\"],\n",
        "         \"--host\", \"0.0.0.0\", \"--port\", str(svc[\"port\"])],\n",
        "        cwd=FRAMEWORK_DIR,\n",
        "        stdout=open(svc[\"log\"], \"w\"),\n",
        "        stderr=subprocess.STDOUT,\n",
        "        env=svc_env\n",
        "    )\n",
        "\n",
        "    # Wait and check\n",
        "    time.sleep(4)\n",
        "    if check_port(svc[\"port\"]):\n",
        "        print(\"OK\")\n",
        "    else:\n",
        "        # Check if process is even running\n",
        "        pid_check = subprocess.run([\"pgrep\", \"-f\", f\"port {svc['port']}\"], capture_output=True)\n",
        "        if pid_check.returncode == 0:\n",
        "             print(\"Running (but health check failed - still initializing?)\")\n",
        "        else:\n",
        "             print(\"FAIL (Crashed)\")\n",
        "             print(f\"--- Last 20 lines of {svc['log']} ---\")\n",
        "             if os.path.exists(svc[\"log\"]):\n",
        "                 subprocess.run([\"tail\", \"-n\", \"20\", svc[\"log\"]])\n",
        "             else:\n",
        "                 print(\"Log file not found.\")\n",
        "             print(\"------------------------------------\")\n",
        "\n",
        "print(\"\\nRepair complete. Try running Phase 6 (Smoke Test) again.\")"
      ],
      "id": "1799502a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "44117a36",
      "metadata": {
        "id": "44117a36"
      },
      "source": [
        "---\n",
        "## Utility Cells (run manually as needed)\n",
        "\n",
        "The cells below are optional ‚Äî run them when you want to interact with the system."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4c8eb3bb",
      "metadata": {
        "id": "4c8eb3bb"
      },
      "outputs": [],
      "source": [
        "# ‚îÄ‚îÄ Send a task to the Orchestrator ‚îÄ‚îÄ\n",
        "import json, urllib.request\n",
        "\n",
        "task = \"Write a Python function that calculates the Fibonacci sequence up to n terms, with proper error handling and type hints.\"\n",
        "\n",
        "print(f\"Task: {task}\\n\")\n",
        "data = json.dumps({\"message\": task, \"session_id\": \"colab-auto-001\"}).encode()\n",
        "req = urllib.request.Request(\n",
        "    \"http://localhost:8000/chat\",\n",
        "    data=data,\n",
        "    headers={\"Content-Type\": \"application/json\"}\n",
        ")\n",
        "try:\n",
        "    resp = urllib.request.urlopen(req, timeout=300)\n",
        "    result = json.loads(resp.read().decode())\n",
        "    print(json.dumps(result, indent=2)[:3000])\n",
        "except Exception as e:\n",
        "    print(f\"Error: {e}\")\n",
        "    print(\"Tip: !tail -100 /tmp/orchestrator.log\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "16fe6036",
      "metadata": {
        "id": "16fe6036"
      },
      "outputs": [],
      "source": [
        "# ‚îÄ‚îÄ View service logs ‚îÄ‚îÄ\n",
        "# Change SERVICE to: orchestrator, memory_service, subagent_manager,\n",
        "#                     mcp_gateway, code_exec, ollama, chroma, minio, dashboard\n",
        "SERVICE = \"orchestrator\"\n",
        "LINES = 50\n",
        "\n",
        "import subprocess\n",
        "print(f\"Last {LINES} lines of {SERVICE}:\")\n",
        "print(\"=\" * 60)\n",
        "subprocess.run([\"tail\", f\"-{LINES}\", f\"/tmp/{SERVICE}.log\"], capture_output=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "41e3d312",
      "metadata": {
        "id": "41e3d312"
      },
      "outputs": [],
      "source": [
        "# ‚îÄ‚îÄ System resource monitor ‚îÄ‚îÄ\n",
        "import subprocess, psutil, shutil\n",
        "\n",
        "print(\"GPU:\")\n",
        "subprocess.run(\"nvidia-smi\", shell=True)\n",
        "\n",
        "mem = psutil.virtual_memory()\n",
        "print(f\"\\nRAM: {mem.used/1024**3:.1f}/{mem.total/1024**3:.1f} GB ({mem.percent}%)\")\n",
        "\n",
        "disk = shutil.disk_usage(\"/\")\n",
        "print(f\"Disk: {(disk.total-disk.free)/1024**3:.1f}/{disk.total/1024**3:.1f} GB\")\n",
        "\n",
        "print(\"\\nRunning services:\")\n",
        "for proc in psutil.process_iter(['pid', 'name', 'cmdline']):\n",
        "    try:\n",
        "        cmd = \" \".join(proc.info.get('cmdline', []))\n",
        "        if 'uvicorn' in cmd or 'ollama' in proc.info.get('name', '').lower():\n",
        "            print(f\"  PID {proc.info['pid']}: {cmd[:80]}\")\n",
        "    except:\n",
        "        pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9c48e5cd",
      "metadata": {
        "id": "9c48e5cd"
      },
      "outputs": [],
      "source": [
        "# ‚îÄ‚îÄ Restart all services ‚îÄ‚îÄ\n",
        "import psutil, time\n",
        "\n",
        "print(\"Stopping all services...\")\n",
        "for proc in psutil.process_iter(['pid', 'cmdline']):\n",
        "    try:\n",
        "        cmd = \" \".join(proc.info.get('cmdline', []))\n",
        "        if 'uvicorn' in cmd and 'service.main' in cmd:\n",
        "            proc.kill()\n",
        "            print(f\"  Killed PID {proc.info['pid']}\")\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "time.sleep(3)\n",
        "print(\"Done. Re-run Phase 4 cell to restart services.\")"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}