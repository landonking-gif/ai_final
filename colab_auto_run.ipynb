{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "e3e7a6bf",
      "metadata": {
        "id": "e3e7a6bf"
      },
      "source": [
        "# Agentic Framework â€” Fully Automatic Google Colab Deployment\n",
        "\n",
        "**One-click deployment**: Just click **Runtime â†’ Run all** (or `Ctrl+F9`) and everything will start automatically.\n",
        "\n",
        "### What this does\n",
        "1. Verifies GPU (H100/A100) and system resources\n",
        "2. Installs system dependencies (PostgreSQL, Redis, Node.js 22, MinIO)\n",
        "3. Installs Ollama + pulls DeepSeek R1 14B (GPU-accelerated)\n",
        "4. Clones the repo and installs Python packages\n",
        "5. Starts all infrastructure (PostgreSQL, Redis, ChromaDB, MinIO)\n",
        "6. Starts all 5 microservices + dashboard\n",
        "7. Creates ngrok tunnels for external access\n",
        "8. Runs health checks\n",
        "9. Keeps the session alive so Colab doesn't disconnect\n",
        "\n",
        "### Prerequisites\n",
        "- Google Colab **Pro** account (for GPU access)\n",
        "- Runtime set to **GPU** (Runtime â†’ Change runtime type â†’ T4/A100/H100)\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "4c70cab1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4c70cab1",
        "outputId": "e70ef3ea-26fa-4679-e60e-1b661578ab9b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'ai_final'...\n",
            "remote: Enumerating objects: 60780, done.\u001b[K\n",
            "remote: Counting objects: 100% (165/165), done.\u001b[K\n",
            "remote: Compressing objects: 100% (135/135), done.\u001b[K\n",
            "remote: Total 60780 (delta 55), reused 121 (delta 28), pack-reused 60615 (from 1)\u001b[K\n",
            "Receiving objects: 100% (60780/60780), 60.31 MiB | 12.85 MiB/s, done.\n",
            "Resolving deltas: 100% (22793/22793), done.\n",
            "Updating files: 100% (79496/79496), done.\n",
            "total 360\n",
            "drwxr-xr-x 10 root root   4096 Feb  8 03:22 .\n",
            "drwxr-xr-x  1 root root   4096 Feb  8 03:21 ..\n",
            "-rw-r--r--  1 root root   4812 Feb  8 03:21 agentic-framework-deploy-auto.ipynb\n",
            "drwxr-xr-x 17 root root   4096 Feb  8 03:22 agentic-framework-main\n",
            "-rw-r--r--  1 root root   1105 Feb  8 03:22 check_deployment_status.ps1\n",
            "-rw-r--r--  1 root root   8252 Feb  8 03:22 colab_automated_deploy.py\n",
            "-rw-r--r--  1 root root 107033 Feb  8 03:22 colab_auto_run.ipynb\n",
            "-rw-r--r--  1 root root   2771 Feb  8 03:22 colab_critical_diagnostic.py\n",
            "-rw-r--r--  1 root root  34957 Feb  8 03:22 colab_deploy.ipynb\n",
            "-rw-r--r--  1 root root  22119 Feb  8 03:22 colab_deployment.py\n",
            "-rw-r--r--  1 root root   3756 Feb  8 03:21 COLAB_DEPLOYMENT_README.md\n",
            "-rw-r--r--  1 root root   5337 Feb  8 03:22 colab_deploy.ps1\n",
            "-rw-r--r--  1 root root   3501 Feb  8 03:22 colab_diagnostic_cell_emergency.py\n",
            "-rw-r--r--  1 root root   5095 Feb  8 03:22 colab_diagnostics.py\n",
            "-rw-r--r--  1 root root   3293 Feb  8 03:22 colab_recovery_cell.py\n",
            "-rw-r--r--  1 root root   3456 Feb  8 03:22 colab_service_recovery.py\n",
            "-rw-r--r--  1 root root   4586 Feb  8 03:22 colab_shortcuts.ipynb\n",
            "-rw-r--r--  1 root root   3631 Feb  8 03:21 COLAB_TROUBLESHOOTING.md\n",
            "drwxr-xr-x  4 root root   4096 Feb  8 03:22 copilot-memory-plugin\n",
            "-rw-r--r--  1 root root   1449 Feb  8 03:22 dashboard_troubleshoot.py\n",
            "-rw-r--r--  1 root root   3439 Feb  8 03:22 deploy_colab_automated.ps1\n",
            "-rw-r--r--  1 root root  18727 Feb  8 03:22 deploy-colab-automation.ps1\n",
            "-rw-r--r--  1 root root   4597 Feb  8 03:22 deploy-colab-cli.ps1\n",
            "-rw-r--r--  1 root root   1899 Feb  8 03:22 deploy-colab-final.ps1\n",
            "-rw-r--r--  1 root root   1527 Feb  8 03:22 deploy_colab_simple.bat\n",
            "-rw-r--r--  1 root root   7411 Feb  8 03:22 deploy-colab-simple.ps1\n",
            "-rw-r--r--  1 root root   1752 Feb  8 03:22 deploy_colab_simple.ps1\n",
            "-rw-r--r--  1 root root   5088 Feb  8 03:21 DEPLOYMENT_FIXES.md\n",
            "drwxr-xr-x  8 root root   4096 Feb  8 03:22 .git\n",
            "-rw-r--r--  1 root root   1599 Feb  8 03:22 hotfix_deploy.ps1\n",
            "-rw-r--r--  1 root root    388 Feb  8 03:22 king-ai-studio.pem\n",
            "drwxr-xr-x  2 root root   4096 Feb  8 03:21 LeCoder-cgpu-CLI\n",
            "drwxr-xr-x  6 root root   4096 Feb  8 03:22 multi-agent-orchestration-main\n",
            "drwxr-xr-x  2 root root   4096 Feb  8 03:21 __pycache__\n",
            "drwxr-xr-x  4 root root   4096 Feb  8 03:22 ralph\n",
            "drwxr-xr-x  5 root root   4096 Feb  8 03:22 ralph-work\n",
            "-rw-r--r--  1 root root   2306 Feb  8 03:22 simple_deploy.ps1\n",
            "-rw-r--r--  1 root root    474 Feb  8 03:21 Untitled-1.ipynb\n",
            "âœ… Latest fixes pulled from GitHub!\n",
            "Configuration loaded. Running full deployment...\n"
          ]
        }
      ],
      "source": [
        "# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
        "# â•‘  CONFIGURATION                                               â•‘\n",
        "# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "\n",
        "# GitHub repo\n",
        "REPO_URL = \"https://github.com/landonking-gif/ai_final.git\"\n",
        "\n",
        "# Ngrok Token (Get one free at https://dashboard.ngrok.com/signup)\n",
        "# Required for public URLs\n",
        "NGROK_AUTH_TOKEN = \"39MaIP07IiJMHPNDgd3raMEOL6r_2KyacFVXP68bbxBu9s8E8\"\n",
        "\n",
        "# Models (Pulled via Ollama)\n",
        "PRIMARY_MODEL = \"deepseek-r1:14b\"\n",
        "FALLBACK_MODEL = \"llama3.2:3b\"\n",
        "\n",
        "# Feature Flags\n",
        "START_DASHBOARD = True\n",
        "ENABLE_NGROK = True\n",
        "\n",
        "print(\"âœ… Configuration loaded.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "66186129",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "66186129",
        "outputId": "119ee525-ac39-49e4-a8f9-aeea65705d21"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "PHASE 1: SYSTEM CHECK & DEPENDENCY INSTALL\n",
            "============================================================\n",
            "  [GPU] Tesla T4, 15360 MiB, 550.54.15\n",
            "  [RAM] 12.7 GB\n",
            "  [Disk] 190.9 GB free\n",
            "  [Python] 3.12.12\n",
            "\n",
            "  Installing system packages...\n",
            "  [apt update] OK\n",
            "  [PostgreSQL + Redis + build tools + zstd] OK\n",
            "  [Node.js 22 repo] OK\n",
            "  [Node.js 22] OK\n",
            "  [MinIO] OK\n",
            "  [Node.js] v22.22.0\n",
            "\n",
            "  Phase 1 complete.\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
        "# â•‘  PHASE 1: System Check & Dependencies                      â•‘\n",
        "# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "import subprocess, os, sys, shutil, time\n",
        "\n",
        "def run_cmd(cmd, desc=\"\", check=False):\n",
        "    \"\"\"Run a shell command with status output.\"\"\"\n",
        "    if desc:\n",
        "        print(f\"  [{desc}]\", end=\" \", flush=True)\n",
        "    result = subprocess.run(cmd, shell=True, capture_output=True, text=True)\n",
        "    if desc:\n",
        "        print(\"OK\" if result.returncode == 0 else f\"WARN ({result.stderr[:120]})\")\n",
        "    if check and result.returncode != 0:\n",
        "        raise RuntimeError(f\"{desc} failed: {result.stderr[:300]}\")\n",
        "    return result\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"PHASE 1: SYSTEM CHECK & DEPENDENCY INSTALL\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# --- GPU Check ---\n",
        "gpu_check = subprocess.run(\n",
        "    [\"nvidia-smi\", \"--query-gpu=name,memory.total,driver_version\", \"--format=csv,noheader\"],\n",
        "    capture_output=True, text=True\n",
        ")\n",
        "if gpu_check.returncode == 0:\n",
        "    print(f\"  [GPU] {gpu_check.stdout.strip()}\")\n",
        "else:\n",
        "    print(\"  [GPU] No GPU detected â€” LLM inference will be slow on CPU!\")\n",
        "    print(\"         Go to Runtime > Change runtime type > GPU\")\n",
        "\n",
        "# --- RAM & Disk ---\n",
        "try:\n",
        "    import psutil\n",
        "    ram_gb = psutil.virtual_memory().total / (1024**3)\n",
        "    print(f\"  [RAM] {ram_gb:.1f} GB\")\n",
        "except ImportError:\n",
        "    pass\n",
        "disk = shutil.disk_usage(\"/\")\n",
        "print(f\"  [Disk] {disk.free / (1024**3):.1f} GB free\")\n",
        "print(f\"  [Python] {sys.version.split()[0]}\")\n",
        "\n",
        "# --- Install System Dependencies ---\n",
        "print(\"\\n  Installing system packages...\")\n",
        "run_cmd(\"apt-get update -qq 2>/dev/null\", \"apt update\")\n",
        "run_cmd(\"apt-get install -y -qq postgresql postgresql-client redis-server build-essential libpq-dev zstd > /dev/null 2>&1\", \"PostgreSQL + Redis + build tools + zstd\")\n",
        "\n",
        "# Node.js 22\n",
        "run_cmd(\"curl -fsSL https://deb.nodesource.com/setup_22.x | bash - > /dev/null 2>&1\", \"Node.js 22 repo\")\n",
        "run_cmd(\"apt-get install -y -qq nodejs > /dev/null 2>&1\", \"Node.js 22\")\n",
        "\n",
        "# MinIO binary\n",
        "run_cmd(\"wget -q https://dl.min.io/server/minio/release/linux-amd64/minio -O /usr/local/bin/minio && chmod +x /usr/local/bin/minio\", \"MinIO\")\n",
        "\n",
        "node_ver = subprocess.run(\"node --version\", shell=True, capture_output=True, text=True)\n",
        "print(f\"  [Node.js] {node_ver.stdout.strip()}\")\n",
        "print(\"\\n  Phase 1 complete.\")\n",
        "print(\"=\" * 60)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "8960bca3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8960bca3",
        "outputId": "1cd1fd65-0c67-4e10-cb33-ec0819f148ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "PHASE 2: OLLAMA + LLM MODEL SETUP\n",
            "============================================================\n",
            "  Installing Ollama... OK\n",
            "  Starting Ollama server... OK\n",
            "  Pulling deepseek-r1:14b (this may take 2-8 min)...\n",
            "  Pulling llama3.2:3b...\n",
            "\n",
            "  Available models:\n",
            "\n",
            "  Phase 2 complete.\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
        "# â•‘  PHASE 2: Ollama + LLM Models (GPU-Accelerated)            â•‘\n",
        "# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "import subprocess, os, time\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"PHASE 2: OLLAMA + LLM MODEL SETUP\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Install Ollama\n",
        "print(\"  Installing Ollama...\", end=\" \", flush=True)\n",
        "\n",
        "# Download the install script\n",
        "subprocess.run(\"wget -q https://ollama.com/install.sh -O /tmp/ollama_install.sh\", shell=True, check=True)\n",
        "subprocess.run(\"chmod +x /tmp/ollama_install.sh\", shell=True, check=True)\n",
        "\n",
        "# Run the install script with sudo, capturing output\n",
        "install_command = \"sudo /tmp/ollama_install.sh\"\n",
        "install_process = subprocess.Popen(install_command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
        "stdout, stderr = install_process.communicate()\n",
        "\n",
        "if install_process.returncode == 0:\n",
        "    print(\"OK\")\n",
        "else:\n",
        "    print(f\"WARN: Ollama installation script returned non-zero exit code ({install_process.returncode}).\")\n",
        "    print(f\"Installation STDOUT:\\n{stdout}\")\n",
        "    print(f\"Installation STDERR:\\n{stderr}\")\n",
        "\n",
        "# Verify Ollama executable exists\n",
        "OLLAMA_BIN_PATH = \"/usr/local/bin/ollama\"\n",
        "if not os.path.exists(OLLAMA_BIN_PATH):\n",
        "    print(f\"  [ERROR] Ollama executable not found at {OLLAMA_BIN_PATH}. Installation might have failed or installed elsewhere.\")\n",
        "    print(\"  Attempting to locate ollama binary...\")\n",
        "    find_ollama_result = subprocess.run(\"find / -name ollama 2>/dev/null\", shell=True, capture_output=True, text=True)\n",
        "    found_paths = find_ollama_result.stdout.strip().split('\\n')\n",
        "    if found_paths and found_paths[0]: # If anything was found\n",
        "        print(f\"  Found ollama at: {found_paths[0]}. Please check this path.\")\n",
        "    else:\n",
        "        print(\"  Ollama not found anywhere on the system after installation attempt.\")\n",
        "    raise FileNotFoundError(f\"Ollama executable not found at {OLLAMA_BIN_PATH}\")\n",
        "\n",
        "# Start Ollama server in background\n",
        "print(\"  Starting Ollama server...\", end=\" \", flush=True)\n",
        "os.environ[\"OLLAMA_HOST\"] = \"0.0.0.0:11434\"\n",
        "subprocess.Popen(\n",
        "    [OLLAMA_BIN_PATH, \"serve\"],\n",
        "    stdout=open(\"/tmp/ollama.log\", \"w\"),\n",
        "    stderr=subprocess.STDOUT,\n",
        "    env={**os.environ, \"OLLAMA_HOST\": \"0.0.0.0:11434\"}\n",
        ")\n",
        "time.sleep(5)\n",
        "print(\"OK\")\n",
        "\n",
        "# Pull primary model\n",
        "print(f\"  Pulling {PRIMARY_MODEL} (this may take 2-8 min)...\")\n",
        "subprocess.run([OLLAMA_BIN_PATH, \"pull\", PRIMARY_MODEL], capture_output=False, text=True)\n",
        "\n",
        "# Pull fallback model\n",
        "print(f\"  Pulling {FALLBACK_MODEL}...\")\n",
        "subprocess.run([OLLAMA_BIN_PATH, \"pull\", FALLBACK_MODEL], capture_output=False, text=True)\n",
        "\n",
        "# Verify\n",
        "print(\"\\n  Available models:\")\n",
        "subprocess.run([OLLAMA_BIN_PATH, \"list\"], capture_output=False, text=True)\n",
        "\n",
        "print(\"\\n  Phase 2 complete.\")\n",
        "print(\"=\" * 60)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "b7b9f665",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b7b9f665",
        "outputId": "cbaa3c0c-ac27-413f-a1c7-c6421291bf5d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "PHASE 3: REPO CLONE & PYTHON DEPENDENCIES\n",
            "============================================================\n",
            "  Repo exists â€” pulling latest...\n",
            "  Configuring package symlinks...\n",
            "\n",
            "  Installing Python packages (2-3 min)...\n",
            "  Installing OpenClaw...\n",
            "\n",
            "  Framework directory: /content/ai_final/agentic-framework-main\n",
            "  Phase 3 complete.\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
        "# â•‘  PHASE 3: System Setup, Repo & Dependencies                â•‘\n",
        "# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "import subprocess, os, sys, shutil\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"PHASE 3: SETUP\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# â”€â”€â”€ SYSTEM CHECKS â”€â”€â”€\n",
        "print(\"  [System] Checking GPU...\", end=\" \", flush=True)\n",
        "gpu = subprocess.run(\"nvidia-smi\", shell=True, capture_output=True)\n",
        "if gpu.returncode == 0:\n",
        "    print(\"OK (NVIDIA GPU detected)\")\n",
        "else:\n",
        "    print(\"WARN (No GPU detected - Inference will be slow)\")\n",
        "\n",
        "# â”€â”€â”€ REPOSITORY â”€â”€â”€\n",
        "INSTALL_DIR = \"/content/ai_final\"\n",
        "FRAMEWORK_DIR = f\"{INSTALL_DIR}/agentic-framework-main\"\n",
        "\n",
        "if os.path.exists(INSTALL_DIR):\n",
        "    print(\"  [Repo] Updating...\", end=\" \", flush=True)\n",
        "    subprocess.run([\"git\", \"-C\", INSTALL_DIR, \"pull\"], capture_output=False)\n",
        "    print(\"OK\")\n",
        "else:\n",
        "    print(f\"  [Repo] Cloning {REPO_URL}...\", end=\" \", flush=True)\n",
        "    subprocess.run([\"git\", \"clone\", REPO_URL, INSTALL_DIR], capture_output=False)\n",
        "    print(\"OK\")\n",
        "\n",
        "os.chdir(FRAMEWORK_DIR)\n",
        "\n",
        "# â”€â”€â”€ SYMLINKS â”€â”€â”€\n",
        "print(\"  [Setup] Configuring symlinks...\", end=\" \", flush=True)\n",
        "symlinks = {\n",
        "    \"memory_service\": \"memory-service\",\n",
        "    \"subagent_manager\": \"subagent-manager\",\n",
        "    \"mcp_gateway\": \"mcp-gateway\",\n",
        "    \"code_exec\": \"code-exec\",\n",
        "}\n",
        "for link_name, target in symlinks.items():\n",
        "    if not os.path.exists(link_name) and os.path.exists(target):\n",
        "        os.symlink(target, link_name)\n",
        "print(\"OK\")\n",
        "\n",
        "# â”€â”€â”€ DEPENDENCIES â”€â”€â”€\n",
        "print(\"  [Deps] Installing Python packages (2-3 min)...\", end=\" \", flush=True)\n",
        "subprocess.run(\n",
        "    [sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"-r\", f\"{FRAMEWORK_DIR}/requirements.txt\"],\n",
        "    capture_output=False\n",
        ")\n",
        "subprocess.run(\n",
        "    [sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"pyngrok\", \"asyncpg\", \"aiofiles\", \"psutil\"],\n",
        "    capture_output=False\n",
        ")\n",
        "print(\"OK\")\n",
        "\n",
        "print(\"  [Deps] Installing OpenClaw...\", end=\" \", flush=True)\n",
        "subprocess.run([\"npm\", \"install\", \"-g\", \"openclaw@latest\"], capture_output=True)\n",
        "print(\"OK\")\n",
        "\n",
        "# PYTHONPATH\n",
        "if FRAMEWORK_DIR not in sys.path:\n",
        "    sys.path.insert(0, FRAMEWORK_DIR)\n",
        "os.environ[\"PYTHONPATH\"] = FRAMEWORK_DIR\n",
        "\n",
        "print(\"\\n  Phase 3 complete.\")\n",
        "print(\"=\" * 60)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "78fdaf2a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "78fdaf2a",
        "outputId": "8cd91f0a-3247-4302-fe75-855ad0ecc1db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "PHASE 4: INFRASTRUCTURE & SERVICES (Optimized)\n",
            "============================================================\n",
            "  [System Check] Verifying dependencies... OK\n",
            "\n",
            "â”€â”€ Cleanup â”€â”€\n",
            "\n",
            "â”€â”€ Infrastructure â”€â”€\n",
            "  Starting PostgreSQL... OK\n",
            "  Waiting for Redis (:6379)... OK\n",
            "  Waiting for ChromaDB (:8001)... OK\n",
            "  Waiting for MinIO (:9005)... OK\n",
            "  Waiting for Ollama (:11434)... OK\n",
            "\n",
            "â”€â”€ Microservices â”€â”€\n",
            "  Starting Code Executor... OK\n",
            "  Starting Memory Service... OK\n",
            "  Starting SubAgent Manager... OK\n",
            "  Starting MCP Gateway... OK\n",
            "  Starting Orchestrator... OK\n",
            "\n",
            "â”€â”€ Dashboard â”€â”€\n",
            "  Installing & Starting... OK\n",
            "\n",
            "  Waiting 15s for initialization...\n",
            "\n",
            "â”€â”€ Status â”€â”€\n",
            "  âœ… Orchestrator : ONLINE\n",
            "  âŒ Memory       : OFFLINE\n",
            "  âœ… SubAgents    : ONLINE\n",
            "  âœ… MCP (8082)   : ONLINE\n",
            "  âœ… CodeExec     : ONLINE\n",
            "  âœ… Ollama       : ONLINE\n",
            "\n",
            "âš ï¸ Some services failed. Check logs.\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
        "# â•‘  PHASE 4: Start Infrastructure + All Services               â•‘\n",
        "# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "import subprocess, os, sys, time, urllib.request, json, socket\n",
        "\n",
        "# â”€â”€â”€ CONFIGURATION â”€â”€â”€\n",
        "# Load globals if defined, else defaults\n",
        "if \"PRIMARY_MODEL\" not in locals(): PRIMARY_MODEL = \"deepseek-r1:14b\"\n",
        "if \"FALLBACK_MODEL\" not in locals(): FALLBACK_MODEL = \"llama3.2:3b\"\n",
        "if \"START_DASHBOARD\" not in locals(): START_DASHBOARD = True\n",
        "if \"ENABLE_NGROK\" not in locals(): ENABLE_NGROK = True\n",
        "\n",
        "FRAMEWORK_DIR = \"/content/ai_final/agentic-framework-main\"\n",
        "os.chdir(FRAMEWORK_DIR)\n",
        "\n",
        "# â”€â”€â”€ AUTO-REPAIR â”€â”€â”€\n",
        "def check_system():\n",
        "    print(\"  [System] Verifying binaries...\", end=\" \", flush=True)\n",
        "    missing = []\n",
        "    if not os.path.exists(\"/usr/local/bin/minio\"): missing.append(\"minio\")\n",
        "    if subprocess.run(\"which redis-server\", shell=True).returncode != 0: missing.append(\"redis\")\n",
        "    if subprocess.run(\"which ollama\", shell=True).returncode != 0: missing.append(\"ollama\")\n",
        "\n",
        "    if missing:\n",
        "        print(f\"Fixing: {missing}\")\n",
        "        if \"minio\" in missing:\n",
        "            subprocess.run(\"wget -q https://dl.min.io/server/minio/release/linux-amd64/minio -O /usr/local/bin/minio && chmod +x /usr/local/bin/minio\", shell=True)\n",
        "        if \"redis\" in missing:\n",
        "            subprocess.run(\"apt-get update -qq && apt-get install -y -qq redis-server postgresql postgresql-client > /dev/null\", shell=True)\n",
        "        if \"ollama\" in missing:\n",
        "            subprocess.run(\"curl -fsSL https://ollama.com/install.sh | sh\", shell=True)\n",
        "    else:\n",
        "        print(\"OK\")\n",
        "\n",
        "def wait_for_service(port, name, timeout=60):\n",
        "    print(f\"  Waiting for {name} (:{port})...\", end=\" \", flush=True)\n",
        "    start = time.time()\n",
        "    while time.time() - start < timeout:\n",
        "        try:\n",
        "            with socket.create_connection((\"localhost\", port), timeout=1):\n",
        "                print(\"OK\")\n",
        "                return True\n",
        "        except: time.sleep(1)\n",
        "    print(\"TIMEOUT\")\n",
        "    return False\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"PHASE 4: INFRASTRUCTURE & SERVICES\")\n",
        "print(\"=\" * 60)\n",
        "check_system()\n",
        "\n",
        "# â”€â”€â”€ CLEANUP â”€â”€â”€\n",
        "print(\"\\nâ”€â”€ Cleanup â”€â”€\")\n",
        "subprocess.run(\"pkill -f uvicorn; pkill -f 'chroma run'; pkill -f minio\", shell=True)\n",
        "time.sleep(2)\n",
        "\n",
        "# â”€â”€â”€ INFRASTRUCTURE â”€â”€â”€\n",
        "print(\"\\nâ”€â”€ Infrastructure â”€â”€\")\n",
        "# 1. PostgreSQL\n",
        "print(\"  Starting PostgreSQL...\", end=\" \")\n",
        "subprocess.run(\"service postgresql start\", shell=True, capture_output=True)\n",
        "time.sleep(2)\n",
        "subprocess.run([\"sudo\", \"-u\", \"postgres\", \"psql\", \"-c\", \"CREATE USER agent_user WITH PASSWORD 'agent_pass' CREATEDB;\"], capture_output=True)\n",
        "subprocess.run([\"sudo\", \"-u\", \"postgres\", \"psql\", \"-c\", \"CREATE DATABASE agentic_framework OWNER agent_user;\"], capture_output=True)\n",
        "subprocess.run([\"sudo\", \"-u\", \"postgres\", \"psql\", \"-c\", \"GRANT ALL PRIVILEGES ON DATABASE agentic_framework TO agent_user;\"], capture_output=True)\n",
        "print(\"OK\")\n",
        "# 2. Redis\n",
        "subprocess.run(\"redis-server --daemonize yes --port 6379\", shell=True)\n",
        "wait_for_service(6379, \"Redis\", 10)\n",
        "# 3. ChromaDB\n",
        "os.makedirs(\"/tmp/chroma_data\", exist_ok=True)\n",
        "subprocess.Popen([\"chroma\", \"run\", \"--host\", \"0.0.0.0\", \"--port\", \"8001\", \"--path\", \"/tmp/chroma_data\"], stdout=open(\"/tmp/chroma.log\", \"w\"), stderr=subprocess.STDOUT)\n",
        "wait_for_service(8001, \"ChromaDB\")\n",
        "# 4. MinIO (Port 9005)\n",
        "os.makedirs(\"/tmp/minio_data\", exist_ok=True)\n",
        "subprocess.Popen([\"/usr/local/bin/minio\", \"server\", \"/tmp/minio_data\", \"--address\", \":9005\", \"--console-address\", \":9001\"], stdout=open(\"/tmp/minio.log\", \"w\"), stderr=subprocess.STDOUT, env={**os.environ, \"MINIO_ROOT_USER\": \"minioadmin\", \"MINIO_ROOT_PASSWORD\": \"minioadmin\"})\n",
        "if not wait_for_service(9005, \"MinIO\", 90): print(\"\\n[ERROR] MinIO Failed. Check /tmp/minio.log\")\n",
        "# 5. Ollama\n",
        "if not wait_for_service(11434, \"Ollama\", 2):\n",
        "    print(\"  Starting Ollama...\", end=\" \")\n",
        "    subprocess.Popen([\"ollama\", \"serve\"], stdout=open(\"/tmp/ollama.log\", \"w\"), stderr=subprocess.STDOUT, env={**os.environ, \"OLLAMA_HOST\": \"0.0.0.0:11434\"})\n",
        "    wait_for_service(11434, \"Ollama\", 20)\n",
        "\n",
        "# â”€â”€â”€ MODEL CHECK â”€â”€â”€\n",
        "res = subprocess.run([\"ollama\", \"list\"], capture_output=True, text=True)\n",
        "if PRIMARY_MODEL not in res.stdout:\n",
        "    print(f\"\\n  âš ï¸ Model {PRIMARY_MODEL} missing. Pulling... (5-10m)\")\n",
        "    subprocess.run([\"ollama\", \"pull\", PRIMARY_MODEL], check=True)\n",
        "    print(\"  âœ… Model pulled.\")\n",
        "\n",
        "# â”€â”€â”€ ENVIRONMENT â”€â”€â”€\n",
        "env_vars = {\n",
        "    \"POSTGRES_URL\": \"postgresql://agent_user:agent_pass@localhost:5432/agentic_framework\",\n",
        "    \"REDIS_URL\": \"redis://localhost:6379/0\",\n",
        "    \"MCP_GATEWAY_URL\": \"http://localhost:8082\", \"MEMORY_SERVICE_URL\": \"http://localhost:8002\",\n",
        "    \"SUBAGENT_MANAGER_URL\": \"http://localhost:8003\", \"CODE_EXECUTOR_URL\": \"http://localhost:8004\",\n",
        "    \"CODE_EXECUTION_MODE\": \"local\", \"OLLAMA_ENDPOINT\": \"http://localhost:11434\",\n",
        "    \"OLLAMA_BASE_URL\": \"http://localhost:11434\", \"LOCAL_MODEL\": PRIMARY_MODEL, \"FALLBACK_MODEL\": FALLBACK_MODEL,\n",
        "    \"DEFAULT_LLM_PROVIDER\": \"local\", \"LLM_PROVIDER\": \"local\", \"USE_OPENCLAW\": \"false\",\n",
        "    \"CHROMA_URL\": \"http://localhost:8001\", \"MINIO_ENDPOINT\": \"localhost:9005\",\n",
        "    \"MINIO_ACCESS_KEY\": \"minioadmin\", \"MINIO_SECRET_KEY\": \"minioadmin\", \"JWT_SECRET_KEY\": \"colab-secret\",\n",
        "    \"ENVIRONMENT\": \"development\", \"PYTHONPATH\": FRAMEWORK_DIR,\n",
        "    \"WORKSPACE_ROOT\": f\"{FRAMEWORK_DIR}/workspace\", \"WEBSOCKET_ENABLED\": \"true\", \"INDEX_CODEBASE\": \"true\",\n",
        "}\n",
        "for k, v in env_vars.items(): os.environ[k] = v\n",
        "if os.path.exists(f\"{FRAMEWORK_DIR}/.env\"): os.remove(f\"{FRAMEWORK_DIR}/.env\")\n",
        "for d in [\"workspace/.copilot/memory/diary\", \"workspace/.copilot/memory/reflections\", \"workspace/ralph-work\"]: os.makedirs(f\"{FRAMEWORK_DIR}/{d}\", exist_ok=True)\n",
        "\n",
        "# â”€â”€â”€ MICROSERVICES â”€â”€â”€\n",
        "print(\"\\nâ”€â”€ Microservices â”€â”€\")\n",
        "base_env = {**os.environ}\n",
        "services = [\n",
        "    {\"name\": \"Code Executor\",    \"module\": \"code_exec.service.main:app\",        \"port\": 8004, \"log\": \"/tmp/code_exec.log\",        \"env\": {\"REDIS_URL\": \"redis://localhost:6379/4\"}},\n",
        "    {\"name\": \"Memory Service\",   \"module\": \"memory_service.service.main:app\",   \"port\": 8002, \"log\": \"/tmp/memory_service.log\",   \"env\": {\"REDIS_URL\": \"redis://localhost:6379/2\"}},\n",
        "    {\"name\": \"SubAgent Manager\", \"module\": \"subagent_manager.service.main:app\", \"port\": 8003, \"log\": \"/tmp/subagent_manager.log\", \"env\": {\"REDIS_URL\": \"redis://localhost:6379/1\"}},\n",
        "    {\"name\": \"MCP Gateway\",      \"module\": \"mcp_gateway.service.main:app\",      \"port\": 8082, \"log\": \"/tmp/mcp_gateway.log\",      \"env\": {\"REDIS_URL\": \"redis://localhost:6379/3\"}},\n",
        "    {\"name\": \"Orchestrator\",     \"module\": \"orchestrator.service.main:app\",     \"port\": 8000, \"log\": \"/tmp/orchestrator.log\",     \"env\": {}},\n",
        "]\n",
        "\n",
        "for svc in services:\n",
        "    print(f\"  Starting {svc['name']}...\", end=\" \")\n",
        "    svc_env = base_env.copy()\n",
        "    if svc[\"name\"] == \"Code Executor\":\n",
        "        for k in ['MINIO_ENDPOINT', 'MINIO_ACCESS_KEY', 'MINIO_SECRET_KEY', 'JWT_SECRET_KEY', 'ENVIRONMENT', 'WORKSPACE_ROOT', 'WEBSOCKET_ENABLED', 'INDEX_CODEBASE', 'PYTHONPATH']:\n",
        "            if k in svc_env: del svc_env[k]\n",
        "        svc_env[\"REDIS_URL\"] = svc[\"env\"][\"REDIS_URL\"]\n",
        "        svc_env[\"CODE_EXECUTION_MODE\"] = \"local\"\n",
        "    else:\n",
        "        svc_env.update(svc[\"env\"])\n",
        "    subprocess.Popen([sys.executable, \"-m\", \"uvicorn\", svc[\"module\"], \"--host\", \"0.0.0.0\", \"--port\", str(svc[\"port\"])], cwd=FRAMEWORK_DIR, stdout=open(svc[\"log\"], \"w\"), stderr=subprocess.STDOUT, env=svc_env)\n",
        "    print(\"OK\")\n",
        "    time.sleep(1)\n",
        "\n",
        "# â”€â”€â”€ DASHBOARD â”€â”€â”€\n",
        "if START_DASHBOARD:\n",
        "    print(\"\\nâ”€â”€ Dashboard â”€â”€\")\n",
        "    dash_dir = f\"{FRAMEWORK_DIR}/dashboard\"\n",
        "    if os.path.exists(f\"{dash_dir}/package.json\"):\n",
        "        print(\"  Installing & Starting...\", end=\" \")\n",
        "        subprocess.run([\"npm\", \"install\"], cwd=dash_dir, capture_output=True)\n",
        "        subprocess.Popen([\"npm\", \"start\"], cwd=dash_dir, stdout=open(\"/tmp/dashboard.log\", \"w\"), stderr=subprocess.STDOUT, env={**os.environ, \"PORT\": \"3000\", \"BROWSER\": \"none\"})\n",
        "        print(\"OK\")\n",
        "\n",
        "print(\"\\n  Waiting 20s for services to initialize...\")\n",
        "time.sleep(20)\n",
        "\n",
        "# â”€â”€â”€ HEALTH â”€â”€â”€\n",
        "print(\"\\nâ”€â”€ Status â”€â”€\")\n",
        "checks = [(\"Orchestrator\", 8000), (\"Memory\", 8002), (\"SubAgents\", 8003), (\"MCP (8082)\", 8082), (\"CodeExec\", 8004), (\"Ollama\", 11434)]\n",
        "passed = 0\n",
        "for name, port in checks:\n",
        "    try:\n",
        "        urllib.request.urlopen(f\"http://localhost:{port}/\" + (\"api/tags\" if port==11434 else \"health\"), timeout=2)\n",
        "        print(f\"  âœ… {name:<12} : ONLINE\")\n",
        "        passed += 1\n",
        "    except: print(f\"  âŒ {name:<12} : OFFLINE\")\n",
        "\n",
        "if passed == len(checks): print(\"\\nðŸš€ ALL SYSTEMS GO!\")\n",
        "else: print(\"\\nâš ï¸ Some services failed. Check logs.\")\n",
        "print(\"=\" * 60)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8810e849",
        "outputId": "baf026ae-168c-498c-e526-05330721e31e"
      },
      "source": [
        "import urllib.request, json\n",
        "\n",
        "print(\"=== CHECKING OLLAMA MODELS ===\")\n",
        "try:\n",
        "    resp = urllib.request.urlopen(\"http://localhost:11434/api/tags\")\n",
        "    data = json.loads(resp.read().decode())\n",
        "    models = [m['name'] for m in data.get('models', [])]\n",
        "    if models:\n",
        "        print(f\"âœ… Found {len(models)} models: {models}\")\n",
        "    else:\n",
        "        print(\"âŒ No models found! (They were likely wiped by the runtime reset)\")\n",
        "except Exception as e:\n",
        "    print(f\"Error checking models: {e}\")"
      ],
      "id": "8810e849",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== CHECKING OLLAMA MODELS ===\n",
            "âœ… Found 2 models: ['llama3.2:3b', 'deepseek-r1:14b']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "35219627",
        "outputId": "5ab6daa7-78a7-439c-c2d4-46ad66451ea4"
      },
      "source": [
        "import os, subprocess\n",
        "\n",
        "FRAMEWORK_DIR = \"/content/ai_final/agentic-framework-main\"\n",
        "\n",
        "print(\"=== FILE STRUCTURE DIAGNOSTIC ===\")\n",
        "print(f\"Framework Dir: {FRAMEWORK_DIR}\")\n",
        "\n",
        "# List root to see symlinks\n",
        "subprocess.run(f\"ls -la {FRAMEWORK_DIR}\", shell=True)\n",
        "\n",
        "print(\"\\n--- Checking for __init__.py in services ---\")\n",
        "services_dirs = [\"memory-service\", \"subagent-manager\", \"code-exec\", \"mcp-gateway\"]\n",
        "for d in services_dirs:\n",
        "    path = os.path.join(FRAMEWORK_DIR, d)\n",
        "    if os.path.exists(path):\n",
        "        init_path = os.path.join(path, \"__init__.py\")\n",
        "        has_init = os.path.exists(init_path)\n",
        "        print(f\"{d}: exists={'YES' if os.path.exists(path) else 'NO'}, has_init={'YES' if has_init else 'NO'}\")\n",
        "        if os.path.exists(path):\n",
        "             subprocess.run(f\"ls -F {path}\", shell=True)\n",
        "    else:\n",
        "        print(f\"{d}: MISSING\")\n",
        "\n",
        "print(\"\\n=== FULL LOGS FOR FAILURES ===\")\n",
        "logs = [\"/tmp/code_exec.log\", \"/tmp/subagent_manager.log\"]\n",
        "for log in logs:\n",
        "    print(f\"\\n--- {log} ---\")\n",
        "    if os.path.exists(log):\n",
        "        # Print last 100 lines\n",
        "        subprocess.run(f\"tail -n 100 {log}\", shell=True)\n",
        "    else:\n",
        "        print(\"(File not found)\")"
      ],
      "id": "35219627",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== FILE STRUCTURE DIAGNOSTIC ===\n",
            "Framework Dir: /content/ai_final/agentic-framework-main\n",
            "\n",
            "--- Checking for __init__.py in services ---\n",
            "memory-service: exists=YES, has_init=YES\n",
            "subagent-manager: exists=YES, has_init=YES\n",
            "code-exec: exists=YES, has_init=YES\n",
            "mcp-gateway: exists=YES, has_init=YES\n",
            "\n",
            "=== FULL LOGS FOR FAILURES ===\n",
            "\n",
            "--- /tmp/code_exec.log ---\n",
            "\n",
            "--- /tmp/subagent_manager.log ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "88f85fc8",
        "outputId": "e7993b93-91d0-4a98-db76-ecaea927a3f4"
      },
      "source": [
        "import subprocess\n",
        "\n",
        "print(\"=== CHECKING SERVICE LOGS FOR ERRORS ===\")\n",
        "services = [\n",
        "    \"/tmp/orchestrator.log\",\n",
        "    \"/tmp/memory_service.log\",\n",
        "    \"/tmp/code_exec.log\",\n",
        "    \"/tmp/subagent_manager.log\"\n",
        "]\n",
        "\n",
        "for log in services:\n",
        "    print(f\"\\n--- {log} ---\")\n",
        "    # Check if file exists first\n",
        "    try:\n",
        "        # Print last 30 lines of the log\n",
        "        result = subprocess.run([\"tail\", \"-n\", \"30\", log], capture_output=True, text=True)\n",
        "        print(result.stdout)\n",
        "        if result.stderr:\n",
        "            print(\"STDERR:\", result.stderr)\n",
        "    except Exception as e:\n",
        "        print(f\"Could not read log: {e}\")"
      ],
      "id": "88f85fc8",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== CHECKING SERVICE LOGS FOR ERRORS ===\n",
            "\n",
            "--- /tmp/orchestrator.log ---\n",
            "INFO:     Started server process [17696]\n",
            "INFO:     Waiting for application startup.\n",
            "2026-02-08 03:27:17,718 - orchestrator.service.main - INFO - Starting Lead Agent/Orchestrator service...\n",
            "2026-02-08 03:27:17,718 - orchestrator.service.main - INFO - Configuration: LLM Provider=local\n",
            "2026-02-08 03:27:17,718 - orchestrator.service.main - INFO - MCP Gateway URL: http://localhost:8080\n",
            "2026-02-08 03:27:17,718 - orchestrator.service.main - INFO - Memory Service URL: http://localhost:8002\n",
            "2026-02-08 03:27:17,847 - orchestrator.service.main - INFO - WebSocket manager initialized\n",
            "2026-02-08 03:27:17,850 - orchestrator.service.session_storage - INFO - Connected to Redis at redis://localhost:6379/0\n",
            "2026-02-08 03:27:17,850 - orchestrator.service.agent - INFO - Session storage initialized\n",
            "2026-02-08 03:27:17,850 - orchestrator.service.memory_learning - INFO - MemoryLearningClient initialized: memory_dir=/content/ai_final/agentic-framework-main/workspace/.copilot/memory\n",
            "2026-02-08 03:27:17,850 - orchestrator.service.agent_manager - INFO - Memory learning client initialized\n",
            "2026-02-08 03:27:17,850 - orchestrator.service.agent_manager - INFO - Agent manager started\n",
            "2026-02-08 03:27:17,850 - orchestrator.service.agent - INFO - Agent manager initialized\n",
            "2026-02-08 03:27:17,851 - orchestrator.service.agent - INFO - OrchestratorAgent fully initialized\n",
            "2026-02-08 03:27:17,851 - orchestrator.service.main - INFO - Orchestrator agent initialized with persistent storage\n",
            "2026-02-08 03:27:17,851 - orchestrator.service.main - INFO - Orchestrator service started successfully\n",
            "INFO:     Application startup complete.\n",
            "INFO:     Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit)\n",
            "2026-02-08 03:28:03,781 - httpx - INFO - HTTP Request: GET http://localhost:8080/health \"HTTP/1.1 404 Not Found\"\n",
            "2026-02-08 03:28:03,785 - httpx - INFO - HTTP Request: GET http://localhost:8002/health \"HTTP/1.1 200 OK\"\n",
            "2026-02-08 03:28:03,788 - httpx - INFO - HTTP Request: GET http://localhost:8003/health \"HTTP/1.1 200 OK\"\n",
            "INFO:     127.0.0.1:56762 - \"GET /health HTTP/1.1\" 200 OK\n",
            "\n",
            "\n",
            "--- /tmp/memory_service.log ---\n",
            "INFO:httpx:HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/sentence_bert_config.json \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/adapter_config.json \"HTTP/1.1 404 Not Found\"\n",
            "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n",
            "WARNING:huggingface_hub.utils._http:Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n",
            "INFO:httpx:HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/config.json \"HTTP/1.1 307 Temporary Redirect\"\n",
            "INFO:httpx:HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config.json \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/config.json \"HTTP/1.1 307 Temporary Redirect\"\n",
            "INFO:httpx:HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config.json \"HTTP/1.1 200 OK\"\n",
            "\n",
            "Loading weights:   0%|          | 0/103 [00:00<?, ?it/s]\n",
            "Loading weights:   1%|          | 1/103 [00:00<00:00, 32263.88it/s, Materializing param=embeddings.LayerNorm.bias]\n",
            "Loading weights:   1%|          | 1/103 [00:00<00:00, 9279.43it/s, Materializing param=embeddings.LayerNorm.bias] \n",
            "Loading weights:   2%|â–         | 2/103 [00:00<00:00, 6775.94it/s, Materializing param=embeddings.LayerNorm.weight]\n",
            "Loading weights:   2%|â–         | 2/103 [00:00<00:00, 5511.57it/s, Materializing param=embeddings.LayerNorm.weight]\n",
            "Loading weights:   3%|â–Ž         | 3/103 [00:00<00:00, 6000.43it/s, Materializing param=embeddings.position_embeddings.weight]\n",
            "Loading weights:   3%|â–Ž         | 3/103 [00:00<00:00, 4721.54it/s, Materializing param=embeddings.position_embeddings.weight]\n",
            "Loading weights:   4%|â–         | 4/103 [00:00<00:00, 5140.08it/s, Materializing param=embeddings.token_type_embeddings.weight]\n",
            "Loading weights:   4%|â–         | 4/103 [00:00<00:00, 4792.12it/s, Materializing param=embeddings.token_type_embeddings.weight]\n",
            "Loading weights:   5%|â–         | 5/103 [00:00<00:00, 5363.56it/s, Materializing param=embeddings.word_embeddings.weight]      \n",
            "Loading weights:   5%|â–         | 5/103 [00:00<00:00, 5041.23it/s, Materializing param=embeddings.word_embeddings.weight]\n",
            "Loading weights:   6%|â–Œ         | 6/103 [00:00<00:00, 5511.57it/s, Materializing param=encoder.layer.0.attention.output.LayerNorm.bias]\n",
            "Loading weights:   6%|â–Œ         | 6/103 [00:00<00:00, 5253.83it/s, Materializing param=encoder.layer.0.attention.output.LayerNorm.bias]\n",
            "Loading weights:   7%|â–‹         | 7/103 [00:00<00:00, 5566.96it/s, Materializing param=encoder.layer.0.attention.output.LayerNorm.weight]\n",
            "Loading weights:   7%|â–‹         | 7/103 [00:00<00:00, 5346.95it/s, Materializing param=encoder.layer.0.attention.output.LayerNorm.weight]\n",
            "Loading weights:   8%|â–Š         | 8/103 [00:00<00:00, 5697.81it/s, Materializing param=encoder.layer.0.attention.output.dense.bias]      \n",
            "Loading weights:   8%|â–Š         | 8/103 [00:00<00:00, 5505.24it/s, Materializing param=encoder.layer.0.attention.output.dense.bias]\n",
            "Loading weights:   9%|â–Š         | 9/103 [00:00<00:00, 983.09it/s, Materializing param=encoder.layer.0.attention.output.dense.weight]\n",
            "Loading weights:   9%|â–Š         | 9/103 [00:00<00:00, 967.52it/s, Materializing param=encoder.layer.0.attention.output.dense.weight]\n",
            "Loading weights:  10%|â–‰         | 10/103 [00:00<00:00, 952.10it/s, Materializing param=encoder.layer.0.attention.self.key.bias]     \n",
            "Loading weights:  10%|â–‰         | 10/103 [00:00<00:00, 931.43it/s, Materializing param=encoder.layer.0.attention.self.key.bias]\n",
            "Loading weights:  11%|â–ˆ         | 11/103 [00:00<00:00, 971.70it/s, Materializing param=encoder.layer.0.attention.self.key.weight]\n",
            "Loading weights:  11%|â–ˆ         | 11/103 [00:00<00:00, 962.62it/s, Materializing param=encoder.layer.0.attention.self.key.weight]\n",
            "Loading weights:  12%|â–ˆâ–        | 12/103 [00:00<00:00, 663.98it/s, Materializing param=encoder.layer.0.attention.self.query.bias]\n",
            "Loading weights:  12%|â–ˆâ–        | 12/103 [00:00<00:00, 660.10it/s, Materializing param=encoder.layer.0.attention.self.query.bias]\n",
            "Loading weights:  13%|â–ˆâ–Ž        | 13/103 [00:00<00:00, 706.29it/s, Materializing param=encoder.layer.0.attention.self.query.weight]\n",
            "Loading weights:  13%|â–ˆâ–Ž        | 13/103 [00:00<00:00, 702.72it/s, Materializing param=encoder.layer.0.attention.self.query.weight]\n",
            "Loading weights:  14%|â–ˆâ–Ž        | 14/103 [00:00<00:00, 737.65it/s, Materializing param=encoder.layer.0.attention.self.value.bias]  \n",
            "Loading weights:  14%|â–ˆâ–Ž        | 14/103 [00:00<00:00, 733.58it/s, Materializing param=encoder.layer.0.attention.self.value.bias]\n",
            "Loading weights:  15%|â–ˆâ–        | 15/103 [00:00<00:00, 778.28it/s, Materializing param=encoder.layer.0.attention.self.value.weight]\n",
            "Loading weights:  15%|â–ˆâ–        | 15/103 [00:00<00:00, 775.50it/s, Materializing param=encoder.layer.0.attention.self.value.weight]\n",
            "Loading weights:  16%|â–ˆâ–Œ        | 16/103 [00:00<00:00, 822.40it/s, Materializing param=encoder.layer.0.intermediate.dense.bias]    \n",
            "Loading weights:  16%|â–ˆâ–Œ        | 16/103 [00:00<00:00, 820.15it/s, Materializing param=encoder.layer.0.intermediate.dense.bias]\n",
            "Loading weights:  17%|â–ˆâ–‹        | 17/103 [00:00<00:00, 862.65it/s, Materializing param=encoder.layer.0.intermediate.dense.weight]\n",
            "Loading weights:  17%|â–ˆâ–‹        | 17/103 [00:00<00:00, 858.26it/s, Materializing param=encoder.layer.0.intermediate.dense.weight]\n",
            "Loading weights:  17%|â–ˆâ–‹        | 18/103 [00:00<00:00, 899.43it/s, Materializing param=encoder.layer.0.output.LayerNorm.bias]    \n",
            "Loading weights:  17%|â–ˆâ–‹        | 18/103 [00:00<00:00, 894.36it/s, Materializing param=encoder.layer.0.output.LayerNorm.bias]\n",
            "Loading weights:  18%|â–ˆâ–Š        | 19/103 [00:00<00:00, 934.57it/s, Materializing param=encoder.layer.0.output.LayerNorm.weight]\n",
            "Loading weights:  18%|â–ˆâ–Š        | 19/103 [00:00<00:00, 929.85it/s, Materializing param=encoder.layer.0.output.LayerNorm.weight]\n",
            "Loading weights:  19%|â–ˆâ–‰        | 20/103 [00:00<00:00, 721.19it/s, Materializing param=encoder.layer.0.output.dense.bias]      \n",
            "Loading weights:  19%|â–ˆâ–‰        | 20/103 [00:00<00:00, 717.33it/s, Materializing param=encoder.layer.0.output.dense.bias]\n",
            "Loading weights:  20%|â–ˆâ–ˆ        | 21/103 [00:00<00:00, 746.68it/s, Materializing param=encoder.layer.0.output.dense.weight]\n",
            "Loading weights:  20%|â–ˆâ–ˆ        | 21/103 [00:00<00:00, 742.78it/s, Materializing param=encoder.layer.0.output.dense.weight]\n",
            "Loading weights:  21%|â–ˆâ–ˆâ–       | 22/103 [00:00<00:00, 773.52it/s, Materializing param=encoder.layer.1.attention.output.LayerNorm.bias]\n",
            "Loading weights:  21%|â–ˆâ–ˆâ–       | 22/103 [00:00<00:00, 770.88it/s, Materializing param=encoder.layer.1.attention.output.LayerNorm.bias]\n",
            "Loading weights:  22%|â–ˆâ–ˆâ–       | 23/103 [00:00<00:00, 799.90it/s, Materializing param=encoder.layer.1.attention.output.LayerNorm.weight]\n",
            "Loading weights:  22%|â–ˆâ–ˆâ–       | 23/103 [00:00<00:00, 796.72it/s, Materializing param=encoder.layer.1.attention.output.LayerNorm.weight]\n",
            "Loading weights:  23%|â–ˆâ–ˆâ–Ž       | 24/103 [00:00<00:00, 825.63it/s, Materializing param=encoder.layer.1.attention.output.dense.bias]      \n",
            "Loading weights:  23%|â–ˆâ–ˆâ–Ž       | 24/103 [00:00<00:00, 822.82it/s, Materializing param=encoder.layer.1.attention.output.dense.bias]\n",
            "Loading weights:  24%|â–ˆâ–ˆâ–       | 25/103 [00:00<00:00, 852.00it/s, Materializing param=encoder.layer.1.attention.output.dense.weight]\n",
            "Loading weights:  24%|â–ˆâ–ˆâ–       | 25/103 [00:00<00:00, 849.38it/s, Materializing param=encoder.layer.1.attention.output.dense.weight]\n",
            "Loading weights:  25%|â–ˆâ–ˆâ–Œ       | 26/103 [00:00<00:00, 656.68it/s, Materializing param=encoder.layer.1.attention.self.key.bias]      \n",
            "Loading weights:  25%|â–ˆâ–ˆâ–Œ       | 26/103 [00:00<00:00, 654.43it/s, Materializing param=encoder.layer.1.attention.self.key.bias]\n",
            "Loading weights:  26%|â–ˆâ–ˆâ–Œ       | 27/103 [00:00<00:00, 675.69it/s, Materializing param=encoder.layer.1.attention.self.key.weight]\n",
            "Loading weights:  26%|â–ˆâ–ˆâ–Œ       | 27/103 [00:00<00:00, 673.60it/s, Materializing param=encoder.layer.1.attention.self.key.weight]\n",
            "Loading weights:  27%|â–ˆâ–ˆâ–‹       | 28/103 [00:00<00:00, 695.02it/s, Materializing param=encoder.layer.1.attention.self.query.bias]\n",
            "Loading weights:  27%|â–ˆâ–ˆâ–‹       | 28/103 [00:00<00:00, 693.18it/s, Materializing param=encoder.layer.1.attention.self.query.bias]\n",
            "Loading weights:  28%|â–ˆâ–ˆâ–Š       | 29/103 [00:00<00:00, 714.15it/s, Materializing param=encoder.layer.1.attention.self.query.weight]\n",
            "Loading weights:  28%|â–ˆâ–ˆâ–Š       | 29/103 [00:00<00:00, 712.12it/s, Materializing param=encoder.layer.1.attention.self.query.weight]\n",
            "Loading weights:  29%|â–ˆâ–ˆâ–‰       | 30/103 [00:00<00:00, 733.12it/s, Materializing param=encoder.layer.1.attention.self.value.bias]  \n",
            "Loading weights:  29%|â–ˆâ–ˆâ–‰       | 30/103 [00:00<00:00, 731.01it/s, Materializing param=encoder.layer.1.attention.self.value.bias]\n",
            "Loading weights:  30%|â–ˆâ–ˆâ–ˆ       | 31/103 [00:00<00:00, 751.15it/s, Materializing param=encoder.layer.1.attention.self.value.weight]\n",
            "Loading weights:  30%|â–ˆâ–ˆâ–ˆ       | 31/103 [00:00<00:00, 749.16it/s, Materializing param=encoder.layer.1.attention.self.value.weight]\n",
            "Loading weights:  31%|â–ˆâ–ˆâ–ˆ       | 32/103 [00:00<00:00, 596.93it/s, Materializing param=encoder.layer.1.intermediate.dense.bias]    \n",
            "Loading weights:  31%|â–ˆâ–ˆâ–ˆ       | 32/103 [00:00<00:00, 595.29it/s, Materializing param=encoder.layer.1.intermediate.dense.bias]\n",
            "Loading weights:  32%|â–ˆâ–ˆâ–ˆâ–      | 33/103 [00:00<00:00, 611.02it/s, Materializing param=encoder.layer.1.intermediate.dense.weight]\n",
            "Loading weights:  32%|â–ˆâ–ˆâ–ˆâ–      | 33/103 [00:00<00:00, 609.57it/s, Materializing param=encoder.layer.1.intermediate.dense.weight]\n",
            "Loading weights:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 34/103 [00:00<00:00, 625.59it/s, Materializing param=encoder.layer.1.output.LayerNorm.bias]    \n",
            "Loading weights:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 34/103 [00:00<00:00, 624.36it/s, Materializing param=encoder.layer.1.output.LayerNorm.bias]\n",
            "Loading weights:  34%|â–ˆâ–ˆâ–ˆâ–      | 35/103 [00:00<00:00, 640.07it/s, Materializing param=encoder.layer.1.output.LayerNorm.weight]\n",
            "Loading weights:  34%|â–ˆâ–ˆâ–ˆâ–      | 35/103 [00:00<00:00, 638.78it/s, Materializing param=encoder.layer.1.output.LayerNorm.weight]\n",
            "Loading weights:  35%|â–ˆâ–ˆâ–ˆâ–      | 36/103 [00:00<00:00, 654.14it/s, Materializing param=encoder.layer.1.output.dense.bias]      \n",
            "Loading weights:  35%|â–ˆâ–ˆâ–ˆâ–      | 36/103 [00:00<00:00, 652.77it/s, Materializing param=encoder.layer.1.output.dense.bias]\n",
            "Loading weights:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 37/103 [00:00<00:00, 668.36it/s, Materializing param=encoder.layer.1.output.dense.weight]\n",
            "Loading weights:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 37/103 [00:00<00:00, 667.21it/s, Materializing param=encoder.layer.1.output.dense.weight]\n",
            "Loading weights:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 38/103 [00:00<00:00, 633.43it/s, Materializing param=encoder.layer.2.attention.output.LayerNorm.bias]\n",
            "Loading weights:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 38/103 [00:00<00:00, 632.28it/s, Materializing param=encoder.layer.2.attention.output.LayerNorm.bias]\n",
            "Loading weights:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 39/103 [00:00<00:00, 645.94it/s, Materializing param=encoder.layer.2.attention.output.LayerNorm.weight]\n",
            "Loading weights:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 39/103 [00:00<00:00, 644.89it/s, Materializing param=encoder.layer.2.attention.output.LayerNorm.weight]\n",
            "Loading weights:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 40/103 [00:00<00:00, 624.87it/s, Materializing param=encoder.layer.2.attention.output.dense.bias]      \n",
            "Loading weights:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 40/103 [00:00<00:00, 622.93it/s, Materializing param=encoder.layer.2.attention.output.dense.bias]\n",
            "Loading weights:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 41/103 [00:00<00:00, 634.51it/s, Materializing param=encoder.layer.2.attention.output.dense.weight]\n",
            "Loading weights:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 41/103 [00:00<00:00, 633.49it/s, Materializing param=encoder.layer.2.attention.output.dense.weight]\n",
            "Loading weights:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 42/103 [00:00<00:00, 629.76it/s, Materializing param=encoder.layer.2.attention.self.key.bias]      \n",
            "Loading weights:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 42/103 [00:00<00:00, 628.43it/s, Materializing param=encoder.layer.2.attention.self.key.bias]\n",
            "Loading weights:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/103 [00:00<00:00, 615.15it/s, Materializing param=encoder.layer.2.attention.self.key.weight]\n",
            "Loading weights:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/103 [00:00<00:00, 613.53it/s, Materializing param=encoder.layer.2.attention.self.key.weight]\n",
            "Loading weights:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 44/103 [00:00<00:00, 625.17it/s, Materializing param=encoder.layer.2.attention.self.query.bias]\n",
            "Loading weights:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 44/103 [00:00<00:00, 624.27it/s, Materializing param=encoder.layer.2.attention.self.query.bias]\n",
            "Loading weights:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 45/103 [00:00<00:00, 610.89it/s, Materializing param=encoder.layer.2.attention.self.query.weight]\n",
            "Loading weights:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 45/103 [00:00<00:00, 586.05it/s, Materializing param=encoder.layer.2.attention.self.query.weight]\n",
            "Loading weights:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 46/103 [00:00<00:00, 596.47it/s, Materializing param=encoder.layer.2.attention.self.value.bias]  \n",
            "Loading weights:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 46/103 [00:00<00:00, 595.54it/s, Materializing param=encoder.layer.2.attention.self.value.bias]\n",
            "Loading weights:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 47/103 [00:00<00:00, 605.26it/s, Materializing param=encoder.layer.2.attention.self.value.weight]\n",
            "Loading weights:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 47/103 [00:00<00:00, 604.21it/s, Materializing param=encoder.layer.2.attention.self.value.weight]\n",
            "Loading weights:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 48/103 [00:00<00:00, 615.06it/s, Materializing param=encoder.layer.2.intermediate.dense.bias]    \n",
            "Loading weights:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 48/103 [00:00<00:00, 614.10it/s, Materializing param=encoder.layer.2.intermediate.dense.bias]\n",
            "Loading weights:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 49/103 [00:00<00:00, 624.91it/s, Materializing param=encoder.layer.2.intermediate.dense.weight]\n",
            "Loading weights:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 49/103 [00:00<00:00, 623.80it/s, Materializing param=encoder.layer.2.intermediate.dense.weight]\n",
            "Loading weights:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 50/103 [00:00<00:00, 634.56it/s, Materializing param=encoder.layer.2.output.LayerNorm.bias]    \n",
            "Loading weights:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 50/103 [00:00<00:00, 633.59it/s, Materializing param=encoder.layer.2.output.LayerNorm.bias]\n",
            "Loading weights:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 51/103 [00:00<00:00, 644.34it/s, Materializing param=encoder.layer.2.output.LayerNorm.weight]\n",
            "Loading weights:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 51/103 [00:00<00:00, 643.25it/s, Materializing param=encoder.layer.2.output.LayerNorm.weight]\n",
            "Loading weights:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 52/103 [00:00<00:00, 653.91it/s, Materializing param=encoder.layer.2.output.dense.bias]      \n",
            "Loading weights:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 52/103 [00:00<00:00, 592.26it/s, Materializing param=encoder.layer.2.output.dense.bias]\n",
            "Loading weights:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 53/103 [00:00<00:00, 601.51it/s, Materializing param=encoder.layer.2.output.dense.weight]\n",
            "Loading weights:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 53/103 [00:00<00:00, 600.54it/s, Materializing param=encoder.layer.2.output.dense.weight]\n",
            "Loading weights:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 54/103 [00:00<00:00, 610.03it/s, Materializing param=encoder.layer.3.attention.output.LayerNorm.bias]\n",
            "Loading weights:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 54/103 [00:00<00:00, 608.95it/s, Materializing param=encoder.layer.3.attention.output.LayerNorm.bias]\n",
            "Loading weights:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 55/103 [00:00<00:00, 618.51it/s, Materializing param=encoder.layer.3.attention.output.LayerNorm.weight]\n",
            "Loading weights:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 55/103 [00:00<00:00, 617.57it/s, Materializing param=encoder.layer.3.attention.output.LayerNorm.weight]\n",
            "Loading weights:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 56/103 [00:00<00:00, 626.95it/s, Materializing param=encoder.layer.3.attention.output.dense.bias]      \n",
            "Loading weights:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 56/103 [00:00<00:00, 626.21it/s, Materializing param=encoder.layer.3.attention.output.dense.bias]\n",
            "Loading weights:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 57/103 [00:00<00:00, 592.87it/s, Materializing param=encoder.layer.3.attention.output.dense.weight]\n",
            "Loading weights:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 57/103 [00:00<00:00, 591.90it/s, Materializing param=encoder.layer.3.attention.output.dense.weight]\n",
            "Loading weights:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 58/103 [00:00<00:00, 600.57it/s, Materializing param=encoder.layer.3.attention.self.key.bias]      \n",
            "Loading weights:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 58/103 [00:00<00:00, 599.81it/s, Materializing param=encoder.layer.3.attention.self.key.bias]\n",
            "Loading weights:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 59/103 [00:00<00:00, 608.72it/s, Materializing param=encoder.layer.3.attention.self.key.weight]\n",
            "Loading weights:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 59/103 [00:00<00:00, 608.01it/s, Materializing param=encoder.layer.3.attention.self.key.weight]\n",
            "Loading weights:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 60/103 [00:00<00:00, 616.78it/s, Materializing param=encoder.layer.3.attention.self.query.bias]\n",
            "Loading weights:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 60/103 [00:00<00:00, 616.09it/s, Materializing param=encoder.layer.3.attention.self.query.bias]\n",
            "Loading weights:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 61/103 [00:00<00:00, 585.90it/s, Materializing param=encoder.layer.3.attention.self.query.bias]\n",
            "Loading weights:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 61/103 [00:00<00:00, 585.90it/s, Materializing param=encoder.layer.3.attention.self.query.weight]\n",
            "Loading weights:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 61/103 [00:00<00:00, 585.90it/s, Materializing param=encoder.layer.3.attention.self.query.weight]\n",
            "Loading weights:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 62/103 [00:00<00:00, 585.90it/s, Materializing param=encoder.layer.3.attention.self.value.bias]  \n",
            "Loading weights:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 62/103 [00:00<00:00, 585.90it/s, Materializing param=encoder.layer.3.attention.self.value.bias]\n",
            "Loading weights:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 63/103 [00:00<00:00, 585.90it/s, Materializing param=encoder.layer.3.attention.self.value.weight]\n",
            "Loading weights:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 63/103 [00:00<00:00, 585.90it/s, Materializing param=encoder.layer.3.attention.self.value.weight]\n",
            "Loading weights:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 64/103 [00:00<00:00, 585.90it/s, Materializing param=encoder.layer.3.intermediate.dense.bias]    \n",
            "Loading weights:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 64/103 [00:00<00:00, 585.90it/s, Materializing param=encoder.layer.3.intermediate.dense.bias]\n",
            "Loading weights:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 65/103 [00:00<00:00, 585.90it/s, Materializing param=encoder.layer.3.intermediate.dense.weight]\n",
            "Loading weights:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 65/103 [00:00<00:00, 585.90it/s, Materializing param=encoder.layer.3.intermediate.dense.weight]\n",
            "Loading weights:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 66/103 [00:00<00:00, 585.90it/s, Materializing param=encoder.layer.3.output.LayerNorm.bias]    \n",
            "Loading weights:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 66/103 [00:00<00:00, 585.90it/s, Materializing param=encoder.layer.3.output.LayerNorm.bias]\n",
            "Loading weights:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 67/103 [00:00<00:00, 585.90it/s, Materializing param=encoder.layer.3.output.LayerNorm.weight]\n",
            "Loading weights:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 67/103 [00:00<00:00, 585.90it/s, Materializing param=encoder.layer.3.output.LayerNorm.weight]\n",
            "Loading weights:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 68/103 [00:00<00:00, 585.90it/s, Materializing param=encoder.layer.3.output.dense.bias]      \n",
            "Loading weights:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 68/103 [00:00<00:00, 585.90it/s, Materializing param=encoder.layer.3.output.dense.bias]\n",
            "Loading weights:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 69/103 [00:00<00:00, 585.90it/s, Materializing param=encoder.layer.3.output.dense.weight]\n",
            "Loading weights:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 69/103 [00:00<00:00, 585.90it/s, Materializing param=encoder.layer.3.output.dense.weight]\n",
            "Loading weights:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 70/103 [00:00<00:00, 585.90it/s, Materializing param=encoder.layer.4.attention.output.LayerNorm.bias]\n",
            "Loading weights:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 70/103 [00:00<00:00, 585.90it/s, Materializing param=encoder.layer.4.attention.output.LayerNorm.bias]\n",
            "Loading weights:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 71/103 [00:00<00:00, 585.90it/s, Materializing param=encoder.layer.4.attention.output.LayerNorm.weight]\n",
            "Loading weights:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 71/103 [00:00<00:00, 585.90it/s, Materializing param=encoder.layer.4.attention.output.LayerNorm.weight]\n",
            "Loading weights:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 72/103 [00:00<00:00, 585.90it/s, Materializing param=encoder.layer.4.attention.output.dense.bias]      \n",
            "Loading weights:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 72/103 [00:00<00:00, 585.90it/s, Materializing param=encoder.layer.4.attention.output.dense.bias]\n",
            "Loading weights:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 73/103 [00:00<00:00, 585.90it/s, Materializing param=encoder.layer.4.attention.output.dense.weight]\n",
            "Loading weights:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 73/103 [00:00<00:00, 585.90it/s, Materializing param=encoder.layer.4.attention.output.dense.weight]\n",
            "Loading weights:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 74/103 [00:00<00:00, 585.90it/s, Materializing param=encoder.layer.4.attention.self.key.bias]      \n",
            "Loading weights:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 74/103 [00:00<00:00, 585.90it/s, Materializing param=encoder.layer.4.attention.self.key.bias]\n",
            "Loading weights:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 75/103 [00:00<00:00, 585.90it/s, Materializing param=encoder.layer.4.attention.self.key.weight]\n",
            "Loading weights:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 75/103 [00:00<00:00, 585.90it/s, Materializing param=encoder.layer.4.attention.self.key.weight]\n",
            "Loading weights:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 76/103 [00:00<00:00, 585.90it/s, Materializing param=encoder.layer.4.attention.self.query.bias]\n",
            "Loading weights:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 76/103 [00:00<00:00, 585.90it/s, Materializing param=encoder.layer.4.attention.self.query.bias]\n",
            "Loading weights:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 77/103 [00:00<00:00, 585.90it/s, Materializing param=encoder.layer.4.attention.self.query.weight]\n",
            "Loading weights:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 77/103 [00:00<00:00, 585.90it/s, Materializing param=encoder.layer.4.attention.self.query.weight]\n",
            "Loading weights:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 78/103 [00:00<00:00, 585.90it/s, Materializing param=encoder.layer.4.attention.self.value.bias]  \n",
            "Loading weights:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 78/103 [00:00<00:00, 585.90it/s, Materializing param=encoder.layer.4.attention.self.value.bias]\n",
            "Loading weights:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 79/103 [00:00<00:00, 585.90it/s, Materializing param=encoder.layer.4.attention.self.value.weight]\n",
            "Loading weights:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 79/103 [00:00<00:00, 585.90it/s, Materializing param=encoder.layer.4.attention.self.value.weight]\n",
            "Loading weights:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 80/103 [00:00<00:00, 585.90it/s, Materializing param=encoder.layer.4.intermediate.dense.bias]    \n",
            "Loading weights:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 80/103 [00:00<00:00, 585.90it/s, Materializing param=encoder.layer.4.intermediate.dense.bias]\n",
            "Loading weights:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 81/103 [00:00<00:00, 585.90it/s, Materializing param=encoder.layer.4.intermediate.dense.weight]\n",
            "Loading weights:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 81/103 [00:00<00:00, 585.90it/s, Materializing param=encoder.layer.4.intermediate.dense.weight]\n",
            "Loading weights:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 82/103 [00:00<00:00, 585.90it/s, Materializing param=encoder.layer.4.output.LayerNorm.bias]    \n",
            "Loading weights:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 82/103 [00:00<00:00, 585.90it/s, Materializing param=encoder.layer.4.output.LayerNorm.bias]\n",
            "Loading weights:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 83/103 [00:00<00:00, 585.90it/s, Materializing param=encoder.layer.4.output.LayerNorm.weight]\n",
            "Loading weights:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 83/103 [00:00<00:00, 585.90it/s, Materializing param=encoder.layer.4.output.LayerNorm.weight]\n",
            "Loading weights:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 84/103 [00:00<00:00, 585.90it/s, Materializing param=encoder.layer.4.output.dense.bias]      \n",
            "Loading weights:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 84/103 [00:00<00:00, 585.90it/s, Materializing param=encoder.layer.4.output.dense.bias]\n",
            "Loading weights:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 85/103 [00:00<00:00, 585.90it/s, Materializing param=encoder.layer.4.output.dense.weight]\n",
            "Loading weights:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 85/103 [00:00<00:00, 585.90it/s, Materializing param=encoder.layer.4.output.dense.weight]\n",
            "Loading weights:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 86/103 [00:00<00:00, 585.90it/s, Materializing param=encoder.layer.5.attention.output.LayerNorm.bias]\n",
            "Loading weights:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 86/103 [00:00<00:00, 585.90it/s, Materializing param=encoder.layer.5.attention.output.LayerNorm.bias]\n",
            "Loading weights:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 87/103 [00:00<00:00, 585.90it/s, Materializing param=encoder.layer.5.attention.output.LayerNorm.weight]\n",
            "Loading weights:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 87/103 [00:00<00:00, 585.90it/s, Materializing param=encoder.layer.5.attention.output.LayerNorm.weight]\n",
            "Loading weights:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 88/103 [00:00<00:00, 585.90it/s, Materializing param=encoder.layer.5.attention.output.dense.bias]      \n",
            "Loading weights:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 88/103 [00:00<00:00, 585.90it/s, Materializing param=encoder.layer.5.attention.output.dense.bias]\n",
            "Loading weights:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 89/103 [00:00<00:00, 585.90it/s, Materializing param=encoder.layer.5.attention.output.dense.weight]\n",
            "Loading weights:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 89/103 [00:00<00:00, 585.90it/s, Materializing param=encoder.layer.5.attention.output.dense.weight]\n",
            "Loading weights:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 90/103 [00:00<00:00, 585.90it/s, Materializing param=encoder.layer.5.attention.self.key.bias]      \n",
            "Loading weights:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 90/103 [00:00<00:00, 585.90it/s, Materializing param=encoder.layer.5.attention.self.key.bias]\n",
            "Loading weights:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 91/103 [00:00<00:00, 585.90it/s, Materializing param=encoder.layer.5.attention.self.key.weight]\n",
            "Loading weights:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 91/103 [00:00<00:00, 585.90it/s, Materializing param=encoder.layer.5.attention.self.key.weight]\n",
            "Loading weights:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 92/103 [00:00<00:00, 585.90it/s, Materializing param=encoder.layer.5.attention.self.query.bias]\n",
            "Loading weights:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 92/103 [00:00<00:00, 585.90it/s, Materializing param=encoder.layer.5.attention.self.query.bias]\n",
            "Loading weights:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 93/103 [00:00<00:00, 585.90it/s, Materializing param=encoder.layer.5.attention.self.query.weight]\n",
            "Loading weights:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 93/103 [00:00<00:00, 585.90it/s, Materializing param=encoder.layer.5.attention.self.query.weight]\n",
            "Loading weights:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 94/103 [00:00<00:00, 585.90it/s, Materializing param=encoder.layer.5.attention.self.value.bias]  \n",
            "Loading weights:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 94/103 [00:00<00:00, 585.90it/s, Materializing param=encoder.layer.5.attention.self.value.bias]\n",
            "Loading weights:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 95/103 [00:00<00:00, 585.90it/s, Materializing param=encoder.layer.5.attention.self.value.weight]\n",
            "Loading weights:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 95/103 [00:00<00:00, 585.90it/s, Materializing param=encoder.layer.5.attention.self.value.weight]\n",
            "Loading weights:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 96/103 [00:00<00:00, 585.90it/s, Materializing param=encoder.layer.5.intermediate.dense.bias]    \n",
            "Loading weights:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 96/103 [00:00<00:00, 585.90it/s, Materializing param=encoder.layer.5.intermediate.dense.bias]\n",
            "Loading weights:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 97/103 [00:00<00:00, 585.90it/s, Materializing param=encoder.layer.5.intermediate.dense.weight]\n",
            "Loading weights:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 97/103 [00:00<00:00, 585.90it/s, Materializing param=encoder.layer.5.intermediate.dense.weight]\n",
            "Loading weights:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 98/103 [00:00<00:00, 585.90it/s, Materializing param=encoder.layer.5.output.LayerNorm.bias]    \n",
            "Loading weights:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 98/103 [00:00<00:00, 585.90it/s, Materializing param=encoder.layer.5.output.LayerNorm.bias]\n",
            "Loading weights:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 99/103 [00:00<00:00, 585.90it/s, Materializing param=encoder.layer.5.output.LayerNorm.weight]\n",
            "Loading weights:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 99/103 [00:00<00:00, 585.90it/s, Materializing param=encoder.layer.5.output.LayerNorm.weight]\n",
            "Loading weights:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 100/103 [00:00<00:00, 585.90it/s, Materializing param=encoder.layer.5.output.dense.bias]     \n",
            "Loading weights:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 100/103 [00:00<00:00, 585.90it/s, Materializing param=encoder.layer.5.output.dense.bias]\n",
            "Loading weights:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 101/103 [00:00<00:00, 585.90it/s, Materializing param=encoder.layer.5.output.dense.weight]\n",
            "Loading weights:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 101/103 [00:00<00:00, 585.90it/s, Materializing param=encoder.layer.5.output.dense.weight]\n",
            "Loading weights:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 102/103 [00:00<00:00, 585.90it/s, Materializing param=pooler.dense.bias]                  \n",
            "Loading weights:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 102/103 [00:00<00:00, 585.90it/s, Materializing param=pooler.dense.bias]\n",
            "Loading weights: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 103/103 [00:00<00:00, 585.90it/s, Materializing param=pooler.dense.weight]\n",
            "Loading weights: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 103/103 [00:00<00:00, 585.90it/s, Materializing param=pooler.dense.weight]\n",
            "Loading weights: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 103/103 [00:00<00:00, 815.72it/s, Materializing param=pooler.dense.weight]\n",
            "BertModel LOAD REPORT from: sentence-transformers/all-MiniLM-L6-v2\n",
            "Key                     | Status     |  | \n",
            "------------------------+------------+--+-\n",
            "embeddings.position_ids | UNEXPECTED |  | \n",
            "\n",
            "Notes:\n",
            "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n",
            "INFO:httpx:HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/config.json \"HTTP/1.1 307 Temporary Redirect\"\n",
            "INFO:httpx:HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config.json \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/tokenizer_config.json \"HTTP/1.1 307 Temporary Redirect\"\n",
            "INFO:httpx:HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/tokenizer_config.json \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: GET https://huggingface.co/api/models/sentence-transformers/all-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=false&expand=false \"HTTP/1.1 404 Not Found\"\n",
            "INFO:httpx:HTTP Request: GET https://huggingface.co/api/models/sentence-transformers/all-MiniLM-L6-v2/tree/main?recursive=true&expand=false \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/1_Pooling/config.json \"HTTP/1.1 307 Temporary Redirect\"\n",
            "INFO:httpx:HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/1_Pooling%2Fconfig.json \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: GET https://huggingface.co/api/models/sentence-transformers/all-MiniLM-L6-v2 \"HTTP/1.1 200 OK\"\n",
            "INFO:     Application startup complete.\n",
            "INFO:     Uvicorn running on http://0.0.0.0:8002 (Press CTRL+C to quit)\n",
            "Memory service started on 0.0.0.0:8001\n",
            "INFO:     127.0.0.1:39108 - \"GET /health HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:39124 - \"GET /health HTTP/1.1\" 200 OK\n",
            "\n",
            "\n",
            "--- /tmp/code_exec.log ---\n",
            "INFO:     Started server process [17647]\n",
            "INFO:     Waiting for application startup.\n",
            "2026-02-08 03:27:08,601 - code_exec.service.main - INFO - Starting Code Executor Service\n",
            "2026-02-08 03:27:08,601 - code_exec.service.main - INFO - Skills directory: /Users/paragpradhan/Projects/Agent framework/agent-framework/code-exec/skills\n",
            "2026-02-08 03:27:08,601 - code_exec.service.registry - INFO - Loading skills from: /Users/paragpradhan/Projects/Agent framework/agent-framework/code-exec/skills\n",
            "2026-02-08 03:27:08,601 - code_exec.service.registry - INFO - Loaded 0 skills successfully\n",
            "2026-02-08 03:27:08,601 - code_exec.service.main - INFO - Loaded 0 skills\n",
            "2026-02-08 03:27:08,601 - code_exec.service.main - INFO - Service ready on 0.0.0.0:8002\n",
            "INFO:     Application startup complete.\n",
            "INFO:     Uvicorn running on http://0.0.0.0:8004 (Press CTRL+C to quit)\n",
            "INFO:     127.0.0.1:59214 - \"GET /health HTTP/1.1\" 200 OK\n",
            "\n",
            "\n",
            "--- /tmp/subagent_manager.log ---\n",
            "INFO:     Started server process [17676]\n",
            "INFO:     Waiting for application startup.\n",
            "INFO:     Application startup complete.\n",
            "INFO:     Uvicorn running on http://0.0.0.0:8003 (Press CTRL+C to quit)\n",
            "INFO:     127.0.0.1:46106 - \"GET /health HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:46112 - \"GET /health HTTP/1.1\" 200 OK\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ed8a78b8",
        "outputId": "ecb11961-0928-4d84-9d7a-14e08f038aa8"
      },
      "source": [
        "import subprocess, os\n",
        "\n",
        "print(\"=== PORT DIAGNOSTICS ===\")\n",
        "# Check what's listening on ports 9000 (MinIO) and 8004 (Code Exec)\n",
        "for port in [9000, 9001, 8004]:\n",
        "    print(f\"\\nChecking Port {port}...\")\n",
        "    # lsof -i :port\n",
        "    res = subprocess.run(f\"lsof -i :{port}\", shell=True, capture_output=True, text=True)\n",
        "    if res.stdout.strip():\n",
        "        print(res.stdout)\n",
        "    else:\n",
        "        print(\"  (No process found listening)\")\n",
        "\n",
        "print(\"\\n=== SERVICE LOGS (Last 50 lines) ===\")\n",
        "logs = [\"/tmp/minio.log\", \"/tmp/code_exec.log\", \"/tmp/memory_service.log\"]\n",
        "for log in logs:\n",
        "    print(f\"\\n--- {log} ---\")\n",
        "    if os.path.exists(log):\n",
        "        # check file size\n",
        "        size = os.path.getsize(log)\n",
        "        print(f\"  Size: {size} bytes\")\n",
        "        if size > 0:\n",
        "            subprocess.run(f\"tail -n 50 {log}\", shell=True)\n",
        "        else:\n",
        "            print(\"  (Empty file)\")\n",
        "    else:\n",
        "        print(\"  (File does not exist)\")"
      ],
      "id": "ed8a78b8",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== PORT DIAGNOSTICS ===\n",
            "\n",
            "Checking Port 9000...\n",
            "COMMAND   PID USER   FD   TYPE DEVICE SIZE/OFF NODE NAME\n",
            "kernel_ma  12 root    9u  IPv4 549882      0t0  TCP b2412b48cfa2:57236->b2412b48cfa2:9000 (ESTABLISHED)\n",
            "kernel_ma  12 root   10u  IPv4 550931      0t0  TCP b2412b48cfa2:57244->b2412b48cfa2:9000 (ESTABLISHED)\n",
            "jupyter-s 101 root    7u  IPv4 549865      0t0  TCP b2412b48cfa2:9000 (LISTEN)\n",
            "jupyter-s 101 root    8u  IPv4 549883      0t0  TCP b2412b48cfa2:9000->b2412b48cfa2:57236 (ESTABLISHED)\n",
            "jupyter-s 101 root   16u  IPv4 550932      0t0  TCP b2412b48cfa2:9000->b2412b48cfa2:57244 (ESTABLISHED)\n",
            "\n",
            "\n",
            "Checking Port 9001...\n",
            "COMMAND   PID USER   FD   TYPE DEVICE SIZE/OFF NODE NAME\n",
            "minio   17623 root    7u  IPv6 883794      0t0  TCP *:9001 (LISTEN)\n",
            "\n",
            "\n",
            "Checking Port 8004...\n",
            "COMMAND   PID USER   FD   TYPE DEVICE SIZE/OFF NODE NAME\n",
            "python3 17647 root   13u  IPv4 883168      0t0  TCP *:8004 (LISTEN)\n",
            "\n",
            "\n",
            "=== SERVICE LOGS (Last 50 lines) ===\n",
            "\n",
            "--- /tmp/minio.log ---\n",
            "  Size: 496 bytes\n",
            "\n",
            "--- /tmp/code_exec.log ---\n",
            "  Size: 911 bytes\n",
            "\n",
            "--- /tmp/memory_service.log ---\n",
            "  Size: 35052 bytes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "94b7a06a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "94b7a06a",
        "outputId": "ba0f5cad-3a34-498d-9542-0f5e7b32f7ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "PHASE 5: EXTERNAL ACCESS\n",
            "============================================================\n",
            "\n",
            "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
            "â•‘  ðŸš€ SYSTEM READY - ACCESS LINKS                         â•‘\n",
            "â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£\n",
            "â•‘  ðŸ“Š Dashboard: https://unliquid-blithely-glenda.ngrok-free.devâ•‘\n",
            "â•‘  ðŸ”Œ API:       https://unliquid-blithely-glenda.ngrok-free.devâ•‘\n",
            "â•‘  ðŸ“„ Docs:      https://unliquid-blithely-glenda.ngrok-free.dev/docsâ•‘\n",
            "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
        "# â•‘  PHASE 5: External Access (ngrok Tunnels)                   â•‘\n",
        "# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "import os\n",
        "from pyngrok import ngrok, conf\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"PHASE 5: EXTERNAL ACCESS\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Configuration\n",
        "NGROK_AUTH_TOKEN = \"39MaIP07IiJMHPNDgd3raMEOL6r_2KyacFVXP68bbxBu9s8E8\"\n",
        "\n",
        "if NGROK_AUTH_TOKEN:\n",
        "    ngrok.set_auth_token(NGROK_AUTH_TOKEN)\n",
        "    ngrok.kill()\n",
        "\n",
        "    # API Tunnel (8000)\n",
        "    api_tunnel = ngrok.connect(8000, \"http\")\n",
        "    api_url = api_tunnel.public_url\n",
        "\n",
        "    # Dashboard Tunnel (3000)\n",
        "    dash_tunnel = ngrok.connect(3000, \"http\")\n",
        "    dash_url = dash_tunnel.public_url\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\")\n",
        "    print(\"â•‘  ðŸš€ SYSTEM READY - ACCESS LINKS                         â•‘\")\n",
        "    print(\"â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£\")\n",
        "    print(f\"â•‘  ðŸ“Š Dashboard: {dash_url:<41s}â•‘\")\n",
        "    print(f\"â•‘  ðŸ”Œ API:       {api_url:<41s}â•‘\")\n",
        "    print(f\"â•‘  ðŸ“„ Docs:      {api_url + '/docs':<41s}â•‘\")\n",
        "    print(\"â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\")\n",
        "else:\n",
        "    print(\"âŒ No ngrok token found. Services available locally only.\")\n",
        "\n",
        "print(\"=\" * 60)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4658f5ae",
        "outputId": "efa7bc02-7e35-4523-d333-d3d7d73664af"
      },
      "source": [
        "import subprocess, os\n",
        "\n",
        "print(\"=== PORT CHECK ===\")\n",
        "# Check ports 3000 (Dashboard) and 8080 (MCP)\n",
        "for port in [3000, 8080]:\n",
        "    res = subprocess.run(f\"lsof -i :{port}\", shell=True, capture_output=True, text=True)\n",
        "    print(f\"\\n[:{port}] {'OPEN' if res.stdout.strip() else 'CLOSED'}\")\n",
        "    if res.stdout.strip():\n",
        "        print(res.stdout)\n",
        "\n",
        "print(\"\\n=== LOGS ===\")\n",
        "logs = [\"/tmp/dashboard.log\", \"/tmp/mcp_gateway.log\"]\n",
        "for log in logs:\n",
        "    print(f\"\\n--- {log} ---\")\n",
        "    if os.path.exists(log):\n",
        "        subprocess.run(f\"tail -n 50 {log}\", shell=True)\n",
        "    else:\n",
        "        print(\"(File not found)\")"
      ],
      "id": "4658f5ae",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== PORT CHECK ===\n",
            "\n",
            "[:3000] CLOSED\n",
            "\n",
            "[:8080] OPEN\n",
            "COMMAND PID USER   FD   TYPE DEVICE SIZE/OFF NODE NAME\n",
            "node      7 root   21u  IPv6 549965      0t0  TCP *:http-alt (LISTEN)\n",
            "node      7 root   26u  IPv6 550927      0t0  TCP b2412b48cfa2:http-alt->172.28.0.1:49222 (ESTABLISHED)\n",
            "node      7 root   28u  IPv6 890590      0t0  TCP b2412b48cfa2:http-alt->172.28.0.1:59338 (ESTABLISHED)\n",
            "\n",
            "\n",
            "=== LOGS ===\n",
            "\n",
            "--- /tmp/dashboard.log ---\n",
            "\n",
            "--- /tmp/mcp_gateway.log ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "b927a8c7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b927a8c7",
        "outputId": "25e2a513-3d04-4348-cddd-03e6d4d2d800"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "PHASE 6: SMOKE TEST\n",
            "============================================================\n",
            "  [PASS] Orchestrator (200)\n",
            "  [PASS] MCP Gateway (200)\n",
            "  [PASS] Code Exec (200)\n",
            "\n",
            "  Testing AI Inference... OK (49.6s)\n",
            "\n",
            "  âœ… ALL SYSTEMS GO!\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
        "# â•‘  PHASE 6: Quick Smoke Test                                  â•‘\n",
        "# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "import json, urllib.request, time\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"PHASE 6: SMOKE TEST\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Verify Health\n",
        "checks = [\n",
        "    (\"Orchestrator\", \"http://localhost:8000/health\"),\n",
        "    (\"MCP Gateway\",  \"http://localhost:8082/health\"),\n",
        "    (\"Code Exec\",    \"http://localhost:8004/health\")\n",
        "]\n",
        "for name, url in checks:\n",
        "    try:\n",
        "        code = urllib.request.urlopen(url, timeout=5).getcode()\n",
        "        print(f\"  [PASS] {name} ({code})\")\n",
        "    except Exception as e:\n",
        "        print(f\"  [WARN] {name} ({e})\")\n",
        "\n",
        "# Verify Inference\n",
        "print(\"\\n  Testing AI Inference...\", end=\" \", flush=True)\n",
        "try:\n",
        "    t0 = time.time()\n",
        "    data = json.dumps({\"model\": \"deepseek-r1:14b\", \"prompt\": \"Hello!\", \"stream\": False}).encode()\n",
        "    req = urllib.request.Request(\"http://localhost:11434/api/generate\", data=data, headers={\"Content-Type\": \"application/json\"})\n",
        "    urllib.request.urlopen(req, timeout=120)\n",
        "    print(f\"OK ({time.time()-t0:.1f}s)\")\n",
        "    print(\"\\n  âœ… ALL SYSTEMS GO!\")\n",
        "except Exception as e:\n",
        "    print(f\"FAIL ({e})\")\n",
        "print(\"=\" * 60)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bc99dfa4",
        "outputId": "4a2666ba-6638-464f-d228-18906037b9dd"
      },
      "source": [
        "import subprocess\n",
        "\n",
        "print(\"=== CHECKING SERVICE LOGS FOR ERRORS ===\")\n",
        "services = [\n",
        "    \"/tmp/orchestrator.log\",\n",
        "    \"/tmp/memory_service.log\",\n",
        "    \"/tmp/code_exec.log\",\n",
        "    \"/tmp/mcp_gateway.log\"\n",
        "]\n",
        "\n",
        "for log in services:\n",
        "    print(f\"\\n--- {log} ---\")\n",
        "    # Check if file exists first\n",
        "    try:\n",
        "        # Print last 30 lines of the log\n",
        "        result = subprocess.run([\"tail\", \"-n\", \"30\", log], capture_output=True, text=True)\n",
        "        print(result.stdout)\n",
        "        if result.stderr:\n",
        "            print(\"STDERR:\", result.stderr)\n",
        "    except Exception as e:\n",
        "        print(f\"Could not read log: {e}\")\n"
      ],
      "id": "bc99dfa4",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== CHECKING SERVICE LOGS FOR ERRORS ===\n",
            "\n",
            "--- /tmp/orchestrator.log ---\n",
            "INFO:     Started server process [17696]\n",
            "INFO:     Waiting for application startup.\n",
            "2026-02-08 03:27:17,718 - orchestrator.service.main - INFO - Starting Lead Agent/Orchestrator service...\n",
            "2026-02-08 03:27:17,718 - orchestrator.service.main - INFO - Configuration: LLM Provider=local\n",
            "2026-02-08 03:27:17,718 - orchestrator.service.main - INFO - MCP Gateway URL: http://localhost:8080\n",
            "2026-02-08 03:27:17,718 - orchestrator.service.main - INFO - Memory Service URL: http://localhost:8002\n",
            "2026-02-08 03:27:17,847 - orchestrator.service.main - INFO - WebSocket manager initialized\n",
            "2026-02-08 03:27:17,850 - orchestrator.service.session_storage - INFO - Connected to Redis at redis://localhost:6379/0\n",
            "2026-02-08 03:27:17,850 - orchestrator.service.agent - INFO - Session storage initialized\n",
            "2026-02-08 03:27:17,850 - orchestrator.service.memory_learning - INFO - MemoryLearningClient initialized: memory_dir=/content/ai_final/agentic-framework-main/workspace/.copilot/memory\n",
            "2026-02-08 03:27:17,850 - orchestrator.service.agent_manager - INFO - Memory learning client initialized\n",
            "2026-02-08 03:27:17,850 - orchestrator.service.agent_manager - INFO - Agent manager started\n",
            "2026-02-08 03:27:17,850 - orchestrator.service.agent - INFO - Agent manager initialized\n",
            "2026-02-08 03:27:17,851 - orchestrator.service.agent - INFO - OrchestratorAgent fully initialized\n",
            "2026-02-08 03:27:17,851 - orchestrator.service.main - INFO - Orchestrator agent initialized with persistent storage\n",
            "2026-02-08 03:27:17,851 - orchestrator.service.main - INFO - Orchestrator service started successfully\n",
            "INFO:     Application startup complete.\n",
            "INFO:     Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit)\n",
            "2026-02-08 03:28:03,781 - httpx - INFO - HTTP Request: GET http://localhost:8080/health \"HTTP/1.1 404 Not Found\"\n",
            "2026-02-08 03:28:03,785 - httpx - INFO - HTTP Request: GET http://localhost:8002/health \"HTTP/1.1 200 OK\"\n",
            "2026-02-08 03:28:03,788 - httpx - INFO - HTTP Request: GET http://localhost:8003/health \"HTTP/1.1 200 OK\"\n",
            "INFO:     127.0.0.1:56762 - \"GET /health HTTP/1.1\" 200 OK\n",
            "2026-02-08 03:28:07,112 - httpx - INFO - HTTP Request: GET http://localhost:8080/health \"HTTP/1.1 404 Not Found\"\n",
            "2026-02-08 03:28:07,116 - httpx - INFO - HTTP Request: GET http://localhost:8002/health \"HTTP/1.1 200 OK\"\n",
            "2026-02-08 03:28:07,122 - httpx - INFO - HTTP Request: GET http://localhost:8003/health \"HTTP/1.1 200 OK\"\n",
            "INFO:     127.0.0.1:56778 - \"GET /health HTTP/1.1\" 200 OK\n",
            "\n",
            "\n",
            "--- /tmp/memory_service.log ---\n",
            "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n",
            "WARNING:huggingface_hub.utils._http:Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n",
            "INFO:httpx:HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/config.json \"HTTP/1.1 307 Temporary Redirect\"\n",
            "INFO:httpx:HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config.json \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/config.json \"HTTP/1.1 307 Temporary Redirect\"\n",
            "INFO:httpx:HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config.json \"HTTP/1.1 200 OK\"\n",
            "\n",
            "Loading weights:   0%|          | 0/103 [00:00<?, ?it/s]\n",
            "Loading weights:   1%|          | 1/103 [00:00<00:00, 32263.88it/s, Materializing param=embeddings.LayerNorm.bias]\n",
            "Loading weights:   1%|          | 1/103 [00:00<00:00, 9279.43it/s, Materializing param=embeddings.LayerNorm.bias] \n",
            "Loading weights:   2%|â–         | 2/103 [00:00<00:00, 6775.94it/s, Materializing param=embeddings.LayerNorm.weight]\n",
            "Loading weights:   2%|â–         | 2/103 [00:00<00:00, 5511.57it/s, Materializing param=embeddings.LayerNorm.weight]\n",
            "Loading weights:   3%|â–Ž         | 3/103 [00:00<00:00, 6000.43it/s, Materializing param=embeddings.position_embeddings.weight]\n",
            "Loading weights:   3%|â–Ž         | 3/103 [00:00<00:00, 4721.54it/s, Materializing param=embeddings.position_embeddings.weight]\n",
            "Loading weights:   4%|â–         | 4/103 [00:00<00:00, 5140.08it/s, Materializing param=embeddings.token_type_embeddings.weight]\n",
            "Loading weights:   4%|â–         | 4/103 [00:00<00:00, 4792.12it/s, Materializing param=embeddings.token_type_embeddings.weight]\n",
            "Loading weights:   5%|â–         | 5/103 [00:00<00:00, 5363.56it/s, Materializing param=embeddings.word_embeddings.weight]      \n",
            "Loading weights:   5%|â–         | 5/103 [00:00<00:00, 5041.23it/s, Materializing param=embeddings.word_embeddings.weight]\n",
            "Loading weights:   6%|â–Œ         | 6/103 [00:00<00:00, 5511.57it/s, Materializing param=encoder.layer.0.attention.output.LayerNorm.bias]\n",
            "Loading weights:   6%|â–Œ         | 6/103 [00:00<00:00, 5253.83it/s, Materializing param=encoder.layer.0.attention.output.LayerNorm.bias]\n",
            "Loading weights:   7%|â–‹         | 7/103 [00:00<00:00, 5566.96it/s, Materializing param=encoder.layer.0.attention.output.LayerNorm.weight]\n",
            "Loading weights:   7%|â–‹         | 7/103 [00:00<00:00, 5346.95it/s, Materializing param=encoder.layer.0.attention.output.LayerNorm.weight]\n",
            "Loading weights:   8%|â–Š         | 8/103 [00:00<00:00, 5697.81it/s, Materializing param=encoder.layer.0.attention.output.dense.bias]      \n",
            "Loading weights:   8%|â–Š         | 8/103 [00:00<00:00, 5505.24it/s, Materializing param=encoder.layer.0.attention.output.dense.bias]\n",
            "Loading weights:   9%|â–Š         | 9/103 [00:00<00:00, 983.09it/s, Materializing param=encoder.layer.0.attention.output.dense.weight]\n",
            "Loading weights:   9%|â–Š         | 9/103 [00:00<00:00, 967.52it/s, Materializing param=encoder.layer.0.attention.output.dense.weight]\n",
            "Loading weights:  10%|â–‰         | 10/103 [00:00<00:00, 952.10it/s, Materializing param=encoder.layer.0.attention.self.key.bias]     \n",
            "Loading weights:  10%|â–‰         | 10/103 [00:00<00:00, 931.43it/s, Materializing param=encoder.layer.0.attention.self.key.bias]\n",
            "Loading weights:  11%|â–ˆ         | 11/103 [00:00<00:00, 971.70it/s, Materializing param=encoder.layer.0.attention.self.key.weight]\n",
            "Loading weights:  11%|â–ˆ         | 11/103 [00:00<00:00, 962.62it/s, Materializing param=encoder.layer.0.attention.self.key.weight]\n",
            "Loading weights:  12%|â–ˆâ–        | 12/103 [00:00<00:00, 663.98it/s, Materializing param=encoder.layer.0.attention.self.query.bias]\n",
            "Loading weights:  12%|â–ˆâ–        | 12/103 [00:00<00:00, 660.10it/s, Materializing param=encoder.layer.0.attention.self.query.bias]\n",
            "Loading weights:  13%|â–ˆâ–Ž        | 13/103 [00:00<00:00, 706.29it/s, Materializing param=encoder.layer.0.attention.self.query.weight]\n",
            "Loading weights:  13%|â–ˆâ–Ž        | 13/103 [00:00<00:00, 702.72it/s, Materializing param=encoder.layer.0.attention.self.query.weight]\n",
            "Loading weights:  14%|â–ˆâ–Ž        | 14/103 [00:00<00:00, 737.65it/s, Materializing param=encoder.layer.0.attention.self.value.bias]  \n",
            "Loading weights:  14%|â–ˆâ–Ž        | 14/103 [00:00<00:00, 733.58it/s, Materializing param=encoder.layer.0.attention.self.value.bias]\n",
            "Loading weights:  15%|â–ˆâ–        | 15/103 [00:00<00:00, 778.28it/s, Materializing param=encoder.layer.0.attention.self.value.weight]\n",
            "Loading weights:  15%|â–ˆâ–        | 15/103 [00:00<00:00, 775.50it/s, Materializing param=encoder.layer.0.attention.self.value.weight]\n",
            "Loading weights:  16%|â–ˆâ–Œ        | 16/103 [00:00<00:00, 822.40it/s, Materializing param=encoder.layer.0.intermediate.dense.bias]    \n",
            "Loading weights:  16%|â–ˆâ–Œ        | 16/103 [00:00<00:00, 820.15it/s, Materializing param=encoder.layer.0.intermediate.dense.bias]\n",
            "Loading weights:  17%|â–ˆâ–‹        | 17/103 [00:00<00:00, 862.65it/s, Materializing param=encoder.layer.0.intermediate.dense.weight]\n",
            "Loading weights:  17%|â–ˆâ–‹        | 17/103 [00:00<00:00, 858.26it/s, Materializing param=encoder.layer.0.intermediate.dense.weight]\n",
            "Loading weights:  17%|â–ˆâ–‹        | 18/103 [00:00<00:00, 899.43it/s, Materializing param=encoder.layer.0.output.LayerNorm.bias]    \n",
            "Loading weights:  17%|â–ˆâ–‹        | 18/103 [00:00<00:00, 894.36it/s, Materializing param=encoder.layer.0.output.LayerNorm.bias]\n",
            "Loading weights:  18%|â–ˆâ–Š        | 19/103 [00:00<00:00, 934.57it/s, Materializing param=encoder.layer.0.output.LayerNorm.weight]\n",
            "Loading weights:  18%|â–ˆâ–Š        | 19/103 [00:00<00:00, 929.85it/s, Materializing param=encoder.layer.0.output.LayerNorm.weight]\n",
            "Loading weights:  19%|â–ˆâ–‰        | 20/103 [00:00<00:00, 721.19it/s, Materializing param=encoder.layer.0.output.dense.bias]      \n",
            "Loading weights:  19%|â–ˆâ–‰        | 20/103 [00:00<00:00, 717.33it/s, Materializing param=encoder.layer.0.output.dense.bias]\n",
            "Loading weights:  20%|â–ˆâ–ˆ        | 21/103 [00:00<00:00, 746.68it/s, Materializing param=encoder.layer.0.output.dense.weight]\n",
            "Loading weights:  20%|â–ˆâ–ˆ        | 21/103 [00:00<00:00, 742.78it/s, Materializing param=encoder.layer.0.output.dense.weight]\n",
            "Loading weights:  21%|â–ˆâ–ˆâ–       | 22/103 [00:00<00:00, 773.52it/s, Materializing param=encoder.layer.1.attention.output.LayerNorm.bias]\n",
            "Loading weights:  21%|â–ˆâ–ˆâ–       | 22/103 [00:00<00:00, 770.88it/s, Materializing param=encoder.layer.1.attention.output.LayerNorm.bias]\n",
            "Loading weights:  22%|â–ˆâ–ˆâ–       | 23/103 [00:00<00:00, 799.90it/s, Materializing param=encoder.layer.1.attention.output.LayerNorm.weight]\n",
            "Loading weights:  22%|â–ˆâ–ˆâ–       | 23/103 [00:00<00:00, 796.72it/s, Materializing param=encoder.layer.1.attention.output.LayerNorm.weight]\n",
            "Loading weights:  23%|â–ˆâ–ˆâ–Ž       | 24/103 [00:00<00:00, 825.63it/s, Materializing param=encoder.layer.1.attention.output.dense.bias]      \n",
            "Loading weights:  23%|â–ˆâ–ˆâ–Ž       | 24/103 [00:00<00:00, 822.82it/s, Materializing param=encoder.layer.1.attention.output.dense.bias]\n",
            "Loading weights:  24%|â–ˆâ–ˆâ–       | 25/103 [00:00<00:00, 852.00it/s, Materializing param=encoder.layer.1.attention.output.dense.weight]\n",
            "Loading weights:  24%|â–ˆâ–ˆâ–       | 25/103 [00:00<00:00, 849.38it/s, Materializing param=encoder.layer.1.attention.output.dense.weight]\n",
            "Loading weights:  25%|â–ˆâ–ˆâ–Œ       | 26/103 [00:00<00:00, 656.68it/s, Materializing param=encoder.layer.1.attention.self.key.bias]      \n",
            "Loading weights:  25%|â–ˆâ–ˆâ–Œ       | 26/103 [00:00<00:00, 654.43it/s, Materializing param=encoder.layer.1.attention.self.key.bias]\n",
            "Loading weights:  26%|â–ˆâ–ˆâ–Œ       | 27/103 [00:00<00:00, 675.69it/s, Materializing param=encoder.layer.1.attention.self.key.weight]\n",
            "Loading weights:  26%|â–ˆâ–ˆâ–Œ       | 27/103 [00:00<00:00, 673.60it/s, Materializing param=encoder.layer.1.attention.self.key.weight]\n",
            "Loading weights:  27%|â–ˆâ–ˆâ–‹       | 28/103 [00:00<00:00, 695.02it/s, Materializing param=encoder.layer.1.attention.self.query.bias]\n",
            "Loading weights:  27%|â–ˆâ–ˆâ–‹       | 28/103 [00:00<00:00, 693.18it/s, Materializing param=encoder.layer.1.attention.self.query.bias]\n",
            "Loading weights:  28%|â–ˆâ–ˆâ–Š       | 29/103 [00:00<00:00, 714.15it/s, Materializing param=encoder.layer.1.attention.self.query.weight]\n",
            "Loading weights:  28%|â–ˆâ–ˆâ–Š       | 29/103 [00:00<00:00, 712.12it/s, Materializing param=encoder.layer.1.attention.self.query.weight]\n",
            "Loading weights:  29%|â–ˆâ–ˆâ–‰       | 30/103 [00:00<00:00, 733.12it/s, Materializing param=encoder.layer.1.attention.self.value.bias]  \n",
            "Loading weights:  29%|â–ˆâ–ˆâ–‰       | 30/103 [00:00<00:00, 731.01it/s, Materializing param=encoder.layer.1.attention.self.value.bias]\n",
            "Loading weights:  30%|â–ˆâ–ˆâ–ˆ       | 31/103 [00:00<00:00, 751.15it/s, Materializing param=encoder.layer.1.attention.self.value.weight]\n",
            "Loading weights:  30%|â–ˆâ–ˆâ–ˆ       | 31/103 [00:00<00:00, 749.16it/s, Materializing param=encoder.layer.1.attention.self.value.weight]\n",
            "Loading weights:  31%|â–ˆâ–ˆâ–ˆ       | 32/103 [00:00<00:00, 596.93it/s, Materializing param=encoder.layer.1.intermediate.dense.bias]    \n",
            "Loading weights:  31%|â–ˆâ–ˆâ–ˆ       | 32/103 [00:00<00:00, 595.29it/s, Materializing param=encoder.layer.1.intermediate.dense.bias]\n",
            "Loading weights:  32%|â–ˆâ–ˆâ–ˆâ–      | 33/103 [00:00<00:00, 611.02it/s, Materializing param=encoder.layer.1.intermediate.dense.weight]\n",
            "Loading weights:  32%|â–ˆâ–ˆâ–ˆâ–      | 33/103 [00:00<00:00, 609.57it/s, Materializing param=encoder.layer.1.intermediate.dense.weight]\n",
            "Loading weights:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 34/103 [00:00<00:00, 625.59it/s, Materializing param=encoder.layer.1.output.LayerNorm.bias]    \n",
            "Loading weights:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 34/103 [00:00<00:00, 624.36it/s, Materializing param=encoder.layer.1.output.LayerNorm.bias]\n",
            "Loading weights:  34%|â–ˆâ–ˆâ–ˆâ–      | 35/103 [00:00<00:00, 640.07it/s, Materializing param=encoder.layer.1.output.LayerNorm.weight]\n",
            "Loading weights:  34%|â–ˆâ–ˆâ–ˆâ–      | 35/103 [00:00<00:00, 638.78it/s, Materializing param=encoder.layer.1.output.LayerNorm.weight]\n",
            "Loading weights:  35%|â–ˆâ–ˆâ–ˆâ–      | 36/103 [00:00<00:00, 654.14it/s, Materializing param=encoder.layer.1.output.dense.bias]      \n",
            "Loading weights:  35%|â–ˆâ–ˆâ–ˆâ–      | 36/103 [00:00<00:00, 652.77it/s, Materializing param=encoder.layer.1.output.dense.bias]\n",
            "Loading weights:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 37/103 [00:00<00:00, 668.36it/s, Materializing param=encoder.layer.1.output.dense.weight]\n",
            "Loading weights:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 37/103 [00:00<00:00, 667.21it/s, Materializing param=encoder.layer.1.output.dense.weight]\n",
            "Loading weights:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 38/103 [00:00<00:00, 633.43it/s, Materializing param=encoder.layer.2.attention.output.LayerNorm.bias]\n",
            "Loading weights:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 38/103 [00:00<00:00, 632.28it/s, Materializing param=encoder.layer.2.attention.output.LayerNorm.bias]\n",
            "Loading weights:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 39/103 [00:00<00:00, 645.94it/s, Materializing param=encoder.layer.2.attention.output.LayerNorm.weight]\n",
            "Loading weights:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 39/103 [00:00<00:00, 644.89it/s, Materializing param=encoder.layer.2.attention.output.LayerNorm.weight]\n",
            "Loading weights:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 40/103 [00:00<00:00, 624.87it/s, Materializing param=encoder.layer.2.attention.output.dense.bias]      \n",
            "Loading weights:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 40/103 [00:00<00:00, 622.93it/s, Materializing param=encoder.layer.2.attention.output.dense.bias]\n",
            "Loading weights:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 41/103 [00:00<00:00, 634.51it/s, Materializing param=encoder.layer.2.attention.output.dense.weight]\n",
            "Loading weights:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 41/103 [00:00<00:00, 633.49it/s, Materializing param=encoder.layer.2.attention.output.dense.weight]\n",
            "Loading weights:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 42/103 [00:00<00:00, 629.76it/s, Materializing param=encoder.layer.2.attention.self.key.bias]      \n",
            "Loading weights:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 42/103 [00:00<00:00, 628.43it/s, Materializing param=encoder.layer.2.attention.self.key.bias]\n",
            "Loading weights:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/103 [00:00<00:00, 615.15it/s, Materializing param=encoder.layer.2.attention.self.key.weight]\n",
            "Loading weights:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/103 [00:00<00:00, 613.53it/s, Materializing param=encoder.layer.2.attention.self.key.weight]\n",
            "Loading weights:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 44/103 [00:00<00:00, 625.17it/s, Materializing param=encoder.layer.2.attention.self.query.bias]\n",
            "Loading weights:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 44/103 [00:00<00:00, 624.27it/s, Materializing param=encoder.layer.2.attention.self.query.bias]\n",
            "Loading weights:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 45/103 [00:00<00:00, 610.89it/s, Materializing param=encoder.layer.2.attention.self.query.weight]\n",
            "Loading weights:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 45/103 [00:00<00:00, 586.05it/s, Materializing param=encoder.layer.2.attention.self.query.weight]\n",
            "Loading weights:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 46/103 [00:00<00:00, 596.47it/s, Materializing param=encoder.layer.2.attention.self.value.bias]  \n",
            "Loading weights:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 46/103 [00:00<00:00, 595.54it/s, Materializing param=encoder.layer.2.attention.self.value.bias]\n",
            "Loading weights:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 47/103 [00:00<00:00, 605.26it/s, Materializing param=encoder.layer.2.attention.self.value.weight]\n",
            "Loading weights:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 47/103 [00:00<00:00, 604.21it/s, Materializing param=encoder.layer.2.attention.self.value.weight]\n",
            "Loading weights:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 48/103 [00:00<00:00, 615.06it/s, Materializing param=encoder.layer.2.intermediate.dense.bias]    \n",
            "Loading weights:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 48/103 [00:00<00:00, 614.10it/s, Materializing param=encoder.layer.2.intermediate.dense.bias]\n",
            "Loading weights:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 49/103 [00:00<00:00, 624.91it/s, Materializing param=encoder.layer.2.intermediate.dense.weight]\n",
            "Loading weights:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 49/103 [00:00<00:00, 623.80it/s, Materializing param=encoder.layer.2.intermediate.dense.weight]\n",
            "Loading weights:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 50/103 [00:00<00:00, 634.56it/s, Materializing param=encoder.layer.2.output.LayerNorm.bias]    \n",
            "Loading weights:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 50/103 [00:00<00:00, 633.59it/s, Materializing param=encoder.layer.2.output.LayerNorm.bias]\n",
            "Loading weights:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 51/103 [00:00<00:00, 644.34it/s, Materializing param=encoder.layer.2.output.LayerNorm.weight]\n",
            "Loading weights:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 51/103 [00:00<00:00, 643.25it/s, Materializing param=encoder.layer.2.output.LayerNorm.weight]\n",
            "Loading weights:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 52/103 [00:00<00:00, 653.91it/s, Materializing param=encoder.layer.2.output.dense.bias]      \n",
            "Loading weights:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 52/103 [00:00<00:00, 592.26it/s, Materializing param=encoder.layer.2.output.dense.bias]\n",
            "Loading weights:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 53/103 [00:00<00:00, 601.51it/s, Materializing param=encoder.layer.2.output.dense.weight]\n",
            "Loading weights:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 53/103 [00:00<00:00, 600.54it/s, Materializing param=encoder.layer.2.output.dense.weight]\n",
            "Loading weights:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 54/103 [00:00<00:00, 610.03it/s, Materializing param=encoder.layer.3.attention.output.LayerNorm.bias]\n",
            "Loading weights:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 54/103 [00:00<00:00, 608.95it/s, Materializing param=encoder.layer.3.attention.output.LayerNorm.bias]\n",
            "Loading weights:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 55/103 [00:00<00:00, 618.51it/s, Materializing param=encoder.layer.3.attention.output.LayerNorm.weight]\n",
            "Loading weights:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 55/103 [00:00<00:00, 617.57it/s, Materializing param=encoder.layer.3.attention.output.LayerNorm.weight]\n",
            "Loading weights:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 56/103 [00:00<00:00, 626.95it/s, Materializing param=encoder.layer.3.attention.output.dense.bias]      \n",
            "Loading weights:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 56/103 [00:00<00:00, 626.21it/s, Materializing param=encoder.layer.3.attention.output.dense.bias]\n",
            "Loading weights:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 57/103 [00:00<00:00, 592.87it/s, Materializing param=encoder.layer.3.attention.output.dense.weight]\n",
            "Loading weights:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 57/103 [00:00<00:00, 591.90it/s, Materializing param=encoder.layer.3.attention.output.dense.weight]\n",
            "Loading weights:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 58/103 [00:00<00:00, 600.57it/s, Materializing param=encoder.layer.3.attention.self.key.bias]      \n",
            "Loading weights:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 58/103 [00:00<00:00, 599.81it/s, Materializing param=encoder.layer.3.attention.self.key.bias]\n",
            "Loading weights:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 59/103 [00:00<00:00, 608.72it/s, Materializing param=encoder.layer.3.attention.self.key.weight]\n",
            "Loading weights:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 59/103 [00:00<00:00, 608.01it/s, Materializing param=encoder.layer.3.attention.self.key.weight]\n",
            "Loading weights:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 60/103 [00:00<00:00, 616.78it/s, Materializing param=encoder.layer.3.attention.self.query.bias]\n",
            "Loading weights:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 60/103 [00:00<00:00, 616.09it/s, Materializing param=encoder.layer.3.attention.self.query.bias]\n",
            "Loading weights:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 61/103 [00:00<00:00, 585.90it/s, Materializing param=encoder.layer.3.attention.self.query.bias]\n",
            "Loading weights:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 61/103 [00:00<00:00, 585.90it/s, Materializing param=encoder.layer.3.attention.self.query.weight]\n",
            "Loading weights:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 61/103 [00:00<00:00, 585.90it/s, Materializing param=encoder.layer.3.attention.self.query.weight]\n",
            "Loading weights:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 62/103 [00:00<00:00, 585.90it/s, Materializing param=encoder.layer.3.attention.self.value.bias]  \n",
            "Loading weights:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 62/103 [00:00<00:00, 585.90it/s, Materializing param=encoder.layer.3.attention.self.value.bias]\n",
            "Loading weights:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 63/103 [00:00<00:00, 585.90it/s, Materializing param=encoder.layer.3.attention.self.value.weight]\n",
            "Loading weights:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 63/103 [00:00<00:00, 585.90it/s, Materializing param=encoder.layer.3.attention.self.value.weight]\n",
            "Loading weights:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 64/103 [00:00<00:00, 585.90it/s, Materializing param=encoder.layer.3.intermediate.dense.bias]    \n",
            "Loading weights:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 64/103 [00:00<00:00, 585.90it/s, Materializing param=encoder.layer.3.intermediate.dense.bias]\n",
            "Loading weights:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 65/103 [00:00<00:00, 585.90it/s, Materializing param=encoder.layer.3.intermediate.dense.weight]\n",
            "Loading weights:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 65/103 [00:00<00:00, 585.90it/s, Materializing param=encoder.layer.3.intermediate.dense.weight]\n",
            "Loading weights:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 66/103 [00:00<00:00, 585.90it/s, Materializing param=encoder.layer.3.output.LayerNorm.bias]    \n",
            "Loading weights:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 66/103 [00:00<00:00, 585.90it/s, Materializing param=encoder.layer.3.output.LayerNorm.bias]\n",
            "Loading weights:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 67/103 [00:00<00:00, 585.90it/s, Materializing param=encoder.layer.3.output.LayerNorm.weight]\n",
            "Loading weights:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 67/103 [00:00<00:00, 585.90it/s, Materializing param=encoder.layer.3.output.LayerNorm.weight]\n",
            "Loading weights:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 68/103 [00:00<00:00, 585.90it/s, Materializing param=encoder.layer.3.output.dense.bias]      \n",
            "Loading weights:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 68/103 [00:00<00:00, 585.90it/s, Materializing param=encoder.layer.3.output.dense.bias]\n",
            "Loading weights:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 69/103 [00:00<00:00, 585.90it/s, Materializing param=encoder.layer.3.output.dense.weight]\n",
            "Loading weights:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 69/103 [00:00<00:00, 585.90it/s, Materializing param=encoder.layer.3.output.dense.weight]\n",
            "Loading weights:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 70/103 [00:00<00:00, 585.90it/s, Materializing param=encoder.layer.4.attention.output.LayerNorm.bias]\n",
            "Loading weights:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 70/103 [00:00<00:00, 585.90it/s, Materializing param=encoder.layer.4.attention.output.LayerNorm.bias]\n",
            "Loading weights:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 71/103 [00:00<00:00, 585.90it/s, Materializing param=encoder.layer.4.attention.output.LayerNorm.weight]\n",
            "Loading weights:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 71/103 [00:00<00:00, 585.90it/s, Materializing param=encoder.layer.4.attention.output.LayerNorm.weight]\n",
            "Loading weights:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 72/103 [00:00<00:00, 585.90it/s, Materializing param=encoder.layer.4.attention.output.dense.bias]      \n",
            "Loading weights:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 72/103 [00:00<00:00, 585.90it/s, Materializing param=encoder.layer.4.attention.output.dense.bias]\n",
            "Loading weights:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 73/103 [00:00<00:00, 585.90it/s, Materializing param=encoder.layer.4.attention.output.dense.weight]\n",
            "Loading weights:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 73/103 [00:00<00:00, 585.90it/s, Materializing param=encoder.layer.4.attention.output.dense.weight]\n",
            "Loading weights:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 74/103 [00:00<00:00, 585.90it/s, Materializing param=encoder.layer.4.attention.self.key.bias]      \n",
            "Loading weights:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 74/103 [00:00<00:00, 585.90it/s, Materializing param=encoder.layer.4.attention.self.key.bias]\n",
            "Loading weights:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 75/103 [00:00<00:00, 585.90it/s, Materializing param=encoder.layer.4.attention.self.key.weight]\n",
            "Loading weights:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 75/103 [00:00<00:00, 585.90it/s, Materializing param=encoder.layer.4.attention.self.key.weight]\n",
            "Loading weights:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 76/103 [00:00<00:00, 585.90it/s, Materializing param=encoder.layer.4.attention.self.query.bias]\n",
            "Loading weights:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 76/103 [00:00<00:00, 585.90it/s, Materializing param=encoder.layer.4.attention.self.query.bias]\n",
            "Loading weights:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 77/103 [00:00<00:00, 585.90it/s, Materializing param=encoder.layer.4.attention.self.query.weight]\n",
            "Loading weights:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 77/103 [00:00<00:00, 585.90it/s, Materializing param=encoder.layer.4.attention.self.query.weight]\n",
            "Loading weights:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 78/103 [00:00<00:00, 585.90it/s, Materializing param=encoder.layer.4.attention.self.value.bias]  \n",
            "Loading weights:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 78/103 [00:00<00:00, 585.90it/s, Materializing param=encoder.layer.4.attention.self.value.bias]\n",
            "Loading weights:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 79/103 [00:00<00:00, 585.90it/s, Materializing param=encoder.layer.4.attention.self.value.weight]\n",
            "Loading weights:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 79/103 [00:00<00:00, 585.90it/s, Materializing param=encoder.layer.4.attention.self.value.weight]\n",
            "Loading weights:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 80/103 [00:00<00:00, 585.90it/s, Materializing param=encoder.layer.4.intermediate.dense.bias]    \n",
            "Loading weights:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 80/103 [00:00<00:00, 585.90it/s, Materializing param=encoder.layer.4.intermediate.dense.bias]\n",
            "Loading weights:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 81/103 [00:00<00:00, 585.90it/s, Materializing param=encoder.layer.4.intermediate.dense.weight]\n",
            "Loading weights:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 81/103 [00:00<00:00, 585.90it/s, Materializing param=encoder.layer.4.intermediate.dense.weight]\n",
            "Loading weights:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 82/103 [00:00<00:00, 585.90it/s, Materializing param=encoder.layer.4.output.LayerNorm.bias]    \n",
            "Loading weights:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 82/103 [00:00<00:00, 585.90it/s, Materializing param=encoder.layer.4.output.LayerNorm.bias]\n",
            "Loading weights:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 83/103 [00:00<00:00, 585.90it/s, Materializing param=encoder.layer.4.output.LayerNorm.weight]\n",
            "Loading weights:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 83/103 [00:00<00:00, 585.90it/s, Materializing param=encoder.layer.4.output.LayerNorm.weight]\n",
            "Loading weights:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 84/103 [00:00<00:00, 585.90it/s, Materializing param=encoder.layer.4.output.dense.bias]      \n",
            "Loading weights:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 84/103 [00:00<00:00, 585.90it/s, Materializing param=encoder.layer.4.output.dense.bias]\n",
            "Loading weights:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 85/103 [00:00<00:00, 585.90it/s, Materializing param=encoder.layer.4.output.dense.weight]\n",
            "Loading weights:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 85/103 [00:00<00:00, 585.90it/s, Materializing param=encoder.layer.4.output.dense.weight]\n",
            "Loading weights:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 86/103 [00:00<00:00, 585.90it/s, Materializing param=encoder.layer.5.attention.output.LayerNorm.bias]\n",
            "Loading weights:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 86/103 [00:00<00:00, 585.90it/s, Materializing param=encoder.layer.5.attention.output.LayerNorm.bias]\n",
            "Loading weights:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 87/103 [00:00<00:00, 585.90it/s, Materializing param=encoder.layer.5.attention.output.LayerNorm.weight]\n",
            "Loading weights:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 87/103 [00:00<00:00, 585.90it/s, Materializing param=encoder.layer.5.attention.output.LayerNorm.weight]\n",
            "Loading weights:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 88/103 [00:00<00:00, 585.90it/s, Materializing param=encoder.layer.5.attention.output.dense.bias]      \n",
            "Loading weights:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 88/103 [00:00<00:00, 585.90it/s, Materializing param=encoder.layer.5.attention.output.dense.bias]\n",
            "Loading weights:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 89/103 [00:00<00:00, 585.90it/s, Materializing param=encoder.layer.5.attention.output.dense.weight]\n",
            "Loading weights:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 89/103 [00:00<00:00, 585.90it/s, Materializing param=encoder.layer.5.attention.output.dense.weight]\n",
            "Loading weights:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 90/103 [00:00<00:00, 585.90it/s, Materializing param=encoder.layer.5.attention.self.key.bias]      \n",
            "Loading weights:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 90/103 [00:00<00:00, 585.90it/s, Materializing param=encoder.layer.5.attention.self.key.bias]\n",
            "Loading weights:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 91/103 [00:00<00:00, 585.90it/s, Materializing param=encoder.layer.5.attention.self.key.weight]\n",
            "Loading weights:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 91/103 [00:00<00:00, 585.90it/s, Materializing param=encoder.layer.5.attention.self.key.weight]\n",
            "Loading weights:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 92/103 [00:00<00:00, 585.90it/s, Materializing param=encoder.layer.5.attention.self.query.bias]\n",
            "Loading weights:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 92/103 [00:00<00:00, 585.90it/s, Materializing param=encoder.layer.5.attention.self.query.bias]\n",
            "Loading weights:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 93/103 [00:00<00:00, 585.90it/s, Materializing param=encoder.layer.5.attention.self.query.weight]\n",
            "Loading weights:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 93/103 [00:00<00:00, 585.90it/s, Materializing param=encoder.layer.5.attention.self.query.weight]\n",
            "Loading weights:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 94/103 [00:00<00:00, 585.90it/s, Materializing param=encoder.layer.5.attention.self.value.bias]  \n",
            "Loading weights:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 94/103 [00:00<00:00, 585.90it/s, Materializing param=encoder.layer.5.attention.self.value.bias]\n",
            "Loading weights:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 95/103 [00:00<00:00, 585.90it/s, Materializing param=encoder.layer.5.attention.self.value.weight]\n",
            "Loading weights:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 95/103 [00:00<00:00, 585.90it/s, Materializing param=encoder.layer.5.attention.self.value.weight]\n",
            "Loading weights:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 96/103 [00:00<00:00, 585.90it/s, Materializing param=encoder.layer.5.intermediate.dense.bias]    \n",
            "Loading weights:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 96/103 [00:00<00:00, 585.90it/s, Materializing param=encoder.layer.5.intermediate.dense.bias]\n",
            "Loading weights:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 97/103 [00:00<00:00, 585.90it/s, Materializing param=encoder.layer.5.intermediate.dense.weight]\n",
            "Loading weights:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 97/103 [00:00<00:00, 585.90it/s, Materializing param=encoder.layer.5.intermediate.dense.weight]\n",
            "Loading weights:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 98/103 [00:00<00:00, 585.90it/s, Materializing param=encoder.layer.5.output.LayerNorm.bias]    \n",
            "Loading weights:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 98/103 [00:00<00:00, 585.90it/s, Materializing param=encoder.layer.5.output.LayerNorm.bias]\n",
            "Loading weights:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 99/103 [00:00<00:00, 585.90it/s, Materializing param=encoder.layer.5.output.LayerNorm.weight]\n",
            "Loading weights:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 99/103 [00:00<00:00, 585.90it/s, Materializing param=encoder.layer.5.output.LayerNorm.weight]\n",
            "Loading weights:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 100/103 [00:00<00:00, 585.90it/s, Materializing param=encoder.layer.5.output.dense.bias]     \n",
            "Loading weights:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 100/103 [00:00<00:00, 585.90it/s, Materializing param=encoder.layer.5.output.dense.bias]\n",
            "Loading weights:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 101/103 [00:00<00:00, 585.90it/s, Materializing param=encoder.layer.5.output.dense.weight]\n",
            "Loading weights:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 101/103 [00:00<00:00, 585.90it/s, Materializing param=encoder.layer.5.output.dense.weight]\n",
            "Loading weights:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 102/103 [00:00<00:00, 585.90it/s, Materializing param=pooler.dense.bias]                  \n",
            "Loading weights:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 102/103 [00:00<00:00, 585.90it/s, Materializing param=pooler.dense.bias]\n",
            "Loading weights: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 103/103 [00:00<00:00, 585.90it/s, Materializing param=pooler.dense.weight]\n",
            "Loading weights: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 103/103 [00:00<00:00, 585.90it/s, Materializing param=pooler.dense.weight]\n",
            "Loading weights: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 103/103 [00:00<00:00, 815.72it/s, Materializing param=pooler.dense.weight]\n",
            "BertModel LOAD REPORT from: sentence-transformers/all-MiniLM-L6-v2\n",
            "Key                     | Status     |  | \n",
            "------------------------+------------+--+-\n",
            "embeddings.position_ids | UNEXPECTED |  | \n",
            "\n",
            "Notes:\n",
            "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n",
            "INFO:httpx:HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/config.json \"HTTP/1.1 307 Temporary Redirect\"\n",
            "INFO:httpx:HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config.json \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/tokenizer_config.json \"HTTP/1.1 307 Temporary Redirect\"\n",
            "INFO:httpx:HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/tokenizer_config.json \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: GET https://huggingface.co/api/models/sentence-transformers/all-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=false&expand=false \"HTTP/1.1 404 Not Found\"\n",
            "INFO:httpx:HTTP Request: GET https://huggingface.co/api/models/sentence-transformers/all-MiniLM-L6-v2/tree/main?recursive=true&expand=false \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/1_Pooling/config.json \"HTTP/1.1 307 Temporary Redirect\"\n",
            "INFO:httpx:HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/1_Pooling%2Fconfig.json \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: GET https://huggingface.co/api/models/sentence-transformers/all-MiniLM-L6-v2 \"HTTP/1.1 200 OK\"\n",
            "INFO:     Application startup complete.\n",
            "INFO:     Uvicorn running on http://0.0.0.0:8002 (Press CTRL+C to quit)\n",
            "Memory service started on 0.0.0.0:8001\n",
            "INFO:     127.0.0.1:39108 - \"GET /health HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:39124 - \"GET /health HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:39126 - \"GET /health HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:39128 - \"GET /health HTTP/1.1\" 200 OK\n",
            "\n",
            "\n",
            "--- /tmp/code_exec.log ---\n",
            "INFO:     Started server process [17647]\n",
            "INFO:     Waiting for application startup.\n",
            "2026-02-08 03:27:08,601 - code_exec.service.main - INFO - Starting Code Executor Service\n",
            "2026-02-08 03:27:08,601 - code_exec.service.main - INFO - Skills directory: /Users/paragpradhan/Projects/Agent framework/agent-framework/code-exec/skills\n",
            "2026-02-08 03:27:08,601 - code_exec.service.registry - INFO - Loading skills from: /Users/paragpradhan/Projects/Agent framework/agent-framework/code-exec/skills\n",
            "2026-02-08 03:27:08,601 - code_exec.service.registry - INFO - Loaded 0 skills successfully\n",
            "2026-02-08 03:27:08,601 - code_exec.service.main - INFO - Loaded 0 skills\n",
            "2026-02-08 03:27:08,601 - code_exec.service.main - INFO - Service ready on 0.0.0.0:8002\n",
            "INFO:     Application startup complete.\n",
            "INFO:     Uvicorn running on http://0.0.0.0:8004 (Press CTRL+C to quit)\n",
            "INFO:     127.0.0.1:59214 - \"GET /health HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:59216 - \"GET /health HTTP/1.1\" 200 OK\n",
            "\n",
            "\n",
            "--- /tmp/mcp_gateway.log ---\n",
            "/content/ai_final/agentic-framework-main/mcp_gateway/service/models.py:209: UserWarning: Field name \"schema\" in \"ToolSchemaResponse\" shadows an attribute in parent \"BaseModel\"\n",
            "  class ToolSchemaResponse(BaseModel):\n",
            "INFO:     Started server process [17686]\n",
            "INFO:     Waiting for application startup.\n",
            "INFO:     Application startup complete.\n",
            "ERROR:    [Errno 98] error while attempting to bind on address ('0.0.0.0', 8080): address already in use\n",
            "INFO:     Waiting for application shutdown.\n",
            "INFO:     Application shutdown complete.\n",
            "Starting mcp-gateway v1.0.0\n",
            "Initialized sample tools in catalog\n",
            "Shutting down MCP Gateway\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "737c2ece",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "737c2ece",
        "outputId": "0134ae2d-4e30-450a-e3e8-895f61c54ea3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "KEEP-ALIVE WATCHDOG STARTED\n",
            "  Monitoring services every 60s with auto-restart.\n",
            "  Status updates every 5 minutes.\n",
            "  Stop with: Runtime > Interrupt execution\n",
            "============================================================\n",
            "    Restarting MCP Gateway on port 8080... PID 18325\n",
            "    Restarting MCP Gateway on port 8080... PID 18610\n",
            "    Restarting MCP Gateway on port 8080... PID 18899\n",
            "    Restarting MCP Gateway on port 8080... PID 19184\n",
            "    Restarting MCP Gateway on port 8080... PID 19473\n",
            "  [03:33:20] Services: 4/5 | Ollama: OK | Restarts this cycle: 1\n",
            "    Restarting MCP Gateway on port 8080... PID 19770\n",
            "    Restarting MCP Gateway on port 8080... PID 20056\n",
            "    Restarting MCP Gateway on port 8080... PID 20339\n",
            "    Restarting MCP Gateway on port 8080... PID 20624\n",
            "    Restarting MCP Gateway on port 8080... PID 20910\n",
            "  [03:38:45] Services: 4/5 | Ollama: OK | Restarts this cycle: 1\n",
            "    Restarting MCP Gateway on port 8080... PID 21198\n",
            "    Restarting MCP Gateway on port 8080... PID 21485\n",
            "    Restarting MCP Gateway on port 8080... PID 21770\n",
            "    Restarting MCP Gateway on port 8080... PID 22055\n",
            "    Restarting MCP Gateway on port 8080... PID 22339\n",
            "  [03:44:10] Services: 4/5 | Ollama: OK | Restarts this cycle: 1\n",
            "    Restarting MCP Gateway on port 8080... PID 22620\n",
            "    Restarting MCP Gateway on port 8080... PID 22901\n",
            "    Restarting MCP Gateway on port 8080... PID 23186\n",
            "    Restarting MCP Gateway on port 8080... PID 23472\n",
            "    Restarting MCP Gateway on port 8080... PID 23759\n",
            "  [03:49:36] Services: 4/5 | Ollama: OK | Restarts this cycle: 1\n",
            "    Restarting MCP Gateway on port 8080... PID 24044\n",
            "    Restarting MCP Gateway on port 8080... PID 24325\n",
            "    Restarting MCP Gateway on port 8080... PID 24613\n",
            "    Restarting MCP Gateway on port 8080... PID 24900\n",
            "    Restarting MCP Gateway on port 8080... PID 25187\n",
            "  [03:55:01] Services: 4/5 | Ollama: OK | Restarts this cycle: 1\n",
            "    Restarting MCP Gateway on port 8080... PID 25472\n",
            "\n",
            "  Watchdog stopped by user.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:pyngrok.process.ngrok:t=2026-02-08T03:56:08+0000 lvl=warn msg=\"Stopping forwarder\" name=http-3000-d18827c5-8209-4cb7-8b8c-be4519cb4549 acceptErr=\"failed to accept connection: Listener closed\"\n"
          ]
        }
      ],
      "source": [
        "# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
        "# â•‘  PHASE 7: Keep-Alive (prevents Colab from disconnecting)    â•‘\n",
        "# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "import subprocess, os, sys, time, urllib.request, datetime\n",
        "\n",
        "FRAMEWORK_DIR = \"/content/ai_final/agentic-framework-main\"\n",
        "\n",
        "service_defs = [\n",
        "    {\"name\": \"MCP Gateway\",      \"module\": \"mcp_gateway.service.main:app\",      \"port\": 8082, \"log\": \"/tmp/mcp_gateway.log\",      \"env\": {\"REDIS_URL\": \"redis://localhost:6379/3\"}},\n",
        "    {\"name\": \"Memory Service\",   \"module\": \"memory_service.service.main:app\",   \"port\": 8002, \"log\": \"/tmp/memory_service.log\",   \"env\": {\"REDIS_URL\": \"redis://localhost:6379/2\"}},\n",
        "    {\"name\": \"SubAgent Manager\", \"module\": \"subagent_manager.service.main:app\", \"port\": 8003, \"log\": \"/tmp/subagent_manager.log\", \"env\": {\"REDIS_URL\": \"redis://localhost:6379/1\"}},\n",
        "    {\"name\": \"Code Executor\",    \"module\": \"code_exec.service.main:app\",        \"port\": 8004, \"log\": \"/tmp/code_exec.log\",        \"env\": {\"REDIS_URL\": \"redis://localhost:6379/4\"}},\n",
        "    {\"name\": \"Orchestrator\",     \"module\": \"orchestrator.service.main:app\",     \"port\": 8000, \"log\": \"/tmp/orchestrator.log\",     \"env\": {}},\n",
        "]\n",
        "\n",
        "def is_alive(port):\n",
        "    try:\n",
        "        url = f\"http://localhost:{port}/health\" if port != 11434 else f\"http://localhost:{port}/api/tags\"\n",
        "        urllib.request.urlopen(url, timeout=5)\n",
        "        return True\n",
        "    except: return False\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"KEEP-ALIVE WATCHDOG STARTED\")\n",
        "print(\"  Monitoring services... Stop with Ctrl+M I\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "cycle = 0\n",
        "while True:\n",
        "    cycle += 1\n",
        "    restarts = 0\n",
        "    for svc in service_defs:\n",
        "        if not is_alive(svc[\"port\"]):\n",
        "            print(f\"  Restarting {svc['name']}...\", end=\" \", flush=True)\n",
        "            # Special env handling for Code Executor\n",
        "            svc_env = {**os.environ}\n",
        "            if svc['name'] == \"Code Executor\":\n",
        "                svc_env[\"CODE_EXECUTION_MODE\"] = \"local\"\n",
        "                # Remove potential conflict keys\n",
        "                for k in ['MINIO_ENDPOINT', 'MINIO_SECRET_KEY', 'JWT_SECRET_KEY']:\n",
        "                    if k in svc_env: del svc_env[k]\n",
        "            else:\n",
        "                svc_env.update(svc['env'])\n",
        "\n",
        "            subprocess.Popen([sys.executable, \"-m\", \"uvicorn\", svc[\"module\"], \"--host\", \"0.0.0.0\", \"--port\", str(svc[\"port\"])],\n",
        "                             cwd=FRAMEWORK_DIR, stdout=open(svc[\"log\"], \"a\"), stderr=subprocess.STDOUT, env=svc_env)\n",
        "            print(\"OK\")\n",
        "            restarts += 1\n",
        "\n",
        "    if cycle % 5 == 0:\n",
        "        print(f\"  [{datetime.datetime.now().strftime('%H:%M')}] System OK\")\n",
        "    time.sleep(60)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e199e12f",
        "outputId": "93d327e8-3ec1-4100-a360-db5a29e86a90"
      },
      "source": [
        "import subprocess\n",
        "\n",
        "logs = [\"/tmp/minio.log\", \"/tmp/code_exec.log\", \"/tmp/mcp_gateway.log\"]\n",
        "\n",
        "print(\"=== SERVICE LOGS ===\")\n",
        "for log in logs:\n",
        "    print(f\"\\n--- {log} ---\")\n",
        "    try:\n",
        "        # Check if file exists and has content\n",
        "        if os.path.exists(log):\n",
        "            with open(log, 'r') as f:\n",
        "                content = f.read().strip()\n",
        "                if content:\n",
        "                    print(content[-2000:]) # Print last 2000 chars\n",
        "                else:\n",
        "                    print(\"(Empty file)\")\n",
        "        else:\n",
        "            print(\"(File not found)\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error reading {log}: {e}\")"
      ],
      "id": "e199e12f",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== SERVICE LOGS ===\n",
            "\n",
            "--- /tmp/minio.log ---\n",
            "MinIO Object Storage Server\n",
            "Copyright: 2015-2026 MinIO, Inc.\n",
            "License: GNU AGPLv3 - https://www.gnu.org/licenses/agpl-3.0.html\n",
            "Version: RELEASE.2025-09-07T16-13-09Z (go1.24.6 linux/amd64)\n",
            "\n",
            "API: http://172.28.0.12:9005  http://127.0.0.1:9005 \n",
            "WebUI: http://172.28.0.12:9001 http://127.0.0.1:9001  \n",
            "\n",
            "Docs: https://docs.min.io\n",
            "WARN: Detected default credentials 'minioadmin:minioadmin', we recommend that you change these values with 'MINIO_ROOT_USER' and 'MINIO_ROOT_PASSWORD' environment variables\n",
            "INFO: Exiting on signal: INTERRUPT\n",
            "\n",
            "--- /tmp/code_exec.log ---\n",
            "rtup complete.\n",
            "INFO:     Uvicorn running on http://0.0.0.0:8004 (Press CTRL+C to quit)\n",
            "INFO:     127.0.0.1:59214 - \"GET /health HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:59216 - \"GET /health HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:36874 - \"GET /health HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:48806 - \"GET /health HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:48730 - \"GET /health HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:41246 - \"GET /health HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:52894 - \"GET /health HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:52902 - \"GET /health HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:47976 - \"GET /health HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:60696 - \"GET /health HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:56208 - \"GET /health HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:39954 - \"GET /health HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:44430 - \"GET /health HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:44432 - \"GET /health HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:47646 - \"GET /health HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:54770 - \"GET /health HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:55560 - \"GET /health HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:48834 - \"GET /health HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:53798 - \"GET /health HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:53800 - \"GET /health HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:46142 - \"GET /health HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:52370 - \"GET /health HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:45476 - \"GET /health HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:45902 - \"GET /health HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:51116 - \"GET /health HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:51130 - \"GET /health HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:54240 - \"GET /health HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:45572 - \"GET /health HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:40542 - \"GET /health HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:50700 - \"GET /health HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:43422 - \"GET /health HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:43432 - \"GET /health HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:55486 - \"GET /health HTTP/1.1\" 200 OK\n",
            "\n",
            "--- /tmp/mcp_gateway.log ---\n",
            "on shutdown.\n",
            "INFO:     Application shutdown complete.\n",
            "Starting mcp-gateway v1.0.0\n",
            "Initialized sample tools in catalog\n",
            "Shutting down MCP Gateway\n",
            "/content/ai_final/agentic-framework-main/mcp_gateway/service/models.py:209: UserWarning: Field name \"schema\" in \"ToolSchemaResponse\" shadows an attribute in parent \"BaseModel\"\n",
            "  class ToolSchemaResponse(BaseModel):\n",
            "INFO:     Started server process [24900]\n",
            "INFO:     Waiting for application startup.\n",
            "INFO:     Application startup complete.\n",
            "ERROR:    [Errno 98] error while attempting to bind on address ('0.0.0.0', 8080): address already in use\n",
            "INFO:     Waiting for application shutdown.\n",
            "INFO:     Application shutdown complete.\n",
            "Starting mcp-gateway v1.0.0\n",
            "Initialized sample tools in catalog\n",
            "Shutting down MCP Gateway\n",
            "/content/ai_final/agentic-framework-main/mcp_gateway/service/models.py:209: UserWarning: Field name \"schema\" in \"ToolSchemaResponse\" shadows an attribute in parent \"BaseModel\"\n",
            "  class ToolSchemaResponse(BaseModel):\n",
            "INFO:     Started server process [25187]\n",
            "INFO:     Waiting for application startup.\n",
            "INFO:     Application startup complete.\n",
            "ERROR:    [Errno 98] error while attempting to bind on address ('0.0.0.0', 8080): address already in use\n",
            "INFO:     Waiting for application shutdown.\n",
            "INFO:     Application shutdown complete.\n",
            "Starting mcp-gateway v1.0.0\n",
            "Initialized sample tools in catalog\n",
            "Shutting down MCP Gateway\n",
            "/content/ai_final/agentic-framework-main/mcp_gateway/service/models.py:209: UserWarning: Field name \"schema\" in \"ToolSchemaResponse\" shadows an attribute in parent \"BaseModel\"\n",
            "  class ToolSchemaResponse(BaseModel):\n",
            "INFO:     Started server process [25472]\n",
            "INFO:     Waiting for application startup.\n",
            "INFO:     Application startup complete.\n",
            "ERROR:    [Errno 98] error while attempting to bind on address ('0.0.0.0', 8080): address already in use\n",
            "INFO:     Waiting for application shutdown.\n",
            "INFO:     Application shutdown complete.\n",
            "Starting mcp-gateway v1.0.0\n",
            "Initialized sample tools in catalog\n",
            "Shutting down MCP Gateway\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1799502a",
        "outputId": "4d8e358b-bc12-421e-b3cb-2d4e7e4cc17c"
      },
      "source": [
        "# â”€â”€ Repair & Restart Services â”€â”€\n",
        "import subprocess, time, sys, os, urllib.request\n",
        "\n",
        "# Detect correct framework directory\n",
        "POSSIBLE_DIRS = [\n",
        "    \"/content/ai_final/agentic-framework-main\",\n",
        "    \"/content/ai_final\"\n",
        "]\n",
        "FRAMEWORK_DIR = \"/content/ai_final\"\n",
        "for d in POSSIBLE_DIRS:\n",
        "    if os.path.exists(d) and os.path.exists(os.path.join(d, \"orchestrator\")):\n",
        "        FRAMEWORK_DIR = d\n",
        "        break\n",
        "\n",
        "print(f\"Using Framework Directory: {FRAMEWORK_DIR}\")\n",
        "\n",
        "services = [\n",
        "    {\"name\": \"Code Executor\",    \"module\": \"code_exec.service.main:app\",        \"port\": 8004, \"log\": \"/tmp/code_exec.log\",        \"env\": {\"REDIS_URL\": \"redis://localhost:6379/4\"}},\n",
        "    {\"name\": \"Memory Service\",   \"module\": \"memory_service.service.main:app\",   \"port\": 8002, \"log\": \"/tmp/memory_service.log\",   \"env\": {\"REDIS_URL\": \"redis://localhost:6379/2\"}},\n",
        "    {\"name\": \"SubAgent Manager\", \"module\": \"subagent_manager.service.main:app\", \"port\": 8003, \"log\": \"/tmp/subagent_manager.log\", \"env\": {\"REDIS_URL\": \"redis://localhost:6379/1\"}},\n",
        "    {\"name\": \"MCP Gateway\",      \"module\": \"mcp_gateway.service.main:app\",      \"port\": 8080, \"log\": \"/tmp/mcp_gateway.log\",      \"env\": {\"REDIS_URL\": \"redis://localhost:6379/3\"}},\n",
        "    {\"name\": \"Orchestrator\",     \"module\": \"orchestrator.service.main:app\",     \"port\": 8000, \"log\": \"/tmp/orchestrator.log\",     \"env\": {}},\n",
        "]\n",
        "\n",
        "def check_port(port):\n",
        "    try:\n",
        "        urllib.request.urlopen(f\"http://localhost:{port}/health\", timeout=2)\n",
        "        return True\n",
        "    except:\n",
        "        return False\n",
        "\n",
        "print(\"Stopping any stuck services...\")\n",
        "subprocess.run([\"pkill\", \"-f\", \"uvicorn\"])\n",
        "time.sleep(2)\n",
        "\n",
        "print(\"Restarting services with log inspection...\")\n",
        "service_env = {**os.environ, \"PYTHONPATH\": FRAMEWORK_DIR}\n",
        "\n",
        "for svc in services:\n",
        "    print(f\"Starting {svc['name']} (:{svc['port']})...\", end=\" \", flush=True)\n",
        "    svc_env = {**service_env, **svc[\"env\"]}\n",
        "\n",
        "    # Start process\n",
        "    subprocess.Popen(\n",
        "        [sys.executable, \"-m\", \"uvicorn\", svc[\"module\"],\n",
        "         \"--host\", \"0.0.0.0\", \"--port\", str(svc[\"port\"])],\n",
        "        cwd=FRAMEWORK_DIR,\n",
        "        stdout=open(svc[\"log\"], \"w\"),\n",
        "        stderr=subprocess.STDOUT,\n",
        "        env=svc_env\n",
        "    )\n",
        "\n",
        "    # Wait and check\n",
        "    time.sleep(4)\n",
        "    if check_port(svc[\"port\"]):\n",
        "        print(\"OK\")\n",
        "    else:\n",
        "        # Check if process is even running\n",
        "        pid_check = subprocess.run([\"pgrep\", \"-f\", f\"port {svc['port']}\"], capture_output=True)\n",
        "        if pid_check.returncode == 0:\n",
        "             print(\"Running (but health check failed - still initializing?)\")\n",
        "        else:\n",
        "             print(\"FAIL (Crashed)\")\n",
        "             print(f\"--- Last 20 lines of {svc['log']} ---\")\n",
        "             if os.path.exists(svc[\"log\"]):\n",
        "                 subprocess.run([\"tail\", \"-n\", \"20\", svc[\"log\"]])\n",
        "             else:\n",
        "                 print(\"Log file not found.\")\n",
        "             print(\"------------------------------------\")\n",
        "\n",
        "print(\"\\nRepair complete. Try running Phase 6 (Smoke Test) again.\")"
      ],
      "id": "1799502a",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Framework Directory: /content/ai_final/agentic-framework-main\n",
            "Stopping any stuck services...\n",
            "Restarting services with log inspection...\n",
            "Starting Code Executor (:8004)... OK\n",
            "Starting Memory Service (:8002)... Running (but health check failed - still initializing?)\n",
            "Starting SubAgent Manager (:8003)... OK\n",
            "Starting MCP Gateway (:8080)... FAIL (Crashed)\n",
            "--- Last 20 lines of /tmp/mcp_gateway.log ---\n",
            "------------------------------------\n",
            "Starting Orchestrator (:8000)... OK\n",
            "\n",
            "Repair complete. Try running Phase 6 (Smoke Test) again.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "44117a36",
      "metadata": {
        "id": "44117a36"
      },
      "source": [
        "---\n",
        "## Utility Cells (run manually as needed)\n",
        "\n",
        "The cells below are optional â€” run them when you want to interact with the system."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "4c8eb3bb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4c8eb3bb",
        "outputId": "5f7b220b-76c7-4d8c-c16f-b57e2c1948c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Task: Write a Python function that calculates the Fibonacci sequence up to n terms, with proper error handling and type hints.\n",
            "\n",
            "Error: HTTP Error 401: Unauthorized\n",
            "Tip: !tail -100 /tmp/orchestrator.log\n"
          ]
        }
      ],
      "source": [
        "# â”€â”€ Send a task to the Orchestrator â”€â”€\n",
        "import json, urllib.request\n",
        "\n",
        "task = \"Write a Python function that calculates the Fibonacci sequence up to n terms, with proper error handling and type hints.\"\n",
        "\n",
        "print(f\"Task: {task}\\n\")\n",
        "data = json.dumps({\"message\": task, \"session_id\": \"colab-auto-001\"}).encode()\n",
        "req = urllib.request.Request(\n",
        "    \"http://localhost:8000/chat\",\n",
        "    data=data,\n",
        "    headers={\"Content-Type\": \"application/json\"}\n",
        ")\n",
        "try:\n",
        "    resp = urllib.request.urlopen(req, timeout=300)\n",
        "    result = json.loads(resp.read().decode())\n",
        "    print(json.dumps(result, indent=2)[:3000])\n",
        "except Exception as e:\n",
        "    print(f\"Error: {e}\")\n",
        "    print(\"Tip: !tail -100 /tmp/orchestrator.log\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "16fe6036",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "16fe6036",
        "outputId": "c2b0cda3-8e15-4da6-c7ff-9025d74f329b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Last 50 lines of orchestrator:\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CompletedProcess(args=['tail', '-50', '/tmp/orchestrator.log'], returncode=0)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "# â”€â”€ View service logs â”€â”€\n",
        "# Change SERVICE to: orchestrator, memory_service, subagent_manager,\n",
        "#                     mcp_gateway, code_exec, ollama, chroma, minio, dashboard\n",
        "SERVICE = \"orchestrator\"\n",
        "LINES = 50\n",
        "\n",
        "import subprocess\n",
        "print(f\"Last {LINES} lines of {SERVICE}:\")\n",
        "print(\"=\" * 60)\n",
        "subprocess.run([\"tail\", f\"-{LINES}\", f\"/tmp/{SERVICE}.log\"], capture_output=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "41e3d312",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "41e3d312",
        "outputId": "0b5bb36f-6aea-4044-e42f-35d3eae25cd9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU:\n",
            "\n",
            "RAM: 1.5/12.7 GB (14.8%)\n",
            "Disk: 57.1/235.7 GB\n",
            "\n",
            "Running services:\n",
            "  PID 25515: /usr/bin/python3 -m uvicorn code_exec.service.main:app --host 0.0.0.0 --port 800\n",
            "  PID 25537: /usr/bin/python3 -m uvicorn memory_service.service.main:app --host 0.0.0.0 --por\n",
            "  PID 25561: /usr/bin/python3 -m uvicorn subagent_manager.service.main:app --host 0.0.0.0 --p\n",
            "  PID 25608: /usr/bin/python3 -m uvicorn orchestrator.service.main:app --host 0.0.0.0 --port \n"
          ]
        }
      ],
      "source": [
        "# â”€â”€ System resource monitor â”€â”€\n",
        "import subprocess, psutil, shutil\n",
        "\n",
        "print(\"GPU:\")\n",
        "subprocess.run(\"nvidia-smi\", shell=True)\n",
        "\n",
        "mem = psutil.virtual_memory()\n",
        "print(f\"\\nRAM: {mem.used/1024**3:.1f}/{mem.total/1024**3:.1f} GB ({mem.percent}%)\")\n",
        "\n",
        "disk = shutil.disk_usage(\"/\")\n",
        "print(f\"Disk: {(disk.total-disk.free)/1024**3:.1f}/{disk.total/1024**3:.1f} GB\")\n",
        "\n",
        "print(\"\\nRunning services:\")\n",
        "for proc in psutil.process_iter(['pid', 'name', 'cmdline']):\n",
        "    try:\n",
        "        cmd = \" \".join(proc.info.get('cmdline', []))\n",
        "        if 'uvicorn' in cmd or 'ollama' in proc.info.get('name', '').lower():\n",
        "            print(f\"  PID {proc.info['pid']}: {cmd[:80]}\")\n",
        "    except:\n",
        "        pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "9c48e5cd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9c48e5cd",
        "outputId": "9695d95f-de8b-46f9-d554-0afc171db5da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stopping all services...\n",
            "  Killed PID 25515\n",
            "  Killed PID 25537\n",
            "  Killed PID 25561\n",
            "  Killed PID 25608\n",
            "Done. Re-run Phase 4 cell to restart services.\n"
          ]
        }
      ],
      "source": [
        "# â”€â”€ Restart all services â”€â”€\n",
        "import psutil, time\n",
        "\n",
        "print(\"Stopping all services...\")\n",
        "for proc in psutil.process_iter(['pid', 'cmdline']):\n",
        "    try:\n",
        "        cmd = \" \".join(proc.info.get('cmdline', []))\n",
        "        if 'uvicorn' in cmd and 'service.main' in cmd:\n",
        "            proc.kill()\n",
        "            print(f\"  Killed PID {proc.info['pid']}\")\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "time.sleep(3)\n",
        "print(\"Done. Re-run Phase 4 cell to restart services.\")"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}