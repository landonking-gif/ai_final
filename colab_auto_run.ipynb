{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "e3e7a6bf",
      "metadata": {
        "id": "e3e7a6bf"
      },
      "source": [
        "# Agentic Framework â€” Fully Automatic Google Colab Deployment\n",
        "\n",
        "**One-click deployment**: Just click **Runtime â†’ Run all** (or `Ctrl+F9`) and everything will start automatically.\n",
        "\n",
        "### What this does\n",
        "1. Verifies GPU (H100/A100) and system resources\n",
        "2. Installs system dependencies (PostgreSQL, Redis, Node.js 22, MinIO)\n",
        "3. Installs Ollama + pulls DeepSeek R1 14B (GPU-accelerated)\n",
        "4. Clones the repo and installs Python packages\n",
        "5. Starts all infrastructure (PostgreSQL, Redis, ChromaDB, MinIO)\n",
        "6. Starts all 5 microservices + dashboard\n",
        "7. Creates ngrok tunnels for external access\n",
        "8. Runs health checks\n",
        "9. Keeps the session alive so Colab doesn't disconnect\n",
        "\n",
        "### Prerequisites\n",
        "- Google Colab **Pro** account (for GPU access)\n",
        "- Runtime set to **GPU** (Runtime â†’ Change runtime type â†’ T4/A100/H100)\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "4c70cab1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4c70cab1",
        "outputId": "1c374c1a-5361-48b4-f7de-4c6bbd2e1fcc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Configuration loaded.\n"
          ]
        }
      ],
      "source": [
        "# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
        "# â•‘  CONFIGURATION                                               â•‘\n",
        "# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "\n",
        "# GitHub repo\n",
        "REPO_URL = \"https://github.com/landonking-gif/ai_final.git\"\n",
        "\n",
        "# Ngrok Token (Get one free at https://dashboard.ngrok.com/signup)\n",
        "# Required for public URLs\n",
        "NGROK_AUTH_TOKEN = \"39MaIP07IiJMHPNDgd3raMEOL6r_2KyacFVXP68bbxBu9s8E8\"\n",
        "\n",
        "# Models (Pulled via Ollama)\n",
        "PRIMARY_MODEL = \"deepseek-r1:14b\"\n",
        "FALLBACK_MODEL = \"llama3.2:3b\"\n",
        "\n",
        "# Feature Flags\n",
        "START_DASHBOARD = True\n",
        "ENABLE_NGROK = True\n",
        "\n",
        "print(\"âœ… Configuration loaded.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "66186129",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "66186129",
        "outputId": "c1988b7f-6e3e-451e-b7c0-86067f34f54a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "PHASE 1: SYSTEM CHECK & DEPENDENCY INSTALL\n",
            "============================================================\n",
            "  [GPU] Tesla T4, 15360 MiB, 550.54.15\n",
            "  [RAM] 12.7 GB\n",
            "  [Disk] 178.6 GB free\n",
            "  [Python] 3.12.12\n",
            "\n",
            "  Installing system packages...\n",
            "  [apt update] OK\n",
            "  [PostgreSQL + Redis + build tools + zstd] OK\n",
            "  [Node.js 22 repo] OK\n",
            "  [Node.js 22] OK\n",
            "  [MinIO] OK\n",
            "  [Node.js] v22.22.0\n",
            "\n",
            "  Phase 1 complete.\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
        "# â•‘  PHASE 1: System Check & Dependencies                      â•‘\n",
        "# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "import subprocess, os, sys, shutil, time\n",
        "\n",
        "def run_cmd(cmd, desc=\"\", check=False):\n",
        "    \"\"\"Run a shell command with status output.\"\"\"\n",
        "    if desc:\n",
        "        print(f\"  [{desc}]\", end=\" \", flush=True)\n",
        "    result = subprocess.run(cmd, shell=True, capture_output=True, text=True)\n",
        "    if desc:\n",
        "        print(\"OK\" if result.returncode == 0 else f\"WARN ({result.stderr[:120]})\")\n",
        "    if check and result.returncode != 0:\n",
        "        raise RuntimeError(f\"{desc} failed: {result.stderr[:300]}\")\n",
        "    return result\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"PHASE 1: SYSTEM CHECK & DEPENDENCY INSTALL\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# --- GPU Check ---\n",
        "gpu_check = subprocess.run(\n",
        "    [\"nvidia-smi\", \"--query-gpu=name,memory.total,driver_version\", \"--format=csv,noheader\"],\n",
        "    capture_output=True, text=True\n",
        ")\n",
        "if gpu_check.returncode == 0:\n",
        "    print(f\"  [GPU] {gpu_check.stdout.strip()}\")\n",
        "else:\n",
        "    print(\"  [GPU] No GPU detected â€” LLM inference will be slow on CPU!\")\n",
        "    print(\"         Go to Runtime > Change runtime type > GPU\")\n",
        "\n",
        "# --- RAM & Disk ---\n",
        "try:\n",
        "    import psutil\n",
        "    ram_gb = psutil.virtual_memory().total / (1024**3)\n",
        "    print(f\"  [RAM] {ram_gb:.1f} GB\")\n",
        "except ImportError:\n",
        "    pass\n",
        "disk = shutil.disk_usage(\"/\")\n",
        "print(f\"  [Disk] {disk.free / (1024**3):.1f} GB free\")\n",
        "print(f\"  [Python] {sys.version.split()[0]}\")\n",
        "\n",
        "# --- Install System Dependencies ---\n",
        "print(\"\\n  Installing system packages...\")\n",
        "run_cmd(\"apt-get update -qq 2>/dev/null\", \"apt update\")\n",
        "run_cmd(\"apt-get install -y -qq postgresql postgresql-client redis-server build-essential libpq-dev zstd > /dev/null 2>&1\", \"PostgreSQL + Redis + build tools + zstd\")\n",
        "\n",
        "# Node.js 22\n",
        "run_cmd(\"curl -fsSL https://deb.nodesource.com/setup_22.x | bash - > /dev/null 2>&1\", \"Node.js 22 repo\")\n",
        "run_cmd(\"apt-get install -y -qq nodejs > /dev/null 2>&1\", \"Node.js 22\")\n",
        "\n",
        "# MinIO binary\n",
        "run_cmd(\"wget -q https://dl.min.io/server/minio/release/linux-amd64/minio -O /usr/local/bin/minio && chmod +x /usr/local/bin/minio\", \"MinIO\")\n",
        "\n",
        "node_ver = subprocess.run(\"node --version\", shell=True, capture_output=True, text=True)\n",
        "print(f\"  [Node.js] {node_ver.stdout.strip()}\")\n",
        "print(\"\\n  Phase 1 complete.\")\n",
        "print(\"=\" * 60)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "8960bca3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8960bca3",
        "outputId": "7902b88f-3315-47a7-993f-363d3b6dc1a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "PHASE 2: OLLAMA + LLM MODEL SETUP\n",
            "============================================================\n",
            "  Installing Ollama... OK\n",
            "  Starting Ollama server... OK\n",
            "  Pulling deepseek-r1:14b (this may take 2-8 min)...\n",
            "  Pulling llama3.2:3b...\n",
            "\n",
            "  Available models:\n",
            "\n",
            "  Phase 2 complete.\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
        "# â•‘  PHASE 2: Ollama + LLM Models (GPU-Accelerated)            â•‘\n",
        "# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "import subprocess, os, time\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"PHASE 2: OLLAMA + LLM MODEL SETUP\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Install Ollama\n",
        "print(\"  Installing Ollama...\", end=\" \", flush=True)\n",
        "\n",
        "# Download the install script\n",
        "subprocess.run(\"wget -q https://ollama.com/install.sh -O /tmp/ollama_install.sh\", shell=True, check=True)\n",
        "subprocess.run(\"chmod +x /tmp/ollama_install.sh\", shell=True, check=True)\n",
        "\n",
        "# Run the install script with sudo, capturing output\n",
        "install_command = \"sudo /tmp/ollama_install.sh\"\n",
        "install_process = subprocess.Popen(install_command, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n",
        "stdout, stderr = install_process.communicate()\n",
        "\n",
        "if install_process.returncode == 0:\n",
        "    print(\"OK\")\n",
        "else:\n",
        "    print(f\"WARN: Ollama installation script returned non-zero exit code ({install_process.returncode}).\")\n",
        "    print(f\"Installation STDOUT:\\n{stdout}\")\n",
        "    print(f\"Installation STDERR:\\n{stderr}\")\n",
        "\n",
        "# Verify Ollama executable exists\n",
        "OLLAMA_BIN_PATH = \"/usr/local/bin/ollama\"\n",
        "if not os.path.exists(OLLAMA_BIN_PATH):\n",
        "    print(f\"  [ERROR] Ollama executable not found at {OLLAMA_BIN_PATH}. Installation might have failed or installed elsewhere.\")\n",
        "    print(\"  Attempting to locate ollama binary...\")\n",
        "    find_ollama_result = subprocess.run(\"find / -name ollama 2>/dev/null\", shell=True, capture_output=True, text=True)\n",
        "    found_paths = find_ollama_result.stdout.strip().split('\\n')\n",
        "    if found_paths and found_paths[0]: # If anything was found\n",
        "        print(f\"  Found ollama at: {found_paths[0]}. Please check this path.\")\n",
        "    else:\n",
        "        print(\"  Ollama not found anywhere on the system after installation attempt.\")\n",
        "    raise FileNotFoundError(f\"Ollama executable not found at {OLLAMA_BIN_PATH}\")\n",
        "\n",
        "# Start Ollama server in background\n",
        "print(\"  Starting Ollama server...\", end=\" \", flush=True)\n",
        "os.environ[\"OLLAMA_HOST\"] = \"0.0.0.0:11434\"\n",
        "subprocess.Popen(\n",
        "    [OLLAMA_BIN_PATH, \"serve\"],\n",
        "    stdout=open(\"/tmp/ollama.log\", \"w\"),\n",
        "    stderr=subprocess.STDOUT,\n",
        "    env={**os.environ, \"OLLAMA_HOST\": \"0.0.0.0:11434\"}\n",
        ")\n",
        "time.sleep(5)\n",
        "print(\"OK\")\n",
        "\n",
        "# Pull primary model\n",
        "print(f\"  Pulling {PRIMARY_MODEL} (this may take 2-8 min)...\")\n",
        "subprocess.run([OLLAMA_BIN_PATH, \"pull\", PRIMARY_MODEL], capture_output=False, text=True)\n",
        "\n",
        "# Pull fallback model\n",
        "print(f\"  Pulling {FALLBACK_MODEL}...\")\n",
        "subprocess.run([OLLAMA_BIN_PATH, \"pull\", FALLBACK_MODEL], capture_output=False, text=True)\n",
        "\n",
        "# Verify\n",
        "print(\"\\n  Available models:\")\n",
        "subprocess.run([OLLAMA_BIN_PATH, \"list\"], capture_output=False, text=True)\n",
        "\n",
        "print(\"\\n  Phase 2 complete.\")\n",
        "print(\"=\" * 60)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "b7b9f665",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b7b9f665",
        "outputId": "fb00f23b-ec81-4492-82ef-59a5a89972c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "PHASE 3: SETUP\n",
            "============================================================\n",
            "  [System] Checking GPU... OK (NVIDIA GPU detected)\n",
            "  [Repo] Updating... OK\n",
            "  [Setup] Configuring symlinks... OK\n",
            "  [Deps] Installing Python packages (2-3 min)... OK\n",
            "  [Deps] Installing OpenClaw... OK\n",
            "\n",
            "  Phase 3 complete.\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
        "# â•‘  PHASE 3: System Setup, Repo & Dependencies                â•‘\n",
        "# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "import subprocess, os, sys, shutil\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"PHASE 3: SETUP\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# â”€â”€â”€ SYSTEM CHECKS â”€â”€â”€\n",
        "print(\"  [System] Checking GPU...\", end=\" \", flush=True)\n",
        "gpu = subprocess.run(\"nvidia-smi\", shell=True, capture_output=True)\n",
        "if gpu.returncode == 0:\n",
        "    print(\"OK (NVIDIA GPU detected)\")\n",
        "else:\n",
        "    print(\"WARN (No GPU detected - Inference will be slow)\")\n",
        "\n",
        "# â”€â”€â”€ REPOSITORY â”€â”€â”€\n",
        "INSTALL_DIR = \"/content/ai_final\"\n",
        "FRAMEWORK_DIR = f\"{INSTALL_DIR}/agentic-framework-main\"\n",
        "\n",
        "if os.path.exists(INSTALL_DIR):\n",
        "    print(\"  [Repo] Updating...\", end=\" \", flush=True)\n",
        "    subprocess.run([\"git\", \"-C\", INSTALL_DIR, \"pull\"], capture_output=False)\n",
        "    print(\"OK\")\n",
        "else:\n",
        "    print(f\"  [Repo] Cloning {REPO_URL}...\", end=\" \", flush=True)\n",
        "    subprocess.run([\"git\", \"clone\", REPO_URL, INSTALL_DIR], capture_output=False)\n",
        "    print(\"OK\")\n",
        "\n",
        "os.chdir(FRAMEWORK_DIR)\n",
        "\n",
        "# â”€â”€â”€ SYMLINKS â”€â”€â”€\n",
        "print(\"  [Setup] Configuring symlinks...\", end=\" \", flush=True)\n",
        "symlinks = {\n",
        "    \"memory_service\": \"memory-service\",\n",
        "    \"subagent_manager\": \"subagent-manager\",\n",
        "    \"mcp_gateway\": \"mcp-gateway\",\n",
        "    \"code_exec\": \"code-exec\",\n",
        "}\n",
        "for link_name, target in symlinks.items():\n",
        "    if not os.path.exists(link_name) and os.path.exists(target):\n",
        "        os.symlink(target, link_name)\n",
        "print(\"OK\")\n",
        "\n",
        "# â”€â”€â”€ DEPENDENCIES â”€â”€â”€\n",
        "print(\"  [Deps] Installing Python packages (2-3 min)...\", end=\" \", flush=True)\n",
        "subprocess.run(\n",
        "    [sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"-r\", f\"{FRAMEWORK_DIR}/requirements.txt\"],\n",
        "    capture_output=False\n",
        ")\n",
        "subprocess.run(\n",
        "    [sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"pyngrok\", \"asyncpg\", \"aiofiles\", \"psutil\"],\n",
        "    capture_output=False\n",
        ")\n",
        "print(\"OK\")\n",
        "\n",
        "print(\"  [Deps] Installing OpenClaw...\", end=\" \", flush=True)\n",
        "subprocess.run([\"npm\", \"install\", \"-g\", \"openclaw@latest\"], capture_output=True)\n",
        "print(\"OK\")\n",
        "\n",
        "# PYTHONPATH\n",
        "if FRAMEWORK_DIR not in sys.path:\n",
        "    sys.path.insert(0, FRAMEWORK_DIR)\n",
        "os.environ[\"PYTHONPATH\"] = FRAMEWORK_DIR\n",
        "\n",
        "print(\"\\n  Phase 3 complete.\")\n",
        "print(\"=\" * 60)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "78fdaf2a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "78fdaf2a",
        "outputId": "e9b2eab3-07c8-42e1-cb04-a7a9299a797e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "PHASE 4: INFRASTRUCTURE & SERVICES\n",
            "============================================================\n",
            "  [System] Verifying binaries... OK\n",
            "\n",
            "â”€â”€ Cleanup â”€â”€\n",
            "\n",
            "â”€â”€ Infrastructure â”€â”€\n",
            "  Starting PostgreSQL... OK\n",
            "  Waiting for Redis (:6379)... OK\n",
            "  Waiting for ChromaDB (:8001)... OK\n",
            "  Waiting for MinIO (:9005)... OK\n",
            "  Waiting for Ollama (:11434)... OK\n",
            "\n",
            "â”€â”€ Microservices â”€â”€\n",
            "  Starting Code Executor... OK\n",
            "  Starting Memory Service... OK\n",
            "  Starting SubAgent Manager... OK\n",
            "  Starting MCP Gateway... OK\n",
            "  Starting Orchestrator... OK\n",
            "\n",
            "â”€â”€ Dashboard â”€â”€\n",
            "  Installing & Starting... OK\n",
            "\n",
            "  Waiting 20s for services to initialize...\n",
            "\n",
            "â”€â”€ Status â”€â”€\n",
            "  âœ… Orchestrator : ONLINE\n",
            "  âœ… Memory       : ONLINE\n",
            "  âœ… SubAgents    : ONLINE\n",
            "  âœ… MCP (8082)   : ONLINE\n",
            "  âœ… CodeExec     : ONLINE\n",
            "  âœ… Ollama       : ONLINE\n",
            "\n",
            "ðŸš€ ALL SYSTEMS GO!\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
        "# â•‘  PHASE 4: Start Infrastructure + All Services               â•‘\n",
        "# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "import subprocess, os, sys, time, urllib.request, json, socket\n",
        "\n",
        "# â”€â”€â”€ CONFIGURATION â”€â”€â”€\n",
        "# Load globals if defined, else defaults\n",
        "if \"PRIMARY_MODEL\" not in locals(): PRIMARY_MODEL = \"deepseek-r1:14b\"\n",
        "if \"FALLBACK_MODEL\" not in locals(): FALLBACK_MODEL = \"llama3.2:3b\"\n",
        "if \"START_DASHBOARD\" not in locals(): START_DASHBOARD = True\n",
        "if \"ENABLE_NGROK\" not in locals(): ENABLE_NGROK = True\n",
        "\n",
        "FRAMEWORK_DIR = \"/content/ai_final/agentic-framework-main\"\n",
        "os.chdir(FRAMEWORK_DIR)\n",
        "\n",
        "# â”€â”€â”€ AUTO-REPAIR â”€â”€â”€\n",
        "def check_system():\n",
        "    print(\"  [System] Verifying binaries...\", end=\" \", flush=True)\n",
        "    missing = []\n",
        "    if not os.path.exists(\"/usr/local/bin/minio\"): missing.append(\"minio\")\n",
        "    if subprocess.run(\"which redis-server\", shell=True).returncode != 0: missing.append(\"redis\")\n",
        "    if subprocess.run(\"which ollama\", shell=True).returncode != 0: missing.append(\"ollama\")\n",
        "\n",
        "    if missing:\n",
        "        print(f\"Fixing: {missing}\")\n",
        "        if \"minio\" in missing:\n",
        "            subprocess.run(\"wget -q https://dl.min.io/server/minio/release/linux-amd64/minio -O /usr/local/bin/minio && chmod +x /usr/local/bin/minio\", shell=True)\n",
        "        if \"redis\" in missing:\n",
        "            subprocess.run(\"apt-get update -qq && apt-get install -y -qq redis-server postgresql postgresql-client > /dev/null\", shell=True)\n",
        "        if \"ollama\" in missing:\n",
        "            subprocess.run(\"curl -fsSL https://ollama.com/install.sh | sh\", shell=True)\n",
        "    else:\n",
        "        print(\"OK\")\n",
        "\n",
        "def wait_for_service(port, name, timeout=60):\n",
        "    print(f\"  Waiting for {name} (:{port})...\", end=\" \", flush=True)\n",
        "    start = time.time()\n",
        "    while time.time() - start < timeout:\n",
        "        try:\n",
        "            with socket.create_connection((\"localhost\", port), timeout=1):\n",
        "                print(\"OK\")\n",
        "                return True\n",
        "        except: time.sleep(1)\n",
        "    print(\"TIMEOUT\")\n",
        "    return False\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"PHASE 4: INFRASTRUCTURE & SERVICES\")\n",
        "print(\"=\" * 60)\n",
        "check_system()\n",
        "\n",
        "# â”€â”€â”€ CLEANUP â”€â”€â”€\n",
        "print(\"\\nâ”€â”€ Cleanup â”€â”€\")\n",
        "subprocess.run(\"pkill -f uvicorn; pkill -f 'chroma run'; pkill -f minio\", shell=True)\n",
        "time.sleep(2)\n",
        "\n",
        "# â”€â”€â”€ INFRASTRUCTURE â”€â”€â”€\n",
        "print(\"\\nâ”€â”€ Infrastructure â”€â”€\")\n",
        "# 1. PostgreSQL\n",
        "print(\"  Starting PostgreSQL...\", end=\" \")\n",
        "subprocess.run(\"service postgresql start\", shell=True, capture_output=True)\n",
        "time.sleep(2)\n",
        "subprocess.run([\"sudo\", \"-u\", \"postgres\", \"psql\", \"-c\", \"CREATE USER agent_user WITH PASSWORD 'agent_pass' CREATEDB;\"], capture_output=True)\n",
        "subprocess.run([\"sudo\", \"-u\", \"postgres\", \"psql\", \"-c\", \"CREATE DATABASE agentic_framework OWNER agent_user;\"], capture_output=True)\n",
        "subprocess.run([\"sudo\", \"-u\", \"postgres\", \"psql\", \"-c\", \"GRANT ALL PRIVILEGES ON DATABASE agentic_framework TO agent_user;\"], capture_output=True)\n",
        "print(\"OK\")\n",
        "# 2. Redis\n",
        "subprocess.run(\"redis-server --daemonize yes --port 6379\", shell=True)\n",
        "wait_for_service(6379, \"Redis\", 10)\n",
        "# 3. ChromaDB\n",
        "os.makedirs(\"/tmp/chroma_data\", exist_ok=True)\n",
        "subprocess.Popen([\"chroma\", \"run\", \"--host\", \"0.0.0.0\", \"--port\", \"8001\", \"--path\", \"/tmp/chroma_data\"], stdout=open(\"/tmp/chroma.log\", \"w\"), stderr=subprocess.STDOUT)\n",
        "wait_for_service(8001, \"ChromaDB\")\n",
        "# 4. MinIO (Port 9005)\n",
        "os.makedirs(\"/tmp/minio_data\", exist_ok=True)\n",
        "subprocess.Popen([\"/usr/local/bin/minio\", \"server\", \"/tmp/minio_data\", \"--address\", \":9005\", \"--console-address\", \":9001\"], stdout=open(\"/tmp/minio.log\", \"w\"), stderr=subprocess.STDOUT, env={**os.environ, \"MINIO_ROOT_USER\": \"minioadmin\", \"MINIO_ROOT_PASSWORD\": \"minioadmin\"})\n",
        "if not wait_for_service(9005, \"MinIO\", 90): print(\"\\n[ERROR] MinIO Failed. Check /tmp/minio.log\")\n",
        "# 5. Ollama\n",
        "if not wait_for_service(11434, \"Ollama\", 2):\n",
        "    print(\"  Starting Ollama...\", end=\" \")\n",
        "    subprocess.Popen([\"ollama\", \"serve\"], stdout=open(\"/tmp/ollama.log\", \"w\"), stderr=subprocess.STDOUT, env={**os.environ, \"OLLAMA_HOST\": \"0.0.0.0:11434\"})\n",
        "    wait_for_service(11434, \"Ollama\", 20)\n",
        "\n",
        "# â”€â”€â”€ MODEL CHECK â”€â”€â”€\n",
        "res = subprocess.run([\"ollama\", \"list\"], capture_output=True, text=True)\n",
        "if PRIMARY_MODEL not in res.stdout:\n",
        "    print(f\"\\n  âš ï¸ Model {PRIMARY_MODEL} missing. Pulling... (5-10m)\")\n",
        "    subprocess.run([\"ollama\", \"pull\", PRIMARY_MODEL], check=True)\n",
        "    print(\"  âœ… Model pulled.\")\n",
        "\n",
        "# â”€â”€â”€ ENVIRONMENT â”€â”€â”€\n",
        "env_vars = {\n",
        "    \"POSTGRES_URL\": \"postgresql://agent_user:agent_pass@localhost:5432/agentic_framework\",\n",
        "    \"REDIS_URL\": \"redis://localhost:6379/0\",\n",
        "    \"MCP_GATEWAY_URL\": \"http://localhost:8082\", \"MEMORY_SERVICE_URL\": \"http://localhost:8002\",\n",
        "    \"SUBAGENT_MANAGER_URL\": \"http://localhost:8003\", \"CODE_EXECUTOR_URL\": \"http://localhost:8004\",\n",
        "    \"CODE_EXECUTION_MODE\": \"local\", \"OLLAMA_ENDPOINT\": \"http://localhost:11434\",\n",
        "    \"OLLAMA_BASE_URL\": \"http://localhost:11434\", \"LOCAL_MODEL\": PRIMARY_MODEL, \"FALLBACK_MODEL\": FALLBACK_MODEL,\n",
        "    \"DEFAULT_LLM_PROVIDER\": \"local\", \"LLM_PROVIDER\": \"local\", \"USE_OPENCLAW\": \"false\",\n",
        "    \"CHROMA_URL\": \"http://localhost:8001\", \"MINIO_ENDPOINT\": \"localhost:9005\",\n",
        "    \"MINIO_ACCESS_KEY\": \"minioadmin\", \"MINIO_SECRET_KEY\": \"minioadmin\", \"JWT_SECRET_KEY\": \"colab-secret\",\n",
        "    \"ENVIRONMENT\": \"development\", \"PYTHONPATH\": FRAMEWORK_DIR,\n",
        "    \"WORKSPACE_ROOT\": f\"{FRAMEWORK_DIR}/workspace\", \"WEBSOCKET_ENABLED\": \"true\", \"INDEX_CODEBASE\": \"true\",\n",
        "}\n",
        "for k, v in env_vars.items(): os.environ[k] = v\n",
        "if os.path.exists(f\"{FRAMEWORK_DIR}/.env\"): os.remove(f\"{FRAMEWORK_DIR}/.env\")\n",
        "for d in [\"workspace/.copilot/memory/diary\", \"workspace/.copilot/memory/reflections\", \"workspace/ralph-work\"]: os.makedirs(f\"{FRAMEWORK_DIR}/{d}\", exist_ok=True)\n",
        "\n",
        "# â”€â”€â”€ MICROSERVICES â”€â”€â”€\n",
        "print(\"\\nâ”€â”€ Microservices â”€â”€\")\n",
        "base_env = {**os.environ}\n",
        "services = [\n",
        "    {\"name\": \"Code Executor\",    \"module\": \"code_exec.service.main:app\",        \"port\": 8004, \"log\": \"/tmp/code_exec.log\",        \"env\": {\"REDIS_URL\": \"redis://localhost:6379/4\"}},\n",
        "    {\"name\": \"Memory Service\",   \"module\": \"memory_service.service.main:app\",   \"port\": 8002, \"log\": \"/tmp/memory_service.log\",   \"env\": {\"REDIS_URL\": \"redis://localhost:6379/2\"}},\n",
        "    {\"name\": \"SubAgent Manager\", \"module\": \"subagent_manager.service.main:app\", \"port\": 8003, \"log\": \"/tmp/subagent_manager.log\", \"env\": {\"REDIS_URL\": \"redis://localhost:6379/1\"}},\n",
        "    {\"name\": \"MCP Gateway\",      \"module\": \"mcp_gateway.service.main:app\",      \"port\": 8082, \"log\": \"/tmp/mcp_gateway.log\",      \"env\": {\"REDIS_URL\": \"redis://localhost:6379/3\"}},\n",
        "    {\"name\": \"Orchestrator\",     \"module\": \"orchestrator.service.main:app\",     \"port\": 8000, \"log\": \"/tmp/orchestrator.log\",     \"env\": {}},\n",
        "]\n",
        "\n",
        "for svc in services:\n",
        "    print(f\"  Starting {svc['name']}...\", end=\" \")\n",
        "    svc_env = base_env.copy()\n",
        "    if svc[\"name\"] == \"Code Executor\":\n",
        "        for k in ['MINIO_ENDPOINT', 'MINIO_ACCESS_KEY', 'MINIO_SECRET_KEY', 'JWT_SECRET_KEY', 'ENVIRONMENT', 'WORKSPACE_ROOT', 'WEBSOCKET_ENABLED', 'INDEX_CODEBASE', 'PYTHONPATH']:\n",
        "            if k in svc_env: del svc_env[k]\n",
        "        svc_env[\"REDIS_URL\"] = svc[\"env\"][\"REDIS_URL\"]\n",
        "        svc_env[\"CODE_EXECUTION_MODE\"] = \"local\"\n",
        "    else:\n",
        "        svc_env.update(svc[\"env\"])\n",
        "    subprocess.Popen([sys.executable, \"-m\", \"uvicorn\", svc[\"module\"], \"--host\", \"0.0.0.0\", \"--port\", str(svc[\"port\"])], cwd=FRAMEWORK_DIR, stdout=open(svc[\"log\"], \"w\"), stderr=subprocess.STDOUT, env=svc_env)\n",
        "    print(\"OK\")\n",
        "    time.sleep(1)\n",
        "\n",
        "# â”€â”€â”€ DASHBOARD â”€â”€â”€\n",
        "if START_DASHBOARD:\n",
        "    print(\"\\nâ”€â”€ Dashboard â”€â”€\")\n",
        "    dash_dir = f\"{FRAMEWORK_DIR}/dashboard\"\n",
        "    if os.path.exists(f\"{dash_dir}/package.json\"):\n",
        "        print(\"  Installing & Starting...\", end=\" \")\n",
        "        subprocess.run([\"npm\", \"install\"], cwd=dash_dir, capture_output=True)\n",
        "        subprocess.Popen([\"npm\", \"start\"], cwd=dash_dir, stdout=open(\"/tmp/dashboard.log\", \"w\"), stderr=subprocess.STDOUT, env={**os.environ, \"PORT\": \"3000\", \"BROWSER\": \"none\"})\n",
        "        print(\"OK\")\n",
        "\n",
        "print(\"\\n  Waiting 20s for services to initialize...\")\n",
        "time.sleep(20)\n",
        "\n",
        "# â”€â”€â”€ HEALTH â”€â”€â”€\n",
        "print(\"\\nâ”€â”€ Status â”€â”€\")\n",
        "checks = [(\"Orchestrator\", 8000), (\"Memory\", 8002), (\"SubAgents\", 8003), (\"MCP (8082)\", 8082), (\"CodeExec\", 8004), (\"Ollama\", 11434)]\n",
        "passed = 0\n",
        "for name, port in checks:\n",
        "    try:\n",
        "        urllib.request.urlopen(f\"http://localhost:{port}/\" + (\"api/tags\" if port==11434 else \"health\"), timeout=2)\n",
        "        print(f\"  âœ… {name:<12} : ONLINE\")\n",
        "        passed += 1\n",
        "    except: print(f\"  âŒ {name:<12} : OFFLINE\")\n",
        "\n",
        "if passed == len(checks): print(\"\\nðŸš€ ALL SYSTEMS GO!\")\n",
        "else: print(\"\\nâš ï¸ Some services failed. Check logs.\")\n",
        "print(\"=\" * 60)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8810e849",
        "outputId": "8c53ba76-05d7-4a6e-a8dc-152f2bc014ba"
      },
      "source": [
        "import urllib.request, json\n",
        "\n",
        "print(\"=== CHECKING OLLAMA MODELS ===\")\n",
        "try:\n",
        "    resp = urllib.request.urlopen(\"http://localhost:11434/api/tags\")\n",
        "    data = json.loads(resp.read().decode())\n",
        "    models = [m['name'] for m in data.get('models', [])]\n",
        "    if models:\n",
        "        print(f\"âœ… Found {len(models)} models: {models}\")\n",
        "    else:\n",
        "        print(\"âŒ No models found! (They were likely wiped by the runtime reset)\")\n",
        "except Exception as e:\n",
        "    print(f\"Error checking models: {e}\")"
      ],
      "id": "8810e849",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== CHECKING OLLAMA MODELS ===\n",
            "âœ… Found 2 models: ['llama3.2:3b', 'deepseek-r1:14b']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "35219627",
        "outputId": "63f0ac7c-39fe-4d2d-ed63-e8c113f04568"
      },
      "source": [
        "import os, subprocess\n",
        "\n",
        "FRAMEWORK_DIR = \"/content/ai_final/agentic-framework-main\"\n",
        "\n",
        "print(\"=== FILE STRUCTURE DIAGNOSTIC ===\")\n",
        "print(f\"Framework Dir: {FRAMEWORK_DIR}\")\n",
        "\n",
        "# List root to see symlinks\n",
        "subprocess.run(f\"ls -la {FRAMEWORK_DIR}\", shell=True)\n",
        "\n",
        "print(\"\\n--- Checking for __init__.py in services ---\")\n",
        "services_dirs = [\"memory-service\", \"subagent-manager\", \"code-exec\", \"mcp-gateway\"]\n",
        "for d in services_dirs:\n",
        "    path = os.path.join(FRAMEWORK_DIR, d)\n",
        "    if os.path.exists(path):\n",
        "        init_path = os.path.join(path, \"__init__.py\")\n",
        "        has_init = os.path.exists(init_path)\n",
        "        print(f\"{d}: exists={'YES' if os.path.exists(path) else 'NO'}, has_init={'YES' if has_init else 'NO'}\")\n",
        "        if os.path.exists(path):\n",
        "             subprocess.run(f\"ls -F {path}\", shell=True)\n",
        "    else:\n",
        "        print(f\"{d}: MISSING\")\n",
        "\n",
        "print(\"\\n=== FULL LOGS FOR FAILURES ===\")\n",
        "logs = [\"/tmp/code_exec.log\", \"/tmp/subagent_manager.log\"]\n",
        "for log in logs:\n",
        "    print(f\"\\n--- {log} ---\")\n",
        "    if os.path.exists(log):\n",
        "        # Print last 100 lines\n",
        "        subprocess.run(f\"tail -n 100 {log}\", shell=True)\n",
        "    else:\n",
        "        print(\"(File not found)\")"
      ],
      "id": "35219627",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== FILE STRUCTURE DIAGNOSTIC ===\n",
            "Framework Dir: /content/ai_final/agentic-framework-main\n",
            "\n",
            "--- Checking for __init__.py in services ---\n",
            "memory-service: exists=YES, has_init=YES\n",
            "subagent-manager: exists=YES, has_init=YES\n",
            "code-exec: exists=YES, has_init=YES\n",
            "mcp-gateway: exists=YES, has_init=YES\n",
            "\n",
            "=== FULL LOGS FOR FAILURES ===\n",
            "\n",
            "--- /tmp/code_exec.log ---\n",
            "\n",
            "--- /tmp/subagent_manager.log ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "88f85fc8",
        "outputId": "aca26b33-1530-4ac5-ee34-1c4cfbdaf882"
      },
      "source": [
        "import subprocess\n",
        "\n",
        "print(\"=== CHECKING SERVICE LOGS FOR ERRORS ===\")\n",
        "services = [\n",
        "    \"/tmp/orchestrator.log\",\n",
        "    \"/tmp/memory_service.log\",\n",
        "    \"/tmp/code_exec.log\",\n",
        "    \"/tmp/subagent_manager.log\"\n",
        "]\n",
        "\n",
        "for log in services:\n",
        "    print(f\"\\n--- {log} ---\")\n",
        "    # Check if file exists first\n",
        "    try:\n",
        "        # Print last 30 lines of the log\n",
        "        result = subprocess.run([\"tail\", \"-n\", \"30\", log], capture_output=True, text=True)\n",
        "        print(result.stdout)\n",
        "        if result.stderr:\n",
        "            print(\"STDERR:\", result.stderr)\n",
        "    except Exception as e:\n",
        "        print(f\"Could not read log: {e}\")"
      ],
      "id": "88f85fc8",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== CHECKING SERVICE LOGS FOR ERRORS ===\n",
            "\n",
            "--- /tmp/orchestrator.log ---\n",
            "INFO:     Started server process [36820]\n",
            "INFO:     Waiting for application startup.\n",
            "2026-02-08 04:26:56,070 - orchestrator.service.main - INFO - Starting Lead Agent/Orchestrator service...\n",
            "2026-02-08 04:26:56,076 - orchestrator.service.main - INFO - Configuration: LLM Provider=local\n",
            "2026-02-08 04:26:56,076 - orchestrator.service.main - INFO - MCP Gateway URL: http://localhost:8082\n",
            "2026-02-08 04:26:56,076 - orchestrator.service.main - INFO - Memory Service URL: http://localhost:8002\n",
            "2026-02-08 04:26:56,319 - orchestrator.service.main - INFO - WebSocket manager initialized\n",
            "2026-02-08 04:26:56,323 - orchestrator.service.session_storage - INFO - Connected to Redis at redis://localhost:6379/0\n",
            "2026-02-08 04:26:56,324 - orchestrator.service.agent - INFO - Session storage initialized\n",
            "2026-02-08 04:26:56,324 - orchestrator.service.memory_learning - INFO - MemoryLearningClient initialized: memory_dir=/content/ai_final/agentic-framework-main/workspace/.copilot/memory\n",
            "2026-02-08 04:26:56,324 - orchestrator.service.agent_manager - INFO - Memory learning client initialized\n",
            "2026-02-08 04:26:56,324 - orchestrator.service.agent_manager - INFO - Agent manager started\n",
            "2026-02-08 04:26:56,324 - orchestrator.service.agent - INFO - Agent manager initialized\n",
            "2026-02-08 04:26:56,324 - orchestrator.service.agent - INFO - OrchestratorAgent fully initialized\n",
            "2026-02-08 04:26:56,324 - orchestrator.service.main - INFO - Orchestrator agent initialized with persistent storage\n",
            "2026-02-08 04:26:56,324 - orchestrator.service.main - INFO - Orchestrator service started successfully\n",
            "INFO:     Application startup complete.\n",
            "INFO:     Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit)\n",
            "2026-02-08 04:27:20,207 - httpx - INFO - HTTP Request: GET http://localhost:8082/health \"HTTP/1.1 200 OK\"\n",
            "2026-02-08 04:27:20,210 - httpx - INFO - HTTP Request: GET http://localhost:8002/health \"HTTP/1.1 200 OK\"\n",
            "2026-02-08 04:27:20,213 - httpx - INFO - HTTP Request: GET http://localhost:8003/health \"HTTP/1.1 200 OK\"\n",
            "INFO:     127.0.0.1:48688 - \"GET /health HTTP/1.1\" 200 OK\n",
            "\n",
            "\n",
            "--- /tmp/memory_service.log ---\n",
            "INFO:httpx:HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/modules.json \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/sentence_bert_config.json \"HTTP/1.1 307 Temporary Redirect\"\n",
            "INFO:httpx:HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/sentence_bert_config.json \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/adapter_config.json \"HTTP/1.1 404 Not Found\"\n",
            "INFO:httpx:HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/config.json \"HTTP/1.1 307 Temporary Redirect\"\n",
            "INFO:httpx:HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config.json \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/config.json \"HTTP/1.1 307 Temporary Redirect\"\n",
            "INFO:httpx:HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config.json \"HTTP/1.1 200 OK\"\n",
            "\n",
            "Loading weights:   0%|          | 0/103 [00:00<?, ?it/s]\n",
            "Loading weights:   1%|          | 1/103 [00:00<00:00, 29959.31it/s, Materializing param=embeddings.LayerNorm.bias]\n",
            "Loading weights:   1%|          | 1/103 [00:00<00:00, 6887.20it/s, Materializing param=embeddings.LayerNorm.bias] \n",
            "Loading weights:   2%|â–         | 2/103 [00:00<00:00, 5440.08it/s, Materializing param=embeddings.LayerNorm.weight]\n",
            "Loading weights:   2%|â–         | 2/103 [00:00<00:00, 4146.62it/s, Materializing param=embeddings.LayerNorm.weight]\n",
            "Loading weights:   3%|â–Ž         | 3/103 [00:00<00:00, 4482.69it/s, Materializing param=embeddings.position_embeddings.weight]\n",
            "Loading weights:   3%|â–Ž         | 3/103 [00:00<00:00, 3960.63it/s, Materializing param=embeddings.position_embeddings.weight]\n",
            "Loading weights:   4%|â–         | 4/103 [00:00<00:00, 4447.83it/s, Materializing param=embeddings.token_type_embeddings.weight]\n",
            "Loading weights:   4%|â–         | 4/103 [00:00<00:00, 4027.18it/s, Materializing param=embeddings.token_type_embeddings.weight]\n",
            "Loading weights:   5%|â–         | 5/103 [00:00<00:00, 4362.70it/s, Materializing param=embeddings.word_embeddings.weight]      \n",
            "Loading weights:   5%|â–         | 5/103 [00:00<00:00, 4068.19it/s, Materializing param=embeddings.word_embeddings.weight]\n",
            "Loading weights:   6%|â–Œ         | 6/103 [00:00<00:00, 4402.70it/s, Materializing param=encoder.layer.0.attention.output.LayerNorm.bias]\n",
            "Loading weights:   6%|â–Œ         | 6/103 [00:00<00:00, 4152.78it/s, Materializing param=encoder.layer.0.attention.output.LayerNorm.bias]\n",
            "Loading weights:   7%|â–‹         | 7/103 [00:00<00:00, 922.11it/s, Materializing param=encoder.layer.0.attention.output.LayerNorm.weight]\n",
            "Loading weights:   7%|â–‹         | 7/103 [00:00<00:00, 906.79it/s, Materializing param=encoder.layer.0.attention.output.LayerNorm.weight]\n",
            "Loading weights:   8%|â–Š         | 8/103 [00:00<00:00, 1014.68it/s, Materializing param=encoder.layer.0.attention.output.dense.bias]     \n",
            "Loading weights:   8%|â–Š         | 8/103 [00:00<00:00, 1001.62it/s, Materializing param=encoder.layer.0.attention.output.dense.bias]\n",
            "Loading weights:   9%|â–Š         | 9/103 [00:00<00:00, 1103.34it/s, Materializing param=encoder.layer.0.attention.output.dense.weight]\n",
            "Loading weights:   9%|â–Š         | 9/103 [00:00<00:00, 1092.14it/s, Materializing param=encoder.layer.0.attention.output.dense.weight]\n",
            "Loading weights:  10%|â–‰         | 10/103 [00:00<00:00, 1192.21it/s, Materializing param=encoder.layer.0.attention.self.key.bias]     \n",
            "Loading weights:  10%|â–‰         | 10/103 [00:00<00:00, 1178.84it/s, Materializing param=encoder.layer.0.attention.self.key.bias]\n",
            "Loading weights:  11%|â–ˆ         | 11/103 [00:00<00:00, 1272.75it/s, Materializing param=encoder.layer.0.attention.self.key.weight]\n",
            "Loading weights:  11%|â–ˆ         | 11/103 [00:00<00:00, 1261.00it/s, Materializing param=encoder.layer.0.attention.self.key.weight]\n",
            "Loading weights:  12%|â–ˆâ–        | 12/103 [00:00<00:00, 1353.77it/s, Materializing param=encoder.layer.0.attention.self.query.bias]\n",
            "Loading weights:  12%|â–ˆâ–        | 12/103 [00:00<00:00, 1341.93it/s, Materializing param=encoder.layer.0.attention.self.query.bias]\n",
            "Loading weights:  13%|â–ˆâ–Ž        | 13/103 [00:00<00:00, 1430.68it/s, Materializing param=encoder.layer.0.attention.self.query.weight]\n",
            "Loading weights:  13%|â–ˆâ–Ž        | 13/103 [00:00<00:00, 1416.88it/s, Materializing param=encoder.layer.0.attention.self.query.weight]\n",
            "Loading weights:  14%|â–ˆâ–Ž        | 14/103 [00:00<00:00, 1500.84it/s, Materializing param=encoder.layer.0.attention.self.value.bias]  \n",
            "Loading weights:  14%|â–ˆâ–Ž        | 14/103 [00:00<00:00, 1487.94it/s, Materializing param=encoder.layer.0.attention.self.value.bias]\n",
            "Loading weights:  15%|â–ˆâ–        | 15/103 [00:00<00:00, 986.46it/s, Materializing param=encoder.layer.0.attention.self.value.weight]\n",
            "Loading weights:  15%|â–ˆâ–        | 15/103 [00:00<00:00, 978.38it/s, Materializing param=encoder.layer.0.attention.self.value.weight]\n",
            "Loading weights:  16%|â–ˆâ–Œ        | 16/103 [00:00<00:00, 1029.91it/s, Materializing param=encoder.layer.0.intermediate.dense.bias]   \n",
            "Loading weights:  16%|â–ˆâ–Œ        | 16/103 [00:00<00:00, 1023.56it/s, Materializing param=encoder.layer.0.intermediate.dense.bias]\n",
            "Loading weights:  17%|â–ˆâ–‹        | 17/103 [00:00<00:00, 1076.97it/s, Materializing param=encoder.layer.0.intermediate.dense.weight]\n",
            "Loading weights:  17%|â–ˆâ–‹        | 17/103 [00:00<00:00, 1071.31it/s, Materializing param=encoder.layer.0.intermediate.dense.weight]\n",
            "Loading weights:  17%|â–ˆâ–‹        | 18/103 [00:00<00:00, 1123.99it/s, Materializing param=encoder.layer.0.output.LayerNorm.bias]    \n",
            "Loading weights:  17%|â–ˆâ–‹        | 18/103 [00:00<00:00, 1118.41it/s, Materializing param=encoder.layer.0.output.LayerNorm.bias]\n",
            "Loading weights:  18%|â–ˆâ–Š        | 19/103 [00:00<00:00, 1169.36it/s, Materializing param=encoder.layer.0.output.LayerNorm.weight]\n",
            "Loading weights:  18%|â–ˆâ–Š        | 19/103 [00:00<00:00, 1163.06it/s, Materializing param=encoder.layer.0.output.LayerNorm.weight]\n",
            "Loading weights:  19%|â–ˆâ–‰        | 20/103 [00:00<00:00, 906.02it/s, Materializing param=encoder.layer.0.output.dense.bias]       \n",
            "Loading weights:  19%|â–ˆâ–‰        | 20/103 [00:00<00:00, 900.59it/s, Materializing param=encoder.layer.0.output.dense.bias]\n",
            "Loading weights:  20%|â–ˆâ–ˆ        | 21/103 [00:00<00:00, 937.54it/s, Materializing param=encoder.layer.0.output.dense.weight]\n",
            "Loading weights:  20%|â–ˆâ–ˆ        | 21/103 [00:00<00:00, 932.35it/s, Materializing param=encoder.layer.0.output.dense.weight]\n",
            "Loading weights:  21%|â–ˆâ–ˆâ–       | 22/103 [00:00<00:00, 969.49it/s, Materializing param=encoder.layer.1.attention.output.LayerNorm.bias]\n",
            "Loading weights:  21%|â–ˆâ–ˆâ–       | 22/103 [00:00<00:00, 965.89it/s, Materializing param=encoder.layer.1.attention.output.LayerNorm.bias]\n",
            "Loading weights:  22%|â–ˆâ–ˆâ–       | 23/103 [00:00<00:00, 1003.09it/s, Materializing param=encoder.layer.1.attention.output.LayerNorm.weight]\n",
            "Loading weights:  22%|â–ˆâ–ˆâ–       | 23/103 [00:00<00:00, 999.42it/s, Materializing param=encoder.layer.1.attention.output.LayerNorm.weight] \n",
            "Loading weights:  23%|â–ˆâ–ˆâ–Ž       | 24/103 [00:00<00:00, 1036.00it/s, Materializing param=encoder.layer.1.attention.output.dense.bias]     \n",
            "Loading weights:  23%|â–ˆâ–ˆâ–Ž       | 24/103 [00:00<00:00, 1032.34it/s, Materializing param=encoder.layer.1.attention.output.dense.bias]\n",
            "Loading weights:  24%|â–ˆâ–ˆâ–       | 25/103 [00:00<00:00, 1068.87it/s, Materializing param=encoder.layer.1.attention.output.dense.weight]\n",
            "Loading weights:  24%|â–ˆâ–ˆâ–       | 25/103 [00:00<00:00, 1063.89it/s, Materializing param=encoder.layer.1.attention.output.dense.weight]\n",
            "Loading weights:  25%|â–ˆâ–ˆâ–Œ       | 26/103 [00:00<00:00, 866.72it/s, Materializing param=encoder.layer.1.attention.self.key.bias]       \n",
            "Loading weights:  25%|â–ˆâ–ˆâ–Œ       | 26/103 [00:00<00:00, 863.18it/s, Materializing param=encoder.layer.1.attention.self.key.bias]\n",
            "Loading weights:  26%|â–ˆâ–ˆâ–Œ       | 27/103 [00:00<00:00, 890.99it/s, Materializing param=encoder.layer.1.attention.self.key.weight]\n",
            "Loading weights:  26%|â–ˆâ–ˆâ–Œ       | 27/103 [00:00<00:00, 888.49it/s, Materializing param=encoder.layer.1.attention.self.key.weight]\n",
            "Loading weights:  27%|â–ˆâ–ˆâ–‹       | 28/103 [00:00<00:00, 915.78it/s, Materializing param=encoder.layer.1.attention.self.query.bias]\n",
            "Loading weights:  27%|â–ˆâ–ˆâ–‹       | 28/103 [00:00<00:00, 913.07it/s, Materializing param=encoder.layer.1.attention.self.query.bias]\n",
            "Loading weights:  28%|â–ˆâ–ˆâ–Š       | 29/103 [00:00<00:00, 940.85it/s, Materializing param=encoder.layer.1.attention.self.query.weight]\n",
            "Loading weights:  28%|â–ˆâ–ˆâ–Š       | 29/103 [00:00<00:00, 938.31it/s, Materializing param=encoder.layer.1.attention.self.query.weight]\n",
            "Loading weights:  29%|â–ˆâ–ˆâ–‰       | 30/103 [00:00<00:00, 966.08it/s, Materializing param=encoder.layer.1.attention.self.value.bias]  \n",
            "Loading weights:  29%|â–ˆâ–ˆâ–‰       | 30/103 [00:00<00:00, 963.69it/s, Materializing param=encoder.layer.1.attention.self.value.bias]\n",
            "Loading weights:  30%|â–ˆâ–ˆâ–ˆ       | 31/103 [00:00<00:00, 991.09it/s, Materializing param=encoder.layer.1.attention.self.value.weight]\n",
            "Loading weights:  30%|â–ˆâ–ˆâ–ˆ       | 31/103 [00:00<00:00, 988.64it/s, Materializing param=encoder.layer.1.attention.self.value.weight]\n",
            "Loading weights:  31%|â–ˆâ–ˆâ–ˆ       | 32/103 [00:00<00:00, 832.39it/s, Materializing param=encoder.layer.1.intermediate.dense.bias]    \n",
            "Loading weights:  31%|â–ˆâ–ˆâ–ˆ       | 32/103 [00:00<00:00, 829.40it/s, Materializing param=encoder.layer.1.intermediate.dense.bias]\n",
            "Loading weights:  32%|â–ˆâ–ˆâ–ˆâ–      | 33/103 [00:00<00:00, 851.30it/s, Materializing param=encoder.layer.1.intermediate.dense.weight]\n",
            "Loading weights:  32%|â–ˆâ–ˆâ–ˆâ–      | 33/103 [00:00<00:00, 849.40it/s, Materializing param=encoder.layer.1.intermediate.dense.weight]\n",
            "Loading weights:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 34/103 [00:00<00:00, 871.79it/s, Materializing param=encoder.layer.1.output.LayerNorm.bias]    \n",
            "Loading weights:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 34/103 [00:00<00:00, 869.53it/s, Materializing param=encoder.layer.1.output.LayerNorm.bias]\n",
            "Loading weights:  34%|â–ˆâ–ˆâ–ˆâ–      | 35/103 [00:00<00:00, 891.39it/s, Materializing param=encoder.layer.1.output.LayerNorm.weight]\n",
            "Loading weights:  34%|â–ˆâ–ˆâ–ˆâ–      | 35/103 [00:00<00:00, 889.58it/s, Materializing param=encoder.layer.1.output.LayerNorm.weight]\n",
            "Loading weights:  35%|â–ˆâ–ˆâ–ˆâ–      | 36/103 [00:00<00:00, 911.45it/s, Materializing param=encoder.layer.1.output.dense.bias]      \n",
            "Loading weights:  35%|â–ˆâ–ˆâ–ˆâ–      | 36/103 [00:00<00:00, 909.47it/s, Materializing param=encoder.layer.1.output.dense.bias]\n",
            "Loading weights:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 37/103 [00:00<00:00, 931.39it/s, Materializing param=encoder.layer.1.output.dense.weight]\n",
            "Loading weights:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 37/103 [00:00<00:00, 929.61it/s, Materializing param=encoder.layer.1.output.dense.weight]\n",
            "Loading weights:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 38/103 [00:00<00:00, 951.50it/s, Materializing param=encoder.layer.2.attention.output.LayerNorm.bias]\n",
            "Loading weights:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 38/103 [00:00<00:00, 949.59it/s, Materializing param=encoder.layer.2.attention.output.LayerNorm.bias]\n",
            "Loading weights:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 39/103 [00:00<00:00, 833.77it/s, Materializing param=encoder.layer.2.attention.output.LayerNorm.weight]\n",
            "Loading weights:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 39/103 [00:00<00:00, 831.41it/s, Materializing param=encoder.layer.2.attention.output.LayerNorm.weight]\n",
            "Loading weights:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 40/103 [00:00<00:00, 849.55it/s, Materializing param=encoder.layer.2.attention.output.dense.bias]      \n",
            "Loading weights:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 40/103 [00:00<00:00, 847.82it/s, Materializing param=encoder.layer.2.attention.output.dense.bias]\n",
            "Loading weights:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 41/103 [00:00<00:00, 866.24it/s, Materializing param=encoder.layer.2.attention.output.dense.weight]\n",
            "Loading weights:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 41/103 [00:00<00:00, 864.54it/s, Materializing param=encoder.layer.2.attention.output.dense.weight]\n",
            "Loading weights:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 42/103 [00:00<00:00, 882.31it/s, Materializing param=encoder.layer.2.attention.self.key.bias]      \n",
            "Loading weights:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 42/103 [00:00<00:00, 880.80it/s, Materializing param=encoder.layer.2.attention.self.key.bias]\n",
            "Loading weights:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/103 [00:00<00:00, 899.08it/s, Materializing param=encoder.layer.2.attention.self.key.weight]\n",
            "Loading weights:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/103 [00:00<00:00, 897.61it/s, Materializing param=encoder.layer.2.attention.self.key.weight]\n",
            "Loading weights:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 44/103 [00:00<00:00, 915.63it/s, Materializing param=encoder.layer.2.attention.self.query.bias]\n",
            "Loading weights:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 44/103 [00:00<00:00, 914.16it/s, Materializing param=encoder.layer.2.attention.self.query.bias]\n",
            "Loading weights:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 45/103 [00:00<00:00, 829.77it/s, Materializing param=encoder.layer.2.attention.self.query.weight]\n",
            "Loading weights:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 45/103 [00:00<00:00, 827.84it/s, Materializing param=encoder.layer.2.attention.self.query.weight]\n",
            "Loading weights:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 46/103 [00:00<00:00, 843.30it/s, Materializing param=encoder.layer.2.attention.self.value.bias]  \n",
            "Loading weights:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 46/103 [00:00<00:00, 841.85it/s, Materializing param=encoder.layer.2.attention.self.value.bias]\n",
            "Loading weights:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 47/103 [00:00<00:00, 857.57it/s, Materializing param=encoder.layer.2.attention.self.value.weight]\n",
            "Loading weights:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 47/103 [00:00<00:00, 856.30it/s, Materializing param=encoder.layer.2.attention.self.value.weight]\n",
            "Loading weights:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 48/103 [00:00<00:00, 872.20it/s, Materializing param=encoder.layer.2.intermediate.dense.bias]    \n",
            "Loading weights:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 48/103 [00:00<00:00, 870.94it/s, Materializing param=encoder.layer.2.intermediate.dense.bias]\n",
            "Loading weights:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 49/103 [00:00<00:00, 789.30it/s, Materializing param=encoder.layer.2.intermediate.dense.weight]\n",
            "Loading weights:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 49/103 [00:00<00:00, 787.57it/s, Materializing param=encoder.layer.2.intermediate.dense.weight]\n",
            "Loading weights:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 50/103 [00:00<00:00, 801.32it/s, Materializing param=encoder.layer.2.output.LayerNorm.bias]    \n",
            "Loading weights:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 50/103 [00:00<00:00, 799.66it/s, Materializing param=encoder.layer.2.output.LayerNorm.bias]\n",
            "Loading weights:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 51/103 [00:00<00:00, 813.18it/s, Materializing param=encoder.layer.2.output.LayerNorm.weight]\n",
            "Loading weights:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 51/103 [00:00<00:00, 811.99it/s, Materializing param=encoder.layer.2.output.LayerNorm.weight]\n",
            "Loading weights:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 52/103 [00:00<00:00, 825.72it/s, Materializing param=encoder.layer.2.output.dense.bias]      \n",
            "Loading weights:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 52/103 [00:00<00:00, 824.55it/s, Materializing param=encoder.layer.2.output.dense.bias]\n",
            "Loading weights:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 53/103 [00:00<00:00, 838.14it/s, Materializing param=encoder.layer.2.output.dense.weight]\n",
            "Loading weights:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 53/103 [00:00<00:00, 836.95it/s, Materializing param=encoder.layer.2.output.dense.weight]\n",
            "Loading weights:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 54/103 [00:00<00:00, 766.51it/s, Materializing param=encoder.layer.3.attention.output.LayerNorm.bias]\n",
            "Loading weights:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 54/103 [00:00<00:00, 764.59it/s, Materializing param=encoder.layer.3.attention.output.LayerNorm.bias]\n",
            "Loading weights:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 55/103 [00:00<00:00, 775.79it/s, Materializing param=encoder.layer.3.attention.output.LayerNorm.weight]\n",
            "Loading weights:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 55/103 [00:00<00:00, 774.55it/s, Materializing param=encoder.layer.3.attention.output.LayerNorm.weight]\n",
            "Loading weights:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 56/103 [00:00<00:00, 786.20it/s, Materializing param=encoder.layer.3.attention.output.dense.bias]      \n",
            "Loading weights:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 56/103 [00:00<00:00, 785.03it/s, Materializing param=encoder.layer.3.attention.output.dense.bias]\n",
            "Loading weights:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 57/103 [00:00<00:00, 736.84it/s, Materializing param=encoder.layer.3.attention.output.dense.weight]\n",
            "Loading weights:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 57/103 [00:00<00:00, 735.40it/s, Materializing param=encoder.layer.3.attention.output.dense.weight]\n",
            "Loading weights:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 58/103 [00:00<00:00, 746.37it/s, Materializing param=encoder.layer.3.attention.self.key.bias]      \n",
            "Loading weights:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 58/103 [00:00<00:00, 745.53it/s, Materializing param=encoder.layer.3.attention.self.key.bias]\n",
            "Loading weights:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 59/103 [00:00<00:00, 756.86it/s, Materializing param=encoder.layer.3.attention.self.key.weight]\n",
            "Loading weights:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 59/103 [00:00<00:00, 756.06it/s, Materializing param=encoder.layer.3.attention.self.key.weight]\n",
            "Loading weights:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 60/103 [00:00<00:00, 767.20it/s, Materializing param=encoder.layer.3.attention.self.query.bias]\n",
            "Loading weights:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 60/103 [00:00<00:00, 766.37it/s, Materializing param=encoder.layer.3.attention.self.query.bias]\n",
            "Loading weights:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 61/103 [00:00<00:00, 777.71it/s, Materializing param=encoder.layer.3.attention.self.query.weight]\n",
            "Loading weights:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 61/103 [00:00<00:00, 714.87it/s, Materializing param=encoder.layer.3.attention.self.query.weight]\n",
            "Loading weights:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 62/103 [00:00<00:00, 724.30it/s, Materializing param=encoder.layer.3.attention.self.value.bias]  \n",
            "Loading weights:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 62/103 [00:00<00:00, 723.26it/s, Materializing param=encoder.layer.3.attention.self.value.bias]\n",
            "Loading weights:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 63/103 [00:00<00:00, 733.26it/s, Materializing param=encoder.layer.3.attention.self.value.weight]\n",
            "Loading weights:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 63/103 [00:00<00:00, 732.42it/s, Materializing param=encoder.layer.3.attention.self.value.weight]\n",
            "Loading weights:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 64/103 [00:00<00:00, 742.63it/s, Materializing param=encoder.layer.3.intermediate.dense.bias]    \n",
            "Loading weights:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 64/103 [00:00<00:00, 741.92it/s, Materializing param=encoder.layer.3.intermediate.dense.bias]\n",
            "Loading weights:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 65/103 [00:00<00:00, 752.27it/s, Materializing param=encoder.layer.3.intermediate.dense.weight]\n",
            "Loading weights:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 65/103 [00:00<00:00, 751.27it/s, Materializing param=encoder.layer.3.intermediate.dense.weight]\n",
            "Loading weights:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 66/103 [00:00<00:00, 761.47it/s, Materializing param=encoder.layer.3.output.LayerNorm.bias]    \n",
            "Loading weights:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 66/103 [00:00<00:00, 760.78it/s, Materializing param=encoder.layer.3.output.LayerNorm.bias]\n",
            "Loading weights:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 67/103 [00:00<00:00, 771.08it/s, Materializing param=encoder.layer.3.output.LayerNorm.weight]\n",
            "Loading weights:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 67/103 [00:00<00:00, 770.37it/s, Materializing param=encoder.layer.3.output.LayerNorm.weight]\n",
            "Loading weights:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 68/103 [00:00<00:00, 780.68it/s, Materializing param=encoder.layer.3.output.dense.bias]      \n",
            "Loading weights:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 68/103 [00:00<00:00, 779.93it/s, Materializing param=encoder.layer.3.output.dense.bias]\n",
            "Loading weights:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 69/103 [00:00<00:00, 790.17it/s, Materializing param=encoder.layer.3.output.dense.weight]\n",
            "Loading weights:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 69/103 [00:00<00:00, 789.49it/s, Materializing param=encoder.layer.3.output.dense.weight]\n",
            "Loading weights:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 70/103 [00:00<00:00, 744.98it/s, Materializing param=encoder.layer.4.attention.output.LayerNorm.bias]\n",
            "Loading weights:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 70/103 [00:00<00:00, 744.01it/s, Materializing param=encoder.layer.4.attention.output.LayerNorm.bias]\n",
            "Loading weights:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 71/103 [00:00<00:00, 753.14it/s, Materializing param=encoder.layer.4.attention.output.LayerNorm.weight]\n",
            "Loading weights:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 71/103 [00:00<00:00, 752.36it/s, Materializing param=encoder.layer.4.attention.output.LayerNorm.weight]\n",
            "Loading weights:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 72/103 [00:00<00:00, 761.29it/s, Materializing param=encoder.layer.4.attention.output.dense.bias]      \n",
            "Loading weights:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 72/103 [00:00<00:00, 760.54it/s, Materializing param=encoder.layer.4.attention.output.dense.bias]\n",
            "Loading weights:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 73/103 [00:00<00:00, 769.85it/s, Materializing param=encoder.layer.4.attention.output.dense.weight]\n",
            "Loading weights:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 73/103 [00:00<00:00, 769.16it/s, Materializing param=encoder.layer.4.attention.output.dense.weight]\n",
            "Loading weights:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 74/103 [00:00<00:00, 778.38it/s, Materializing param=encoder.layer.4.attention.self.key.bias]      \n",
            "Loading weights:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 74/103 [00:00<00:00, 777.64it/s, Materializing param=encoder.layer.4.attention.self.key.bias]\n",
            "Loading weights:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 75/103 [00:00<00:00, 786.95it/s, Materializing param=encoder.layer.4.attention.self.key.weight]\n",
            "Loading weights:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 75/103 [00:00<00:00, 786.33it/s, Materializing param=encoder.layer.4.attention.self.key.weight]\n",
            "Loading weights:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 76/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.4.attention.self.key.weight]\n",
            "Loading weights:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 76/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.4.attention.self.query.bias]\n",
            "Loading weights:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 76/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.4.attention.self.query.bias]\n",
            "Loading weights:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 77/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.4.attention.self.query.weight]\n",
            "Loading weights:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 77/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.4.attention.self.query.weight]\n",
            "Loading weights:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 78/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.4.attention.self.value.bias]  \n",
            "Loading weights:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 78/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.4.attention.self.value.bias]\n",
            "Loading weights:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 79/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.4.attention.self.value.weight]\n",
            "Loading weights:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 79/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.4.attention.self.value.weight]\n",
            "Loading weights:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 80/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.4.intermediate.dense.bias]    \n",
            "Loading weights:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 80/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.4.intermediate.dense.bias]\n",
            "Loading weights:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 81/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.4.intermediate.dense.weight]\n",
            "Loading weights:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 81/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.4.intermediate.dense.weight]\n",
            "Loading weights:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 82/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.4.output.LayerNorm.bias]    \n",
            "Loading weights:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 82/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.4.output.LayerNorm.bias]\n",
            "Loading weights:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 83/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.4.output.LayerNorm.weight]\n",
            "Loading weights:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 83/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.4.output.LayerNorm.weight]\n",
            "Loading weights:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 84/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.4.output.dense.bias]      \n",
            "Loading weights:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 84/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.4.output.dense.bias]\n",
            "Loading weights:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 85/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.4.output.dense.weight]\n",
            "Loading weights:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 85/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.4.output.dense.weight]\n",
            "Loading weights:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 86/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.5.attention.output.LayerNorm.bias]\n",
            "Loading weights:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 86/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.5.attention.output.LayerNorm.bias]\n",
            "Loading weights:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 87/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.5.attention.output.LayerNorm.weight]\n",
            "Loading weights:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 87/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.5.attention.output.LayerNorm.weight]\n",
            "Loading weights:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 88/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.5.attention.output.dense.bias]      \n",
            "Loading weights:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 88/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.5.attention.output.dense.bias]\n",
            "Loading weights:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 89/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.5.attention.output.dense.weight]\n",
            "Loading weights:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 89/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.5.attention.output.dense.weight]\n",
            "Loading weights:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 90/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.5.attention.self.key.bias]      \n",
            "Loading weights:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 90/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.5.attention.self.key.bias]\n",
            "Loading weights:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 91/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.5.attention.self.key.weight]\n",
            "Loading weights:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 91/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.5.attention.self.key.weight]\n",
            "Loading weights:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 92/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.5.attention.self.query.bias]\n",
            "Loading weights:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 92/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.5.attention.self.query.bias]\n",
            "Loading weights:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 93/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.5.attention.self.query.weight]\n",
            "Loading weights:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 93/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.5.attention.self.query.weight]\n",
            "Loading weights:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 94/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.5.attention.self.value.bias]  \n",
            "Loading weights:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 94/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.5.attention.self.value.bias]\n",
            "Loading weights:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 95/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.5.attention.self.value.weight]\n",
            "Loading weights:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 95/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.5.attention.self.value.weight]\n",
            "Loading weights:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 96/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.5.intermediate.dense.bias]    \n",
            "Loading weights:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 96/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.5.intermediate.dense.bias]\n",
            "Loading weights:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 97/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.5.intermediate.dense.weight]\n",
            "Loading weights:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 97/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.5.intermediate.dense.weight]\n",
            "Loading weights:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 98/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.5.output.LayerNorm.bias]    \n",
            "Loading weights:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 98/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.5.output.LayerNorm.bias]\n",
            "Loading weights:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 99/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.5.output.LayerNorm.weight]\n",
            "Loading weights:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 99/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.5.output.LayerNorm.weight]\n",
            "Loading weights:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 100/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.5.output.dense.bias]     \n",
            "Loading weights:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 100/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.5.output.dense.bias]\n",
            "Loading weights:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 101/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.5.output.dense.weight]\n",
            "Loading weights:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 101/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.5.output.dense.weight]\n",
            "Loading weights:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 102/103 [00:00<00:00, 748.11it/s, Materializing param=pooler.dense.bias]                  \n",
            "Loading weights:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 102/103 [00:00<00:00, 748.11it/s, Materializing param=pooler.dense.bias]\n",
            "Loading weights: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 103/103 [00:00<00:00, 748.11it/s, Materializing param=pooler.dense.weight]\n",
            "Loading weights: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 103/103 [00:00<00:00, 748.11it/s, Materializing param=pooler.dense.weight]\n",
            "Loading weights: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 103/103 [00:00<00:00, 782.15it/s, Materializing param=pooler.dense.weight]\n",
            "BertModel LOAD REPORT from: sentence-transformers/all-MiniLM-L6-v2\n",
            "Key                     | Status     |  | \n",
            "------------------------+------------+--+-\n",
            "embeddings.position_ids | UNEXPECTED |  | \n",
            "\n",
            "Notes:\n",
            "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n",
            "INFO:httpx:HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/config.json \"HTTP/1.1 307 Temporary Redirect\"\n",
            "INFO:httpx:HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config.json \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/tokenizer_config.json \"HTTP/1.1 307 Temporary Redirect\"\n",
            "INFO:httpx:HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/tokenizer_config.json \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: GET https://huggingface.co/api/models/sentence-transformers/all-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=false&expand=false \"HTTP/1.1 404 Not Found\"\n",
            "INFO:httpx:HTTP Request: GET https://huggingface.co/api/models/sentence-transformers/all-MiniLM-L6-v2/tree/main?recursive=true&expand=false \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/1_Pooling/config.json \"HTTP/1.1 307 Temporary Redirect\"\n",
            "INFO:httpx:HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/1_Pooling%2Fconfig.json \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: GET https://huggingface.co/api/models/sentence-transformers/all-MiniLM-L6-v2 \"HTTP/1.1 200 OK\"\n",
            "INFO:     Application startup complete.\n",
            "INFO:     Uvicorn running on http://0.0.0.0:8002 (Press CTRL+C to quit)\n",
            "Memory service started on 0.0.0.0:8001\n",
            "INFO:     127.0.0.1:53380 - \"GET /health HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:53382 - \"GET /health HTTP/1.1\" 200 OK\n",
            "\n",
            "\n",
            "--- /tmp/code_exec.log ---\n",
            "INFO:     Started server process [36793]\n",
            "INFO:     Waiting for application startup.\n",
            "2026-02-08 04:26:51,538 - code_exec.service.main - INFO - Starting Code Executor Service\n",
            "2026-02-08 04:26:51,538 - code_exec.service.main - INFO - Skills directory: /Users/paragpradhan/Projects/Agent framework/agent-framework/code-exec/skills\n",
            "2026-02-08 04:26:51,543 - code_exec.service.registry - INFO - Loading skills from: /Users/paragpradhan/Projects/Agent framework/agent-framework/code-exec/skills\n",
            "2026-02-08 04:26:51,544 - code_exec.service.registry - INFO - Loaded 0 skills successfully\n",
            "2026-02-08 04:26:51,544 - code_exec.service.main - INFO - Loaded 0 skills\n",
            "2026-02-08 04:26:51,544 - code_exec.service.main - INFO - Service ready on 0.0.0.0:8002\n",
            "INFO:     Application startup complete.\n",
            "INFO:     Uvicorn running on http://0.0.0.0:8004 (Press CTRL+C to quit)\n",
            "INFO:     127.0.0.1:55428 - \"GET /health HTTP/1.1\" 200 OK\n",
            "\n",
            "\n",
            "--- /tmp/subagent_manager.log ---\n",
            "INFO:     Started server process [36805]\n",
            "INFO:     Waiting for application startup.\n",
            "INFO:     Application startup complete.\n",
            "INFO:     Uvicorn running on http://0.0.0.0:8003 (Press CTRL+C to quit)\n",
            "INFO:     127.0.0.1:49356 - \"GET /health HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:49372 - \"GET /health HTTP/1.1\" 200 OK\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ed8a78b8",
        "outputId": "240d673c-9aa7-4715-fd11-3921694d9d11"
      },
      "source": [
        "import subprocess, os\n",
        "\n",
        "print(\"=== PORT DIAGNOSTICS ===\")\n",
        "# Check what's listening on ports 9000 (MinIO) and 8004 (Code Exec)\n",
        "for port in [9000, 9001, 8004]:\n",
        "    print(f\"\\nChecking Port {port}...\")\n",
        "    # lsof -i :port\n",
        "    res = subprocess.run(f\"lsof -i :{port}\", shell=True, capture_output=True, text=True)\n",
        "    if res.stdout.strip():\n",
        "        print(res.stdout)\n",
        "    else:\n",
        "        print(\"  (No process found listening)\")\n",
        "\n",
        "print(\"\\n=== SERVICE LOGS (Last 50 lines) ===\")\n",
        "logs = [\"/tmp/minio.log\", \"/tmp/code_exec.log\", \"/tmp/memory_service.log\"]\n",
        "for log in logs:\n",
        "    print(f\"\\n--- {log} ---\")\n",
        "    if os.path.exists(log):\n",
        "        # check file size\n",
        "        size = os.path.getsize(log)\n",
        "        print(f\"  Size: {size} bytes\")\n",
        "        if size > 0:\n",
        "            subprocess.run(f\"tail -n 50 {log}\", shell=True)\n",
        "        else:\n",
        "            print(\"  (Empty file)\")\n",
        "    else:\n",
        "        print(\"  (File does not exist)\")"
      ],
      "id": "ed8a78b8",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== PORT DIAGNOSTICS ===\n",
            "\n",
            "Checking Port 9000...\n",
            "COMMAND   PID USER   FD   TYPE DEVICE SIZE/OFF NODE NAME\n",
            "kernel_ma  12 root    9u  IPv4 549882      0t0  TCP b2412b48cfa2:57236->b2412b48cfa2:9000 (ESTABLISHED)\n",
            "kernel_ma  12 root   10u  IPv4 550931      0t0  TCP b2412b48cfa2:57244->b2412b48cfa2:9000 (ESTABLISHED)\n",
            "jupyter-s 101 root    7u  IPv4 549865      0t0  TCP b2412b48cfa2:9000 (LISTEN)\n",
            "jupyter-s 101 root    8u  IPv4 549883      0t0  TCP b2412b48cfa2:9000->b2412b48cfa2:57236 (ESTABLISHED)\n",
            "jupyter-s 101 root   16u  IPv4 550932      0t0  TCP b2412b48cfa2:9000->b2412b48cfa2:57244 (ESTABLISHED)\n",
            "\n",
            "\n",
            "Checking Port 9001...\n",
            "COMMAND   PID USER   FD   TYPE  DEVICE SIZE/OFF NODE NAME\n",
            "minio   36767 root    6u  IPv6 1369528      0t0  TCP *:9001 (LISTEN)\n",
            "\n",
            "\n",
            "Checking Port 8004...\n",
            "COMMAND   PID USER   FD   TYPE  DEVICE SIZE/OFF NODE NAME\n",
            "python3 36793 root   13u  IPv4 1369748      0t0  TCP *:8004 (LISTEN)\n",
            "\n",
            "\n",
            "=== SERVICE LOGS (Last 50 lines) ===\n",
            "\n",
            "--- /tmp/minio.log ---\n",
            "  Size: 496 bytes\n",
            "\n",
            "--- /tmp/code_exec.log ---\n",
            "  Size: 911 bytes\n",
            "\n",
            "--- /tmp/memory_service.log ---\n",
            "  Size: 34767 bytes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "94b7a06a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "94b7a06a",
        "outputId": "d2423d99-758f-4178-8825-7aa7fad6dfab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "PHASE 5: EXTERNAL ACCESS\n",
            "============================================================\n",
            "\n",
            "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
            "â•‘  ðŸš€ SYSTEM READY - ACCESS LINKS                         â•‘\n",
            "â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£\n",
            "â•‘  ðŸ“Š Dashboard: https://unliquid-blithely-glenda.ngrok-free.devâ•‘\n",
            "â•‘  ðŸ”Œ API:       https://unliquid-blithely-glenda.ngrok-free.devâ•‘\n",
            "â•‘  ðŸ“„ Docs:      https://unliquid-blithely-glenda.ngrok-free.dev/docsâ•‘\n",
            "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
        "# â•‘  PHASE 5: External Access (ngrok Tunnels)                   â•‘\n",
        "# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "import os\n",
        "from pyngrok import ngrok, conf\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"PHASE 5: EXTERNAL ACCESS\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Configuration\n",
        "NGROK_AUTH_TOKEN = \"39MaIP07IiJMHPNDgd3raMEOL6r_2KyacFVXP68bbxBu9s8E8\"\n",
        "\n",
        "if NGROK_AUTH_TOKEN:\n",
        "    ngrok.set_auth_token(NGROK_AUTH_TOKEN)\n",
        "    ngrok.kill()\n",
        "\n",
        "    # API Tunnel (8000)\n",
        "    api_tunnel = ngrok.connect(8000, \"http\")\n",
        "    api_url = api_tunnel.public_url\n",
        "\n",
        "    # Dashboard Tunnel (3000)\n",
        "    dash_tunnel = ngrok.connect(3000, \"http\")\n",
        "    dash_url = dash_tunnel.public_url\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\")\n",
        "    print(\"â•‘  ðŸš€ SYSTEM READY - ACCESS LINKS                         â•‘\")\n",
        "    print(\"â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£\")\n",
        "    print(f\"â•‘  ðŸ“Š Dashboard: {dash_url:<41s}â•‘\")\n",
        "    print(f\"â•‘  ðŸ”Œ API:       {api_url:<41s}â•‘\")\n",
        "    print(f\"â•‘  ðŸ“„ Docs:      {api_url + '/docs':<41s}â•‘\")\n",
        "    print(\"â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\")\n",
        "else:\n",
        "    print(\"âŒ No ngrok token found. Services available locally only.\")\n",
        "\n",
        "print(\"=\" * 60)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4658f5ae",
        "outputId": "c5d7874a-159f-4099-c22d-ca47dd98518a"
      },
      "source": [
        "import subprocess, os\n",
        "\n",
        "print(\"=== PORT CHECK ===\")\n",
        "# Check ports 3000 (Dashboard) and 8080 (MCP)\n",
        "for port in [3000, 8080]:\n",
        "    res = subprocess.run(f\"lsof -i :{port}\", shell=True, capture_output=True, text=True)\n",
        "    print(f\"\\n[:{port}] {'OPEN' if res.stdout.strip() else 'CLOSED'}\")\n",
        "    if res.stdout.strip():\n",
        "        print(res.stdout)\n",
        "\n",
        "print(\"\\n=== LOGS ===\")\n",
        "logs = [\"/tmp/dashboard.log\", \"/tmp/mcp_gateway.log\"]\n",
        "for log in logs:\n",
        "    print(f\"\\n--- {log} ---\")\n",
        "    if os.path.exists(log):\n",
        "        subprocess.run(f\"tail -n 50 {log}\", shell=True)\n",
        "    else:\n",
        "        print(\"(File not found)\")"
      ],
      "id": "4658f5ae",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== PORT CHECK ===\n",
            "\n",
            "[:3000] CLOSED\n",
            "\n",
            "[:8080] OPEN\n",
            "COMMAND PID USER   FD   TYPE  DEVICE SIZE/OFF NODE NAME\n",
            "node      7 root   21u  IPv6  549965      0t0  TCP *:http-alt (LISTEN)\n",
            "node      7 root   26u  IPv6  550927      0t0  TCP b2412b48cfa2:http-alt->172.28.0.1:49222 (ESTABLISHED)\n",
            "node      7 root   28u  IPv6 1373854      0t0  TCP b2412b48cfa2:http-alt->172.28.0.1:51090 (ESTABLISHED)\n",
            "\n",
            "\n",
            "=== LOGS ===\n",
            "\n",
            "--- /tmp/dashboard.log ---\n",
            "\n",
            "--- /tmp/mcp_gateway.log ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "b927a8c7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b927a8c7",
        "outputId": "4753d152-8811-4c78-c6f3-58b494e2fe24"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "PHASE 6: SMOKE TEST\n",
            "============================================================\n",
            "  [PASS] Orchestrator (200)\n",
            "  [PASS] MCP Gateway (200)\n",
            "  [PASS] Code Exec (200)\n",
            "\n",
            "  Testing AI Inference... OK (54.4s)\n",
            "\n",
            "  âœ… ALL SYSTEMS GO!\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
        "# â•‘  PHASE 6: Quick Smoke Test                                  â•‘\n",
        "# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "import json, urllib.request, time\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"PHASE 6: SMOKE TEST\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Verify Health\n",
        "checks = [\n",
        "    (\"Orchestrator\", \"http://localhost:8000/health\"),\n",
        "    (\"MCP Gateway\",  \"http://localhost:8082/health\"),\n",
        "    (\"Code Exec\",    \"http://localhost:8004/health\")\n",
        "]\n",
        "for name, url in checks:\n",
        "    try:\n",
        "        code = urllib.request.urlopen(url, timeout=5).getcode()\n",
        "        print(f\"  [PASS] {name} ({code})\")\n",
        "    except Exception as e:\n",
        "        print(f\"  [WARN] {name} ({e})\")\n",
        "\n",
        "# Verify Inference\n",
        "print(\"\\n  Testing AI Inference...\", end=\" \", flush=True)\n",
        "try:\n",
        "    t0 = time.time()\n",
        "    data = json.dumps({\"model\": \"deepseek-r1:14b\", \"prompt\": \"Hello!\", \"stream\": False}).encode()\n",
        "    req = urllib.request.Request(\"http://localhost:11434/api/generate\", data=data, headers={\"Content-Type\": \"application/json\"})\n",
        "    urllib.request.urlopen(req, timeout=120)\n",
        "    print(f\"OK ({time.time()-t0:.1f}s)\")\n",
        "    print(\"\\n  âœ… ALL SYSTEMS GO!\")\n",
        "except Exception as e:\n",
        "    print(f\"FAIL ({e})\")\n",
        "print(\"=\" * 60)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bc99dfa4",
        "outputId": "3122fbe2-ac14-4941-c871-1e092a62ff04"
      },
      "source": [
        "import subprocess\n",
        "\n",
        "print(\"=== CHECKING SERVICE LOGS FOR ERRORS ===\")\n",
        "services = [\n",
        "    \"/tmp/orchestrator.log\",\n",
        "    \"/tmp/memory_service.log\",\n",
        "    \"/tmp/code_exec.log\",\n",
        "    \"/tmp/mcp_gateway.log\"\n",
        "]\n",
        "\n",
        "for log in services:\n",
        "    print(f\"\\n--- {log} ---\")\n",
        "    # Check if file exists first\n",
        "    try:\n",
        "        # Print last 30 lines of the log\n",
        "        result = subprocess.run([\"tail\", \"-n\", \"30\", log], capture_output=True, text=True)\n",
        "        print(result.stdout)\n",
        "        if result.stderr:\n",
        "            print(\"STDERR:\", result.stderr)\n",
        "    except Exception as e:\n",
        "        print(f\"Could not read log: {e}\")\n"
      ],
      "id": "bc99dfa4",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== CHECKING SERVICE LOGS FOR ERRORS ===\n",
            "\n",
            "--- /tmp/orchestrator.log ---\n",
            "INFO:     Started server process [36820]\n",
            "INFO:     Waiting for application startup.\n",
            "2026-02-08 04:26:56,070 - orchestrator.service.main - INFO - Starting Lead Agent/Orchestrator service...\n",
            "2026-02-08 04:26:56,076 - orchestrator.service.main - INFO - Configuration: LLM Provider=local\n",
            "2026-02-08 04:26:56,076 - orchestrator.service.main - INFO - MCP Gateway URL: http://localhost:8082\n",
            "2026-02-08 04:26:56,076 - orchestrator.service.main - INFO - Memory Service URL: http://localhost:8002\n",
            "2026-02-08 04:26:56,319 - orchestrator.service.main - INFO - WebSocket manager initialized\n",
            "2026-02-08 04:26:56,323 - orchestrator.service.session_storage - INFO - Connected to Redis at redis://localhost:6379/0\n",
            "2026-02-08 04:26:56,324 - orchestrator.service.agent - INFO - Session storage initialized\n",
            "2026-02-08 04:26:56,324 - orchestrator.service.memory_learning - INFO - MemoryLearningClient initialized: memory_dir=/content/ai_final/agentic-framework-main/workspace/.copilot/memory\n",
            "2026-02-08 04:26:56,324 - orchestrator.service.agent_manager - INFO - Memory learning client initialized\n",
            "2026-02-08 04:26:56,324 - orchestrator.service.agent_manager - INFO - Agent manager started\n",
            "2026-02-08 04:26:56,324 - orchestrator.service.agent - INFO - Agent manager initialized\n",
            "2026-02-08 04:26:56,324 - orchestrator.service.agent - INFO - OrchestratorAgent fully initialized\n",
            "2026-02-08 04:26:56,324 - orchestrator.service.main - INFO - Orchestrator agent initialized with persistent storage\n",
            "2026-02-08 04:26:56,324 - orchestrator.service.main - INFO - Orchestrator service started successfully\n",
            "INFO:     Application startup complete.\n",
            "INFO:     Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit)\n",
            "2026-02-08 04:27:20,207 - httpx - INFO - HTTP Request: GET http://localhost:8082/health \"HTTP/1.1 200 OK\"\n",
            "2026-02-08 04:27:20,210 - httpx - INFO - HTTP Request: GET http://localhost:8002/health \"HTTP/1.1 200 OK\"\n",
            "2026-02-08 04:27:20,213 - httpx - INFO - HTTP Request: GET http://localhost:8003/health \"HTTP/1.1 200 OK\"\n",
            "INFO:     127.0.0.1:48688 - \"GET /health HTTP/1.1\" 200 OK\n",
            "2026-02-08 04:27:22,836 - httpx - INFO - HTTP Request: GET http://localhost:8082/health \"HTTP/1.1 200 OK\"\n",
            "2026-02-08 04:27:22,839 - httpx - INFO - HTTP Request: GET http://localhost:8002/health \"HTTP/1.1 200 OK\"\n",
            "2026-02-08 04:27:22,843 - httpx - INFO - HTTP Request: GET http://localhost:8003/health \"HTTP/1.1 200 OK\"\n",
            "INFO:     127.0.0.1:48702 - \"GET /health HTTP/1.1\" 200 OK\n",
            "\n",
            "\n",
            "--- /tmp/memory_service.log ---\n",
            "INFO:httpx:HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/sentence_bert_config.json \"HTTP/1.1 307 Temporary Redirect\"\n",
            "INFO:httpx:HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/sentence_bert_config.json \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/adapter_config.json \"HTTP/1.1 404 Not Found\"\n",
            "INFO:httpx:HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/config.json \"HTTP/1.1 307 Temporary Redirect\"\n",
            "INFO:httpx:HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config.json \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/config.json \"HTTP/1.1 307 Temporary Redirect\"\n",
            "INFO:httpx:HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config.json \"HTTP/1.1 200 OK\"\n",
            "\n",
            "Loading weights:   0%|          | 0/103 [00:00<?, ?it/s]\n",
            "Loading weights:   1%|          | 1/103 [00:00<00:00, 29959.31it/s, Materializing param=embeddings.LayerNorm.bias]\n",
            "Loading weights:   1%|          | 1/103 [00:00<00:00, 6887.20it/s, Materializing param=embeddings.LayerNorm.bias] \n",
            "Loading weights:   2%|â–         | 2/103 [00:00<00:00, 5440.08it/s, Materializing param=embeddings.LayerNorm.weight]\n",
            "Loading weights:   2%|â–         | 2/103 [00:00<00:00, 4146.62it/s, Materializing param=embeddings.LayerNorm.weight]\n",
            "Loading weights:   3%|â–Ž         | 3/103 [00:00<00:00, 4482.69it/s, Materializing param=embeddings.position_embeddings.weight]\n",
            "Loading weights:   3%|â–Ž         | 3/103 [00:00<00:00, 3960.63it/s, Materializing param=embeddings.position_embeddings.weight]\n",
            "Loading weights:   4%|â–         | 4/103 [00:00<00:00, 4447.83it/s, Materializing param=embeddings.token_type_embeddings.weight]\n",
            "Loading weights:   4%|â–         | 4/103 [00:00<00:00, 4027.18it/s, Materializing param=embeddings.token_type_embeddings.weight]\n",
            "Loading weights:   5%|â–         | 5/103 [00:00<00:00, 4362.70it/s, Materializing param=embeddings.word_embeddings.weight]      \n",
            "Loading weights:   5%|â–         | 5/103 [00:00<00:00, 4068.19it/s, Materializing param=embeddings.word_embeddings.weight]\n",
            "Loading weights:   6%|â–Œ         | 6/103 [00:00<00:00, 4402.70it/s, Materializing param=encoder.layer.0.attention.output.LayerNorm.bias]\n",
            "Loading weights:   6%|â–Œ         | 6/103 [00:00<00:00, 4152.78it/s, Materializing param=encoder.layer.0.attention.output.LayerNorm.bias]\n",
            "Loading weights:   7%|â–‹         | 7/103 [00:00<00:00, 922.11it/s, Materializing param=encoder.layer.0.attention.output.LayerNorm.weight]\n",
            "Loading weights:   7%|â–‹         | 7/103 [00:00<00:00, 906.79it/s, Materializing param=encoder.layer.0.attention.output.LayerNorm.weight]\n",
            "Loading weights:   8%|â–Š         | 8/103 [00:00<00:00, 1014.68it/s, Materializing param=encoder.layer.0.attention.output.dense.bias]     \n",
            "Loading weights:   8%|â–Š         | 8/103 [00:00<00:00, 1001.62it/s, Materializing param=encoder.layer.0.attention.output.dense.bias]\n",
            "Loading weights:   9%|â–Š         | 9/103 [00:00<00:00, 1103.34it/s, Materializing param=encoder.layer.0.attention.output.dense.weight]\n",
            "Loading weights:   9%|â–Š         | 9/103 [00:00<00:00, 1092.14it/s, Materializing param=encoder.layer.0.attention.output.dense.weight]\n",
            "Loading weights:  10%|â–‰         | 10/103 [00:00<00:00, 1192.21it/s, Materializing param=encoder.layer.0.attention.self.key.bias]     \n",
            "Loading weights:  10%|â–‰         | 10/103 [00:00<00:00, 1178.84it/s, Materializing param=encoder.layer.0.attention.self.key.bias]\n",
            "Loading weights:  11%|â–ˆ         | 11/103 [00:00<00:00, 1272.75it/s, Materializing param=encoder.layer.0.attention.self.key.weight]\n",
            "Loading weights:  11%|â–ˆ         | 11/103 [00:00<00:00, 1261.00it/s, Materializing param=encoder.layer.0.attention.self.key.weight]\n",
            "Loading weights:  12%|â–ˆâ–        | 12/103 [00:00<00:00, 1353.77it/s, Materializing param=encoder.layer.0.attention.self.query.bias]\n",
            "Loading weights:  12%|â–ˆâ–        | 12/103 [00:00<00:00, 1341.93it/s, Materializing param=encoder.layer.0.attention.self.query.bias]\n",
            "Loading weights:  13%|â–ˆâ–Ž        | 13/103 [00:00<00:00, 1430.68it/s, Materializing param=encoder.layer.0.attention.self.query.weight]\n",
            "Loading weights:  13%|â–ˆâ–Ž        | 13/103 [00:00<00:00, 1416.88it/s, Materializing param=encoder.layer.0.attention.self.query.weight]\n",
            "Loading weights:  14%|â–ˆâ–Ž        | 14/103 [00:00<00:00, 1500.84it/s, Materializing param=encoder.layer.0.attention.self.value.bias]  \n",
            "Loading weights:  14%|â–ˆâ–Ž        | 14/103 [00:00<00:00, 1487.94it/s, Materializing param=encoder.layer.0.attention.self.value.bias]\n",
            "Loading weights:  15%|â–ˆâ–        | 15/103 [00:00<00:00, 986.46it/s, Materializing param=encoder.layer.0.attention.self.value.weight]\n",
            "Loading weights:  15%|â–ˆâ–        | 15/103 [00:00<00:00, 978.38it/s, Materializing param=encoder.layer.0.attention.self.value.weight]\n",
            "Loading weights:  16%|â–ˆâ–Œ        | 16/103 [00:00<00:00, 1029.91it/s, Materializing param=encoder.layer.0.intermediate.dense.bias]   \n",
            "Loading weights:  16%|â–ˆâ–Œ        | 16/103 [00:00<00:00, 1023.56it/s, Materializing param=encoder.layer.0.intermediate.dense.bias]\n",
            "Loading weights:  17%|â–ˆâ–‹        | 17/103 [00:00<00:00, 1076.97it/s, Materializing param=encoder.layer.0.intermediate.dense.weight]\n",
            "Loading weights:  17%|â–ˆâ–‹        | 17/103 [00:00<00:00, 1071.31it/s, Materializing param=encoder.layer.0.intermediate.dense.weight]\n",
            "Loading weights:  17%|â–ˆâ–‹        | 18/103 [00:00<00:00, 1123.99it/s, Materializing param=encoder.layer.0.output.LayerNorm.bias]    \n",
            "Loading weights:  17%|â–ˆâ–‹        | 18/103 [00:00<00:00, 1118.41it/s, Materializing param=encoder.layer.0.output.LayerNorm.bias]\n",
            "Loading weights:  18%|â–ˆâ–Š        | 19/103 [00:00<00:00, 1169.36it/s, Materializing param=encoder.layer.0.output.LayerNorm.weight]\n",
            "Loading weights:  18%|â–ˆâ–Š        | 19/103 [00:00<00:00, 1163.06it/s, Materializing param=encoder.layer.0.output.LayerNorm.weight]\n",
            "Loading weights:  19%|â–ˆâ–‰        | 20/103 [00:00<00:00, 906.02it/s, Materializing param=encoder.layer.0.output.dense.bias]       \n",
            "Loading weights:  19%|â–ˆâ–‰        | 20/103 [00:00<00:00, 900.59it/s, Materializing param=encoder.layer.0.output.dense.bias]\n",
            "Loading weights:  20%|â–ˆâ–ˆ        | 21/103 [00:00<00:00, 937.54it/s, Materializing param=encoder.layer.0.output.dense.weight]\n",
            "Loading weights:  20%|â–ˆâ–ˆ        | 21/103 [00:00<00:00, 932.35it/s, Materializing param=encoder.layer.0.output.dense.weight]\n",
            "Loading weights:  21%|â–ˆâ–ˆâ–       | 22/103 [00:00<00:00, 969.49it/s, Materializing param=encoder.layer.1.attention.output.LayerNorm.bias]\n",
            "Loading weights:  21%|â–ˆâ–ˆâ–       | 22/103 [00:00<00:00, 965.89it/s, Materializing param=encoder.layer.1.attention.output.LayerNorm.bias]\n",
            "Loading weights:  22%|â–ˆâ–ˆâ–       | 23/103 [00:00<00:00, 1003.09it/s, Materializing param=encoder.layer.1.attention.output.LayerNorm.weight]\n",
            "Loading weights:  22%|â–ˆâ–ˆâ–       | 23/103 [00:00<00:00, 999.42it/s, Materializing param=encoder.layer.1.attention.output.LayerNorm.weight] \n",
            "Loading weights:  23%|â–ˆâ–ˆâ–Ž       | 24/103 [00:00<00:00, 1036.00it/s, Materializing param=encoder.layer.1.attention.output.dense.bias]     \n",
            "Loading weights:  23%|â–ˆâ–ˆâ–Ž       | 24/103 [00:00<00:00, 1032.34it/s, Materializing param=encoder.layer.1.attention.output.dense.bias]\n",
            "Loading weights:  24%|â–ˆâ–ˆâ–       | 25/103 [00:00<00:00, 1068.87it/s, Materializing param=encoder.layer.1.attention.output.dense.weight]\n",
            "Loading weights:  24%|â–ˆâ–ˆâ–       | 25/103 [00:00<00:00, 1063.89it/s, Materializing param=encoder.layer.1.attention.output.dense.weight]\n",
            "Loading weights:  25%|â–ˆâ–ˆâ–Œ       | 26/103 [00:00<00:00, 866.72it/s, Materializing param=encoder.layer.1.attention.self.key.bias]       \n",
            "Loading weights:  25%|â–ˆâ–ˆâ–Œ       | 26/103 [00:00<00:00, 863.18it/s, Materializing param=encoder.layer.1.attention.self.key.bias]\n",
            "Loading weights:  26%|â–ˆâ–ˆâ–Œ       | 27/103 [00:00<00:00, 890.99it/s, Materializing param=encoder.layer.1.attention.self.key.weight]\n",
            "Loading weights:  26%|â–ˆâ–ˆâ–Œ       | 27/103 [00:00<00:00, 888.49it/s, Materializing param=encoder.layer.1.attention.self.key.weight]\n",
            "Loading weights:  27%|â–ˆâ–ˆâ–‹       | 28/103 [00:00<00:00, 915.78it/s, Materializing param=encoder.layer.1.attention.self.query.bias]\n",
            "Loading weights:  27%|â–ˆâ–ˆâ–‹       | 28/103 [00:00<00:00, 913.07it/s, Materializing param=encoder.layer.1.attention.self.query.bias]\n",
            "Loading weights:  28%|â–ˆâ–ˆâ–Š       | 29/103 [00:00<00:00, 940.85it/s, Materializing param=encoder.layer.1.attention.self.query.weight]\n",
            "Loading weights:  28%|â–ˆâ–ˆâ–Š       | 29/103 [00:00<00:00, 938.31it/s, Materializing param=encoder.layer.1.attention.self.query.weight]\n",
            "Loading weights:  29%|â–ˆâ–ˆâ–‰       | 30/103 [00:00<00:00, 966.08it/s, Materializing param=encoder.layer.1.attention.self.value.bias]  \n",
            "Loading weights:  29%|â–ˆâ–ˆâ–‰       | 30/103 [00:00<00:00, 963.69it/s, Materializing param=encoder.layer.1.attention.self.value.bias]\n",
            "Loading weights:  30%|â–ˆâ–ˆâ–ˆ       | 31/103 [00:00<00:00, 991.09it/s, Materializing param=encoder.layer.1.attention.self.value.weight]\n",
            "Loading weights:  30%|â–ˆâ–ˆâ–ˆ       | 31/103 [00:00<00:00, 988.64it/s, Materializing param=encoder.layer.1.attention.self.value.weight]\n",
            "Loading weights:  31%|â–ˆâ–ˆâ–ˆ       | 32/103 [00:00<00:00, 832.39it/s, Materializing param=encoder.layer.1.intermediate.dense.bias]    \n",
            "Loading weights:  31%|â–ˆâ–ˆâ–ˆ       | 32/103 [00:00<00:00, 829.40it/s, Materializing param=encoder.layer.1.intermediate.dense.bias]\n",
            "Loading weights:  32%|â–ˆâ–ˆâ–ˆâ–      | 33/103 [00:00<00:00, 851.30it/s, Materializing param=encoder.layer.1.intermediate.dense.weight]\n",
            "Loading weights:  32%|â–ˆâ–ˆâ–ˆâ–      | 33/103 [00:00<00:00, 849.40it/s, Materializing param=encoder.layer.1.intermediate.dense.weight]\n",
            "Loading weights:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 34/103 [00:00<00:00, 871.79it/s, Materializing param=encoder.layer.1.output.LayerNorm.bias]    \n",
            "Loading weights:  33%|â–ˆâ–ˆâ–ˆâ–Ž      | 34/103 [00:00<00:00, 869.53it/s, Materializing param=encoder.layer.1.output.LayerNorm.bias]\n",
            "Loading weights:  34%|â–ˆâ–ˆâ–ˆâ–      | 35/103 [00:00<00:00, 891.39it/s, Materializing param=encoder.layer.1.output.LayerNorm.weight]\n",
            "Loading weights:  34%|â–ˆâ–ˆâ–ˆâ–      | 35/103 [00:00<00:00, 889.58it/s, Materializing param=encoder.layer.1.output.LayerNorm.weight]\n",
            "Loading weights:  35%|â–ˆâ–ˆâ–ˆâ–      | 36/103 [00:00<00:00, 911.45it/s, Materializing param=encoder.layer.1.output.dense.bias]      \n",
            "Loading weights:  35%|â–ˆâ–ˆâ–ˆâ–      | 36/103 [00:00<00:00, 909.47it/s, Materializing param=encoder.layer.1.output.dense.bias]\n",
            "Loading weights:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 37/103 [00:00<00:00, 931.39it/s, Materializing param=encoder.layer.1.output.dense.weight]\n",
            "Loading weights:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 37/103 [00:00<00:00, 929.61it/s, Materializing param=encoder.layer.1.output.dense.weight]\n",
            "Loading weights:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 38/103 [00:00<00:00, 951.50it/s, Materializing param=encoder.layer.2.attention.output.LayerNorm.bias]\n",
            "Loading weights:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 38/103 [00:00<00:00, 949.59it/s, Materializing param=encoder.layer.2.attention.output.LayerNorm.bias]\n",
            "Loading weights:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 39/103 [00:00<00:00, 833.77it/s, Materializing param=encoder.layer.2.attention.output.LayerNorm.weight]\n",
            "Loading weights:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 39/103 [00:00<00:00, 831.41it/s, Materializing param=encoder.layer.2.attention.output.LayerNorm.weight]\n",
            "Loading weights:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 40/103 [00:00<00:00, 849.55it/s, Materializing param=encoder.layer.2.attention.output.dense.bias]      \n",
            "Loading weights:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 40/103 [00:00<00:00, 847.82it/s, Materializing param=encoder.layer.2.attention.output.dense.bias]\n",
            "Loading weights:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 41/103 [00:00<00:00, 866.24it/s, Materializing param=encoder.layer.2.attention.output.dense.weight]\n",
            "Loading weights:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 41/103 [00:00<00:00, 864.54it/s, Materializing param=encoder.layer.2.attention.output.dense.weight]\n",
            "Loading weights:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 42/103 [00:00<00:00, 882.31it/s, Materializing param=encoder.layer.2.attention.self.key.bias]      \n",
            "Loading weights:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 42/103 [00:00<00:00, 880.80it/s, Materializing param=encoder.layer.2.attention.self.key.bias]\n",
            "Loading weights:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/103 [00:00<00:00, 899.08it/s, Materializing param=encoder.layer.2.attention.self.key.weight]\n",
            "Loading weights:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 43/103 [00:00<00:00, 897.61it/s, Materializing param=encoder.layer.2.attention.self.key.weight]\n",
            "Loading weights:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 44/103 [00:00<00:00, 915.63it/s, Materializing param=encoder.layer.2.attention.self.query.bias]\n",
            "Loading weights:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 44/103 [00:00<00:00, 914.16it/s, Materializing param=encoder.layer.2.attention.self.query.bias]\n",
            "Loading weights:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 45/103 [00:00<00:00, 829.77it/s, Materializing param=encoder.layer.2.attention.self.query.weight]\n",
            "Loading weights:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 45/103 [00:00<00:00, 827.84it/s, Materializing param=encoder.layer.2.attention.self.query.weight]\n",
            "Loading weights:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 46/103 [00:00<00:00, 843.30it/s, Materializing param=encoder.layer.2.attention.self.value.bias]  \n",
            "Loading weights:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 46/103 [00:00<00:00, 841.85it/s, Materializing param=encoder.layer.2.attention.self.value.bias]\n",
            "Loading weights:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 47/103 [00:00<00:00, 857.57it/s, Materializing param=encoder.layer.2.attention.self.value.weight]\n",
            "Loading weights:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 47/103 [00:00<00:00, 856.30it/s, Materializing param=encoder.layer.2.attention.self.value.weight]\n",
            "Loading weights:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 48/103 [00:00<00:00, 872.20it/s, Materializing param=encoder.layer.2.intermediate.dense.bias]    \n",
            "Loading weights:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 48/103 [00:00<00:00, 870.94it/s, Materializing param=encoder.layer.2.intermediate.dense.bias]\n",
            "Loading weights:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 49/103 [00:00<00:00, 789.30it/s, Materializing param=encoder.layer.2.intermediate.dense.weight]\n",
            "Loading weights:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 49/103 [00:00<00:00, 787.57it/s, Materializing param=encoder.layer.2.intermediate.dense.weight]\n",
            "Loading weights:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 50/103 [00:00<00:00, 801.32it/s, Materializing param=encoder.layer.2.output.LayerNorm.bias]    \n",
            "Loading weights:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 50/103 [00:00<00:00, 799.66it/s, Materializing param=encoder.layer.2.output.LayerNorm.bias]\n",
            "Loading weights:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 51/103 [00:00<00:00, 813.18it/s, Materializing param=encoder.layer.2.output.LayerNorm.weight]\n",
            "Loading weights:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 51/103 [00:00<00:00, 811.99it/s, Materializing param=encoder.layer.2.output.LayerNorm.weight]\n",
            "Loading weights:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 52/103 [00:00<00:00, 825.72it/s, Materializing param=encoder.layer.2.output.dense.bias]      \n",
            "Loading weights:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 52/103 [00:00<00:00, 824.55it/s, Materializing param=encoder.layer.2.output.dense.bias]\n",
            "Loading weights:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 53/103 [00:00<00:00, 838.14it/s, Materializing param=encoder.layer.2.output.dense.weight]\n",
            "Loading weights:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 53/103 [00:00<00:00, 836.95it/s, Materializing param=encoder.layer.2.output.dense.weight]\n",
            "Loading weights:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 54/103 [00:00<00:00, 766.51it/s, Materializing param=encoder.layer.3.attention.output.LayerNorm.bias]\n",
            "Loading weights:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 54/103 [00:00<00:00, 764.59it/s, Materializing param=encoder.layer.3.attention.output.LayerNorm.bias]\n",
            "Loading weights:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 55/103 [00:00<00:00, 775.79it/s, Materializing param=encoder.layer.3.attention.output.LayerNorm.weight]\n",
            "Loading weights:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 55/103 [00:00<00:00, 774.55it/s, Materializing param=encoder.layer.3.attention.output.LayerNorm.weight]\n",
            "Loading weights:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 56/103 [00:00<00:00, 786.20it/s, Materializing param=encoder.layer.3.attention.output.dense.bias]      \n",
            "Loading weights:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 56/103 [00:00<00:00, 785.03it/s, Materializing param=encoder.layer.3.attention.output.dense.bias]\n",
            "Loading weights:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 57/103 [00:00<00:00, 736.84it/s, Materializing param=encoder.layer.3.attention.output.dense.weight]\n",
            "Loading weights:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 57/103 [00:00<00:00, 735.40it/s, Materializing param=encoder.layer.3.attention.output.dense.weight]\n",
            "Loading weights:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 58/103 [00:00<00:00, 746.37it/s, Materializing param=encoder.layer.3.attention.self.key.bias]      \n",
            "Loading weights:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 58/103 [00:00<00:00, 745.53it/s, Materializing param=encoder.layer.3.attention.self.key.bias]\n",
            "Loading weights:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 59/103 [00:00<00:00, 756.86it/s, Materializing param=encoder.layer.3.attention.self.key.weight]\n",
            "Loading weights:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 59/103 [00:00<00:00, 756.06it/s, Materializing param=encoder.layer.3.attention.self.key.weight]\n",
            "Loading weights:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 60/103 [00:00<00:00, 767.20it/s, Materializing param=encoder.layer.3.attention.self.query.bias]\n",
            "Loading weights:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 60/103 [00:00<00:00, 766.37it/s, Materializing param=encoder.layer.3.attention.self.query.bias]\n",
            "Loading weights:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 61/103 [00:00<00:00, 777.71it/s, Materializing param=encoder.layer.3.attention.self.query.weight]\n",
            "Loading weights:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 61/103 [00:00<00:00, 714.87it/s, Materializing param=encoder.layer.3.attention.self.query.weight]\n",
            "Loading weights:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 62/103 [00:00<00:00, 724.30it/s, Materializing param=encoder.layer.3.attention.self.value.bias]  \n",
            "Loading weights:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 62/103 [00:00<00:00, 723.26it/s, Materializing param=encoder.layer.3.attention.self.value.bias]\n",
            "Loading weights:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 63/103 [00:00<00:00, 733.26it/s, Materializing param=encoder.layer.3.attention.self.value.weight]\n",
            "Loading weights:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 63/103 [00:00<00:00, 732.42it/s, Materializing param=encoder.layer.3.attention.self.value.weight]\n",
            "Loading weights:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 64/103 [00:00<00:00, 742.63it/s, Materializing param=encoder.layer.3.intermediate.dense.bias]    \n",
            "Loading weights:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 64/103 [00:00<00:00, 741.92it/s, Materializing param=encoder.layer.3.intermediate.dense.bias]\n",
            "Loading weights:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 65/103 [00:00<00:00, 752.27it/s, Materializing param=encoder.layer.3.intermediate.dense.weight]\n",
            "Loading weights:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 65/103 [00:00<00:00, 751.27it/s, Materializing param=encoder.layer.3.intermediate.dense.weight]\n",
            "Loading weights:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 66/103 [00:00<00:00, 761.47it/s, Materializing param=encoder.layer.3.output.LayerNorm.bias]    \n",
            "Loading weights:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 66/103 [00:00<00:00, 760.78it/s, Materializing param=encoder.layer.3.output.LayerNorm.bias]\n",
            "Loading weights:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 67/103 [00:00<00:00, 771.08it/s, Materializing param=encoder.layer.3.output.LayerNorm.weight]\n",
            "Loading weights:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 67/103 [00:00<00:00, 770.37it/s, Materializing param=encoder.layer.3.output.LayerNorm.weight]\n",
            "Loading weights:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 68/103 [00:00<00:00, 780.68it/s, Materializing param=encoder.layer.3.output.dense.bias]      \n",
            "Loading weights:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 68/103 [00:00<00:00, 779.93it/s, Materializing param=encoder.layer.3.output.dense.bias]\n",
            "Loading weights:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 69/103 [00:00<00:00, 790.17it/s, Materializing param=encoder.layer.3.output.dense.weight]\n",
            "Loading weights:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 69/103 [00:00<00:00, 789.49it/s, Materializing param=encoder.layer.3.output.dense.weight]\n",
            "Loading weights:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 70/103 [00:00<00:00, 744.98it/s, Materializing param=encoder.layer.4.attention.output.LayerNorm.bias]\n",
            "Loading weights:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 70/103 [00:00<00:00, 744.01it/s, Materializing param=encoder.layer.4.attention.output.LayerNorm.bias]\n",
            "Loading weights:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 71/103 [00:00<00:00, 753.14it/s, Materializing param=encoder.layer.4.attention.output.LayerNorm.weight]\n",
            "Loading weights:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 71/103 [00:00<00:00, 752.36it/s, Materializing param=encoder.layer.4.attention.output.LayerNorm.weight]\n",
            "Loading weights:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 72/103 [00:00<00:00, 761.29it/s, Materializing param=encoder.layer.4.attention.output.dense.bias]      \n",
            "Loading weights:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 72/103 [00:00<00:00, 760.54it/s, Materializing param=encoder.layer.4.attention.output.dense.bias]\n",
            "Loading weights:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 73/103 [00:00<00:00, 769.85it/s, Materializing param=encoder.layer.4.attention.output.dense.weight]\n",
            "Loading weights:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 73/103 [00:00<00:00, 769.16it/s, Materializing param=encoder.layer.4.attention.output.dense.weight]\n",
            "Loading weights:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 74/103 [00:00<00:00, 778.38it/s, Materializing param=encoder.layer.4.attention.self.key.bias]      \n",
            "Loading weights:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 74/103 [00:00<00:00, 777.64it/s, Materializing param=encoder.layer.4.attention.self.key.bias]\n",
            "Loading weights:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 75/103 [00:00<00:00, 786.95it/s, Materializing param=encoder.layer.4.attention.self.key.weight]\n",
            "Loading weights:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 75/103 [00:00<00:00, 786.33it/s, Materializing param=encoder.layer.4.attention.self.key.weight]\n",
            "Loading weights:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 76/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.4.attention.self.key.weight]\n",
            "Loading weights:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 76/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.4.attention.self.query.bias]\n",
            "Loading weights:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 76/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.4.attention.self.query.bias]\n",
            "Loading weights:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 77/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.4.attention.self.query.weight]\n",
            "Loading weights:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 77/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.4.attention.self.query.weight]\n",
            "Loading weights:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 78/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.4.attention.self.value.bias]  \n",
            "Loading weights:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 78/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.4.attention.self.value.bias]\n",
            "Loading weights:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 79/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.4.attention.self.value.weight]\n",
            "Loading weights:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 79/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.4.attention.self.value.weight]\n",
            "Loading weights:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 80/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.4.intermediate.dense.bias]    \n",
            "Loading weights:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 80/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.4.intermediate.dense.bias]\n",
            "Loading weights:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 81/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.4.intermediate.dense.weight]\n",
            "Loading weights:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 81/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.4.intermediate.dense.weight]\n",
            "Loading weights:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 82/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.4.output.LayerNorm.bias]    \n",
            "Loading weights:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 82/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.4.output.LayerNorm.bias]\n",
            "Loading weights:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 83/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.4.output.LayerNorm.weight]\n",
            "Loading weights:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 83/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.4.output.LayerNorm.weight]\n",
            "Loading weights:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 84/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.4.output.dense.bias]      \n",
            "Loading weights:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 84/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.4.output.dense.bias]\n",
            "Loading weights:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 85/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.4.output.dense.weight]\n",
            "Loading weights:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 85/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.4.output.dense.weight]\n",
            "Loading weights:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 86/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.5.attention.output.LayerNorm.bias]\n",
            "Loading weights:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 86/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.5.attention.output.LayerNorm.bias]\n",
            "Loading weights:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 87/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.5.attention.output.LayerNorm.weight]\n",
            "Loading weights:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 87/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.5.attention.output.LayerNorm.weight]\n",
            "Loading weights:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 88/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.5.attention.output.dense.bias]      \n",
            "Loading weights:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 88/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.5.attention.output.dense.bias]\n",
            "Loading weights:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 89/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.5.attention.output.dense.weight]\n",
            "Loading weights:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 89/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.5.attention.output.dense.weight]\n",
            "Loading weights:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 90/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.5.attention.self.key.bias]      \n",
            "Loading weights:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 90/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.5.attention.self.key.bias]\n",
            "Loading weights:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 91/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.5.attention.self.key.weight]\n",
            "Loading weights:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 91/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.5.attention.self.key.weight]\n",
            "Loading weights:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 92/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.5.attention.self.query.bias]\n",
            "Loading weights:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 92/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.5.attention.self.query.bias]\n",
            "Loading weights:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 93/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.5.attention.self.query.weight]\n",
            "Loading weights:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 93/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.5.attention.self.query.weight]\n",
            "Loading weights:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 94/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.5.attention.self.value.bias]  \n",
            "Loading weights:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 94/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.5.attention.self.value.bias]\n",
            "Loading weights:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 95/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.5.attention.self.value.weight]\n",
            "Loading weights:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 95/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.5.attention.self.value.weight]\n",
            "Loading weights:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 96/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.5.intermediate.dense.bias]    \n",
            "Loading weights:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 96/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.5.intermediate.dense.bias]\n",
            "Loading weights:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 97/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.5.intermediate.dense.weight]\n",
            "Loading weights:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 97/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.5.intermediate.dense.weight]\n",
            "Loading weights:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 98/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.5.output.LayerNorm.bias]    \n",
            "Loading weights:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 98/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.5.output.LayerNorm.bias]\n",
            "Loading weights:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 99/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.5.output.LayerNorm.weight]\n",
            "Loading weights:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 99/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.5.output.LayerNorm.weight]\n",
            "Loading weights:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 100/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.5.output.dense.bias]     \n",
            "Loading weights:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 100/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.5.output.dense.bias]\n",
            "Loading weights:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 101/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.5.output.dense.weight]\n",
            "Loading weights:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 101/103 [00:00<00:00, 748.11it/s, Materializing param=encoder.layer.5.output.dense.weight]\n",
            "Loading weights:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 102/103 [00:00<00:00, 748.11it/s, Materializing param=pooler.dense.bias]                  \n",
            "Loading weights:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 102/103 [00:00<00:00, 748.11it/s, Materializing param=pooler.dense.bias]\n",
            "Loading weights: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 103/103 [00:00<00:00, 748.11it/s, Materializing param=pooler.dense.weight]\n",
            "Loading weights: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 103/103 [00:00<00:00, 748.11it/s, Materializing param=pooler.dense.weight]\n",
            "Loading weights: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 103/103 [00:00<00:00, 782.15it/s, Materializing param=pooler.dense.weight]\n",
            "BertModel LOAD REPORT from: sentence-transformers/all-MiniLM-L6-v2\n",
            "Key                     | Status     |  | \n",
            "------------------------+------------+--+-\n",
            "embeddings.position_ids | UNEXPECTED |  | \n",
            "\n",
            "Notes:\n",
            "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n",
            "INFO:httpx:HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/config.json \"HTTP/1.1 307 Temporary Redirect\"\n",
            "INFO:httpx:HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/config.json \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/tokenizer_config.json \"HTTP/1.1 307 Temporary Redirect\"\n",
            "INFO:httpx:HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/tokenizer_config.json \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: GET https://huggingface.co/api/models/sentence-transformers/all-MiniLM-L6-v2/tree/main/additional_chat_templates?recursive=false&expand=false \"HTTP/1.1 404 Not Found\"\n",
            "INFO:httpx:HTTP Request: GET https://huggingface.co/api/models/sentence-transformers/all-MiniLM-L6-v2/tree/main?recursive=true&expand=false \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: HEAD https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2/resolve/main/1_Pooling/config.json \"HTTP/1.1 307 Temporary Redirect\"\n",
            "INFO:httpx:HTTP Request: HEAD https://huggingface.co/api/resolve-cache/models/sentence-transformers/all-MiniLM-L6-v2/c9745ed1d9f207416be6d2e6f8de32d1f16199bf/1_Pooling%2Fconfig.json \"HTTP/1.1 200 OK\"\n",
            "INFO:httpx:HTTP Request: GET https://huggingface.co/api/models/sentence-transformers/all-MiniLM-L6-v2 \"HTTP/1.1 200 OK\"\n",
            "INFO:     Application startup complete.\n",
            "INFO:     Uvicorn running on http://0.0.0.0:8002 (Press CTRL+C to quit)\n",
            "Memory service started on 0.0.0.0:8001\n",
            "INFO:     127.0.0.1:53380 - \"GET /health HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:53382 - \"GET /health HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:53384 - \"GET /health HTTP/1.1\" 200 OK\n",
            "\n",
            "\n",
            "--- /tmp/code_exec.log ---\n",
            "INFO:     Started server process [36793]\n",
            "INFO:     Waiting for application startup.\n",
            "2026-02-08 04:26:51,538 - code_exec.service.main - INFO - Starting Code Executor Service\n",
            "2026-02-08 04:26:51,538 - code_exec.service.main - INFO - Skills directory: /Users/paragpradhan/Projects/Agent framework/agent-framework/code-exec/skills\n",
            "2026-02-08 04:26:51,543 - code_exec.service.registry - INFO - Loading skills from: /Users/paragpradhan/Projects/Agent framework/agent-framework/code-exec/skills\n",
            "2026-02-08 04:26:51,544 - code_exec.service.registry - INFO - Loaded 0 skills successfully\n",
            "2026-02-08 04:26:51,544 - code_exec.service.main - INFO - Loaded 0 skills\n",
            "2026-02-08 04:26:51,544 - code_exec.service.main - INFO - Service ready on 0.0.0.0:8002\n",
            "INFO:     Application startup complete.\n",
            "INFO:     Uvicorn running on http://0.0.0.0:8004 (Press CTRL+C to quit)\n",
            "INFO:     127.0.0.1:55428 - \"GET /health HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:55440 - \"GET /health HTTP/1.1\" 200 OK\n",
            "\n",
            "\n",
            "--- /tmp/mcp_gateway.log ---\n",
            "/content/ai_final/agentic-framework-main/mcp_gateway/service/models.py:209: UserWarning: Field name \"schema\" in \"ToolSchemaResponse\" shadows an attribute in parent \"BaseModel\"\n",
            "  class ToolSchemaResponse(BaseModel):\n",
            "INFO:     Started server process [36813]\n",
            "INFO:     Waiting for application startup.\n",
            "INFO:     Application startup complete.\n",
            "INFO:     Uvicorn running on http://0.0.0.0:8082 (Press CTRL+C to quit)\n",
            "Starting mcp-gateway v1.0.0\n",
            "Initialized sample tools in catalog\n",
            "INFO:     127.0.0.1:58622 - \"GET /health HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58630 - \"GET /health HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58638 - \"GET /health HTTP/1.1\" 200 OK\n",
            "INFO:     127.0.0.1:58648 - \"GET /health HTTP/1.1\" 200 OK\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "737c2ece",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "737c2ece",
        "outputId": "86c3e124-4083-42a6-da8d-83bdb45531c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============================================================\n",
            "KEEP-ALIVE WATCHDOG STARTED\n",
            "  Monitoring services... Stop with Ctrl+M I\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:pyngrok.process.ngrok:t=2026-02-08T04:29:52+0000 lvl=warn msg=\"failed to open private leg\" id=c144c49e8c42 privaddr=localhost:3000 err=\"dial tcp [::1]:3000: connect: connection refused\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  [04:32] System OK\n"
          ]
        }
      ],
      "source": [
        "# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
        "# â•‘  PHASE 7: Keep-Alive (prevents Colab from disconnecting)    â•‘\n",
        "# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
        "import subprocess, os, sys, time, urllib.request, datetime\n",
        "\n",
        "FRAMEWORK_DIR = \"/content/ai_final/agentic-framework-main\"\n",
        "\n",
        "service_defs = [\n",
        "    {\"name\": \"MCP Gateway\",      \"module\": \"mcp_gateway.service.main:app\",      \"port\": 8082, \"log\": \"/tmp/mcp_gateway.log\",      \"env\": {\"REDIS_URL\": \"redis://localhost:6379/3\"}},\n",
        "    {\"name\": \"Memory Service\",   \"module\": \"memory_service.service.main:app\",   \"port\": 8002, \"log\": \"/tmp/memory_service.log\",   \"env\": {\"REDIS_URL\": \"redis://localhost:6379/2\"}},\n",
        "    {\"name\": \"SubAgent Manager\", \"module\": \"subagent_manager.service.main:app\", \"port\": 8003, \"log\": \"/tmp/subagent_manager.log\", \"env\": {\"REDIS_URL\": \"redis://localhost:6379/1\"}},\n",
        "    {\"name\": \"Code Executor\",    \"module\": \"code_exec.service.main:app\",        \"port\": 8004, \"log\": \"/tmp/code_exec.log\",        \"env\": {\"REDIS_URL\": \"redis://localhost:6379/4\"}},\n",
        "    {\"name\": \"Orchestrator\",     \"module\": \"orchestrator.service.main:app\",     \"port\": 8000, \"log\": \"/tmp/orchestrator.log\",     \"env\": {}},\n",
        "]\n",
        "\n",
        "def is_alive(port):\n",
        "    try:\n",
        "        url = f\"http://localhost:{port}/health\" if port != 11434 else f\"http://localhost:{port}/api/tags\"\n",
        "        urllib.request.urlopen(url, timeout=5)\n",
        "        return True\n",
        "    except: return False\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"KEEP-ALIVE WATCHDOG STARTED\")\n",
        "print(\"  Monitoring services... Stop with Ctrl+M I\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "cycle = 0\n",
        "while True:\n",
        "    cycle += 1\n",
        "    restarts = 0\n",
        "    for svc in service_defs:\n",
        "        if not is_alive(svc[\"port\"]):\n",
        "            print(f\"  Restarting {svc['name']}...\", end=\" \", flush=True)\n",
        "            # Special env handling for Code Executor\n",
        "            svc_env = {**os.environ}\n",
        "            if svc['name'] == \"Code Executor\":\n",
        "                svc_env[\"CODE_EXECUTION_MODE\"] = \"local\"\n",
        "                # Remove potential conflict keys\n",
        "                for k in ['MINIO_ENDPOINT', 'MINIO_SECRET_KEY', 'JWT_SECRET_KEY']:\n",
        "                    if k in svc_env: del svc_env[k]\n",
        "            else:\n",
        "                svc_env.update(svc['env'])\n",
        "\n",
        "            subprocess.Popen([sys.executable, \"-m\", \"uvicorn\", svc[\"module\"], \"--host\", \"0.0.0.0\", \"--port\", str(svc[\"port\"])],\n",
        "                             cwd=FRAMEWORK_DIR, stdout=open(svc[\"log\"], \"a\"), stderr=subprocess.STDOUT, env=svc_env)\n",
        "            print(\"OK\")\n",
        "            restarts += 1\n",
        "\n",
        "    if cycle % 5 == 0:\n",
        "        print(f\"  [{datetime.datetime.now().strftime('%H:%M')}] System OK\")\n",
        "    time.sleep(60)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e199e12f"
      },
      "source": [
        "import subprocess\n",
        "\n",
        "logs = [\"/tmp/minio.log\", \"/tmp/code_exec.log\", \"/tmp/mcp_gateway.log\"]\n",
        "\n",
        "print(\"=== SERVICE LOGS ===\")\n",
        "for log in logs:\n",
        "    print(f\"\\n--- {log} ---\")\n",
        "    try:\n",
        "        # Check if file exists and has content\n",
        "        if os.path.exists(log):\n",
        "            with open(log, 'r') as f:\n",
        "                content = f.read().strip()\n",
        "                if content:\n",
        "                    print(content[-2000:]) # Print last 2000 chars\n",
        "                else:\n",
        "                    print(\"(Empty file)\")\n",
        "        else:\n",
        "            print(\"(File not found)\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error reading {log}: {e}\")"
      ],
      "id": "e199e12f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1799502a"
      },
      "source": [
        "# â”€â”€ Repair & Restart Services â”€â”€\n",
        "import subprocess, time, sys, os, urllib.request\n",
        "\n",
        "# Detect correct framework directory\n",
        "POSSIBLE_DIRS = [\n",
        "    \"/content/ai_final/agentic-framework-main\",\n",
        "    \"/content/ai_final\"\n",
        "]\n",
        "FRAMEWORK_DIR = \"/content/ai_final\"\n",
        "for d in POSSIBLE_DIRS:\n",
        "    if os.path.exists(d) and os.path.exists(os.path.join(d, \"orchestrator\")):\n",
        "        FRAMEWORK_DIR = d\n",
        "        break\n",
        "\n",
        "print(f\"Using Framework Directory: {FRAMEWORK_DIR}\")\n",
        "\n",
        "services = [\n",
        "    {\"name\": \"Code Executor\",    \"module\": \"code_exec.service.main:app\",        \"port\": 8004, \"log\": \"/tmp/code_exec.log\",        \"env\": {\"REDIS_URL\": \"redis://localhost:6379/4\"}},\n",
        "    {\"name\": \"Memory Service\",   \"module\": \"memory_service.service.main:app\",   \"port\": 8002, \"log\": \"/tmp/memory_service.log\",   \"env\": {\"REDIS_URL\": \"redis://localhost:6379/2\"}},\n",
        "    {\"name\": \"SubAgent Manager\", \"module\": \"subagent_manager.service.main:app\", \"port\": 8003, \"log\": \"/tmp/subagent_manager.log\", \"env\": {\"REDIS_URL\": \"redis://localhost:6379/1\"}},\n",
        "    {\"name\": \"MCP Gateway\",      \"module\": \"mcp_gateway.service.main:app\",      \"port\": 8080, \"log\": \"/tmp/mcp_gateway.log\",      \"env\": {\"REDIS_URL\": \"redis://localhost:6379/3\"}},\n",
        "    {\"name\": \"Orchestrator\",     \"module\": \"orchestrator.service.main:app\",     \"port\": 8000, \"log\": \"/tmp/orchestrator.log\",     \"env\": {}},\n",
        "]\n",
        "\n",
        "def check_port(port):\n",
        "    try:\n",
        "        urllib.request.urlopen(f\"http://localhost:{port}/health\", timeout=2)\n",
        "        return True\n",
        "    except:\n",
        "        return False\n",
        "\n",
        "print(\"Stopping any stuck services...\")\n",
        "subprocess.run([\"pkill\", \"-f\", \"uvicorn\"])\n",
        "time.sleep(2)\n",
        "\n",
        "print(\"Restarting services with log inspection...\")\n",
        "service_env = {**os.environ, \"PYTHONPATH\": FRAMEWORK_DIR}\n",
        "\n",
        "for svc in services:\n",
        "    print(f\"Starting {svc['name']} (:{svc['port']})...\", end=\" \", flush=True)\n",
        "    svc_env = {**service_env, **svc[\"env\"]}\n",
        "\n",
        "    # Start process\n",
        "    subprocess.Popen(\n",
        "        [sys.executable, \"-m\", \"uvicorn\", svc[\"module\"],\n",
        "         \"--host\", \"0.0.0.0\", \"--port\", str(svc[\"port\"])],\n",
        "        cwd=FRAMEWORK_DIR,\n",
        "        stdout=open(svc[\"log\"], \"w\"),\n",
        "        stderr=subprocess.STDOUT,\n",
        "        env=svc_env\n",
        "    )\n",
        "\n",
        "    # Wait and check\n",
        "    time.sleep(4)\n",
        "    if check_port(svc[\"port\"]):\n",
        "        print(\"OK\")\n",
        "    else:\n",
        "        # Check if process is even running\n",
        "        pid_check = subprocess.run([\"pgrep\", \"-f\", f\"port {svc['port']}\"], capture_output=True)\n",
        "        if pid_check.returncode == 0:\n",
        "             print(\"Running (but health check failed - still initializing?)\")\n",
        "        else:\n",
        "             print(\"FAIL (Crashed)\")\n",
        "             print(f\"--- Last 20 lines of {svc['log']} ---\")\n",
        "             if os.path.exists(svc[\"log\"]):\n",
        "                 subprocess.run([\"tail\", \"-n\", \"20\", svc[\"log\"]])\n",
        "             else:\n",
        "                 print(\"Log file not found.\")\n",
        "             print(\"------------------------------------\")\n",
        "\n",
        "print(\"\\nRepair complete. Try running Phase 6 (Smoke Test) again.\")"
      ],
      "id": "1799502a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "44117a36",
      "metadata": {
        "id": "44117a36"
      },
      "source": [
        "---\n",
        "## Utility Cells (run manually as needed)\n",
        "\n",
        "The cells below are optional â€” run them when you want to interact with the system."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4c8eb3bb",
      "metadata": {
        "id": "4c8eb3bb"
      },
      "outputs": [],
      "source": [
        "# â”€â”€ Send a task to the Orchestrator â”€â”€\n",
        "import json, urllib.request\n",
        "\n",
        "task = \"Write a Python function that calculates the Fibonacci sequence up to n terms, with proper error handling and type hints.\"\n",
        "\n",
        "print(f\"Task: {task}\\n\")\n",
        "data = json.dumps({\"message\": task, \"session_id\": \"colab-auto-001\"}).encode()\n",
        "req = urllib.request.Request(\n",
        "    \"http://localhost:8000/chat\",\n",
        "    data=data,\n",
        "    headers={\"Content-Type\": \"application/json\"}\n",
        ")\n",
        "try:\n",
        "    resp = urllib.request.urlopen(req, timeout=300)\n",
        "    result = json.loads(resp.read().decode())\n",
        "    print(json.dumps(result, indent=2)[:3000])\n",
        "except Exception as e:\n",
        "    print(f\"Error: {e}\")\n",
        "    print(\"Tip: !tail -100 /tmp/orchestrator.log\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "16fe6036",
      "metadata": {
        "id": "16fe6036"
      },
      "outputs": [],
      "source": [
        "# â”€â”€ View service logs â”€â”€\n",
        "# Change SERVICE to: orchestrator, memory_service, subagent_manager,\n",
        "#                     mcp_gateway, code_exec, ollama, chroma, minio, dashboard\n",
        "SERVICE = \"orchestrator\"\n",
        "LINES = 50\n",
        "\n",
        "import subprocess\n",
        "print(f\"Last {LINES} lines of {SERVICE}:\")\n",
        "print(\"=\" * 60)\n",
        "subprocess.run([\"tail\", f\"-{LINES}\", f\"/tmp/{SERVICE}.log\"], capture_output=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "41e3d312",
      "metadata": {
        "id": "41e3d312"
      },
      "outputs": [],
      "source": [
        "# â”€â”€ System resource monitor â”€â”€\n",
        "import subprocess, psutil, shutil\n",
        "\n",
        "print(\"GPU:\")\n",
        "subprocess.run(\"nvidia-smi\", shell=True)\n",
        "\n",
        "mem = psutil.virtual_memory()\n",
        "print(f\"\\nRAM: {mem.used/1024**3:.1f}/{mem.total/1024**3:.1f} GB ({mem.percent}%)\")\n",
        "\n",
        "disk = shutil.disk_usage(\"/\")\n",
        "print(f\"Disk: {(disk.total-disk.free)/1024**3:.1f}/{disk.total/1024**3:.1f} GB\")\n",
        "\n",
        "print(\"\\nRunning services:\")\n",
        "for proc in psutil.process_iter(['pid', 'name', 'cmdline']):\n",
        "    try:\n",
        "        cmd = \" \".join(proc.info.get('cmdline', []))\n",
        "        if 'uvicorn' in cmd or 'ollama' in proc.info.get('name', '').lower():\n",
        "            print(f\"  PID {proc.info['pid']}: {cmd[:80]}\")\n",
        "    except:\n",
        "        pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9c48e5cd",
      "metadata": {
        "id": "9c48e5cd"
      },
      "outputs": [],
      "source": [
        "# â”€â”€ Restart all services â”€â”€\n",
        "import psutil, time\n",
        "\n",
        "print(\"Stopping all services...\")\n",
        "for proc in psutil.process_iter(['pid', 'cmdline']):\n",
        "    try:\n",
        "        cmd = \" \".join(proc.info.get('cmdline', []))\n",
        "        if 'uvicorn' in cmd and 'service.main' in cmd:\n",
        "            proc.kill()\n",
        "            print(f\"  Killed PID {proc.info['pid']}\")\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "time.sleep(3)\n",
        "print(\"Done. Re-run Phase 4 cell to restart services.\")"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}