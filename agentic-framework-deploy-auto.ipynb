{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ac75aa0",
   "metadata": {},
   "source": [
    "# Agentic Framework - One-Click Colab Deployment\n",
    "**Run this single cell to deploy the entire multi-agent framework on Google Colab with GPU.**\n",
    "\n",
    "Services deployed: Orchestrator (8000), Memory Service (8002), SubAgent Manager (8003), Code Executor (8004), MCP Gateway (8080), ChromaDB (8001), Ollama+DeepSeek (11434), PostgreSQL (5432), Redis (6379), MinIO (9000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "385ff695",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################\n",
    "# \ud83d\ude80 ONE-CLICK AGENTIC FRAMEWORK DEPLOYMENT FOR GOOGLE COLAB\n",
    "# Run this single cell to deploy everything.\n",
    "##############################################################\n",
    "import subprocess, os, sys, time, json, urllib.request\n",
    "\n",
    "REPO_URL = \"https://github.com/landonking-gif/ai_final.git\"\n",
    "INSTALL_DIR = \"/content/ai_final\"\n",
    "FRAMEWORK_DIR = f\"{INSTALL_DIR}/agentic-framework-main\"\n",
    "\n",
    "def run_cmd(cmd, desc=\"\", shell=True):\n",
    "    \"\"\"Run a shell command with status output.\"\"\"\n",
    "    if desc:\n",
    "        print(f\"  {desc}...\", end=\" \", flush=True)\n",
    "    result = subprocess.run(cmd, shell=shell, capture_output=True, text=True)\n",
    "    if desc:\n",
    "        print(\"[OK]\" if result.returncode == 0 else f\"[WARN] {result.stderr[:200]}\")\n",
    "    return result\n",
    "\n",
    "def wait_for_port(port, timeout=30):\n",
    "    \"\"\"Wait for a service to start listening on a port.\"\"\"\n",
    "    import socket\n",
    "    start = time.time()\n",
    "    while time.time() - start < timeout:\n",
    "        try:\n",
    "            s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "            s.settimeout(1)\n",
    "            s.connect((\"localhost\", port))\n",
    "            s.close()\n",
    "            return True\n",
    "        except (ConnectionRefusedError, socket.timeout, OSError):\n",
    "            time.sleep(1)\n",
    "    return False\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"\ud83d\ude80 AGENTIC FRAMEWORK - FULL DEPLOYMENT\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# ============================================================\n",
    "# PHASE 1: GPU & System Check\n",
    "# ============================================================\n",
    "print(\"\\n\ud83d\udccb PHASE 1: System Check\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "gpu_check = subprocess.run(\n",
    "    [\"nvidia-smi\", \"--query-gpu=name,memory.total,driver_version\", \"--format=csv,noheader\"],\n",
    "    capture_output=True, text=True\n",
    ")\n",
    "if gpu_check.returncode == 0:\n",
    "    print(f\"  [OK] GPU: {gpu_check.stdout.strip()}\")\n",
    "else:\n",
    "    print(\"  [WARN] No GPU detected - LLM inference will be slow on CPU\")\n",
    "\n",
    "import shutil\n",
    "disk = shutil.disk_usage(\"/\")\n",
    "print(f\"  [OK] Disk: {disk.free / (1024**3):.1f} GB free\")\n",
    "print(f\"  [OK] Python: {sys.version.split()[0]}\")\n",
    "\n",
    "# ============================================================\n",
    "# PHASE 2: Install System Dependencies\n",
    "# ============================================================\n",
    "print(\"\\n\ud83d\udce6 PHASE 2: System Dependencies\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "run_cmd(\"apt-get update -qq\", \"Updating apt\")\n",
    "run_cmd(\"apt-get install -y -qq postgresql postgresql-client redis-server build-essential libpq-dev > /dev/null 2>&1\", \"PostgreSQL + Redis + build tools\")\n",
    "run_cmd(\"curl -fsSL https://deb.nodesource.com/setup_22.x | bash - > /dev/null 2>&1 && apt-get install -y -qq nodejs > /dev/null 2>&1\", \"Node.js 22\")\n",
    "run_cmd(\"wget -q https://dl.min.io/server/minio/release/linux-amd64/minio -O /usr/local/bin/minio && chmod +x /usr/local/bin/minio\", \"MinIO\")\n",
    "\n",
    "# ============================================================\n",
    "# PHASE 3: Install Ollama + Pull Model\n",
    "# ============================================================\n",
    "print(\"\\n\\U0001f916 PHASE 3: Ollama + DeepSeek R1\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Install Ollama - use bash explicitly (install script uses bash features)\n",
    "run_cmd(\"curl -fsSL https://ollama.com/install.sh | bash\", \"Installing Ollama\")\n",
    "\n",
    "# Find the Ollama binary - check common locations\n",
    "OLLAMA_BIN = None\n",
    "for path in [\"/usr/local/bin/ollama\", \"/usr/bin/ollama\", shutil.which(\"ollama\") or \"\"]:\n",
    "    if path and os.path.isfile(path):\n",
    "        OLLAMA_BIN = path\n",
    "        break\n",
    "\n",
    "if OLLAMA_BIN is None:\n",
    "    # Try alternative install method\n",
    "    print(\"  [WARN] Ollama binary not found, trying direct download...\")\n",
    "    run_cmd(\"curl -L https://ollama.com/download/ollama-linux-amd64 -o /usr/local/bin/ollama && chmod +x /usr/local/bin/ollama\", \"Direct download\")\n",
    "    if os.path.isfile(\"/usr/local/bin/ollama\"):\n",
    "        OLLAMA_BIN = \"/usr/local/bin/ollama\"\n",
    "    else:\n",
    "        print(\"  [ERROR] Could not install Ollama. Check network connectivity.\")\n",
    "        OLLAMA_BIN = \"ollama\"  # fallback\n",
    "\n",
    "print(f\"  [OK] Ollama binary: {OLLAMA_BIN}\")\n",
    "\n",
    "os.environ[\"OLLAMA_HOST\"] = \"0.0.0.0:11434\"\n",
    "subprocess.Popen(\n",
    "    [OLLAMA_BIN, \"serve\"],\n",
    "    stdout=open(\"/tmp/ollama.log\", \"w\"),\n",
    "    stderr=subprocess.STDOUT,\n",
    "    env={**os.environ, \"OLLAMA_HOST\": \"0.0.0.0:11434\"}\n",
    ")\n",
    "\n",
    "# Wait for Ollama to be ready\n",
    "print(\"  Waiting for Ollama server...\", end=\" \", flush=True)\n",
    "if wait_for_port(11434, timeout=15):\n",
    "    print(\"[OK]\")\n",
    "else:\n",
    "    print(\"[WARN] Port 11434 not responding yet, continuing...\")\n",
    "    time.sleep(5)\n",
    "\n",
    "print(\"  Pulling deepseek-r1:14b (may take 2-5 min)...\")\n",
    "subprocess.run([OLLAMA_BIN, \"pull\", \"deepseek-r1:14b\"], capture_output=False, text=True)\n",
    "print(\"  Pulling llama3.2:3b fallback...\")\n",
    "subprocess.run([OLLAMA_BIN, \"pull\", \"llama3.2:3b\"], capture_output=False, text=True)\n",
    "print(\"  [OK] Models downloaded\")\n",
    "\n",
    "# ============================================================\n",
    "# PHASE 4: Clone Repository & Install Python Dependencies\n",
    "# ============================================================\n",
    "print(\"\\n\ud83d\udd04 PHASE 4: Clone Repo & Install Dependencies\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "if os.path.exists(INSTALL_DIR):\n",
    "    print(\"  Repo exists, pulling latest...\")\n",
    "    subprocess.run([\"git\", \"-C\", INSTALL_DIR, \"pull\"], capture_output=True, text=True)\n",
    "else:\n",
    "    print(f\"  Cloning {REPO_URL}...\")\n",
    "    subprocess.run([\"git\", \"clone\", REPO_URL, INSTALL_DIR], capture_output=False, text=True)\n",
    "\n",
    "os.chdir(FRAMEWORK_DIR)\n",
    "\n",
    "# Create symlinks: hyphenated directories -> underscored Python packages\n",
    "symlinks = {\n",
    "    \"memory_service\": \"memory-service\",\n",
    "    \"subagent_manager\": \"subagent-manager\",\n",
    "    \"mcp_gateway\": \"mcp-gateway\",\n",
    "    \"code_exec\": \"code-exec\",\n",
    "}\n",
    "for link_name, target in symlinks.items():\n",
    "    if not os.path.exists(link_name) and os.path.exists(target):\n",
    "        os.symlink(target, link_name)\n",
    "        print(f\"  Symlink: {link_name} -> {target}\")\n",
    "\n",
    "# Install Python packages\n",
    "print(\"  Installing Python packages (2-3 min)...\")\n",
    "subprocess.run(\n",
    "    [sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"-r\", f\"{FRAMEWORK_DIR}/requirements.txt\"],\n",
    "    capture_output=True, text=True\n",
    ")\n",
    "subprocess.run(\n",
    "    [sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"pyngrok\", \"asyncpg\", \"aiofiles\", \"chromadb\"],\n",
    "    capture_output=True, text=True\n",
    ")\n",
    "print(\"  [OK] Dependencies installed\")\n",
    "\n",
    "# Set PYTHONPATH\n",
    "if FRAMEWORK_DIR not in sys.path:\n",
    "    sys.path.insert(0, FRAMEWORK_DIR)\n",
    "os.environ[\"PYTHONPATH\"] = FRAMEWORK_DIR\n",
    "\n",
    "# ============================================================\n",
    "# PHASE 5: Start Infrastructure Services\n",
    "# ============================================================\n",
    "print(\"\\n\u26a1 PHASE 5: Infrastructure Services\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# PostgreSQL\n",
    "run_cmd(\"service postgresql start\", \"Starting PostgreSQL\")\n",
    "time.sleep(2)\n",
    "pg_cmds = [\n",
    "    \"CREATE USER agent_user WITH PASSWORD 'agent_pass' CREATEDB;\",\n",
    "    \"CREATE DATABASE agentic_framework OWNER agent_user;\",\n",
    "    \"GRANT ALL PRIVILEGES ON DATABASE agentic_framework TO agent_user;\",\n",
    "]\n",
    "for cmd in pg_cmds:\n",
    "    subprocess.run([\"sudo\", \"-u\", \"postgres\", \"psql\", \"-c\", cmd], capture_output=True, text=True)\n",
    "print(\"  [OK] PostgreSQL ready (agent_user/agent_pass)\")\n",
    "\n",
    "# Redis\n",
    "run_cmd(\"redis-server --daemonize yes --port 6379\", \"Starting Redis\")\n",
    "time.sleep(1)\n",
    "redis_check = subprocess.run(\"redis-cli ping\", shell=True, capture_output=True, text=True)\n",
    "print(f\"  [OK] Redis: {'PONG' if 'PONG' in redis_check.stdout else 'STARTING'}\")\n",
    "\n",
    "# ChromaDB\n",
    "os.makedirs(\"/tmp/chroma_data\", exist_ok=True)\n",
    "subprocess.Popen(\n",
    "    [sys.executable, \"-m\", \"chromadb.cli.cli\", \"run\", \"--host\", \"0.0.0.0\", \"--port\", \"8001\", \"--path\", \"/tmp/chroma_data\"],\n",
    "    stdout=open(\"/tmp/chroma.log\", \"w\"),\n",
    "    stderr=subprocess.STDOUT\n",
    ")\n",
    "time.sleep(3)\n",
    "print(\"  [OK] ChromaDB started on port 8001\")\n",
    "\n",
    "# MinIO\n",
    "os.makedirs(\"/tmp/minio_data\", exist_ok=True)\n",
    "subprocess.Popen(\n",
    "    [\"/usr/local/bin/minio\", \"server\", \"/tmp/minio_data\", \"--address\", \":9000\", \"--console-address\", \":9001\"],\n",
    "    stdout=open(\"/tmp/minio.log\", \"w\"),\n",
    "    stderr=subprocess.STDOUT,\n",
    "    env={**os.environ, \"MINIO_ROOT_USER\": \"minioadmin\", \"MINIO_ROOT_PASSWORD\": \"minioadmin\"}\n",
    ")\n",
    "time.sleep(2)\n",
    "print(\"  [OK] MinIO started on port 9000\")\n",
    "\n",
    "# ============================================================\n",
    "# PHASE 6: Configure Environment & Start Framework Services\n",
    "# ============================================================\n",
    "print(\"\\n\ud83d\udd27 PHASE 6: Framework Services\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Environment variables\n",
    "env_vars = {\n",
    "    \"POSTGRES_URL\": \"postgresql://agent_user:agent_pass@localhost:5432/agentic_framework\",\n",
    "    \"REDIS_URL\": \"redis://localhost:6379/0\",\n",
    "    \"MCP_GATEWAY_URL\": \"http://localhost:8080\",\n",
    "    \"MEMORY_SERVICE_URL\": \"http://localhost:8002\",\n",
    "    \"SUBAGENT_MANAGER_URL\": \"http://localhost:8003\",\n",
    "    \"CODE_EXECUTOR_URL\": \"http://localhost:8004\",\n",
    "    \"OLLAMA_ENDPOINT\": \"http://localhost:11434\",\n",
    "    \"OLLAMA_BASE_URL\": \"http://localhost:11434\",\n",
    "    \"LOCAL_MODEL\": \"deepseek-r1:14b\",\n",
    "    \"FALLBACK_MODEL\": \"llama3.2:3b\",\n",
    "    \"DEFAULT_LLM_PROVIDER\": \"ollama\",\n",
    "    \"LLM_PROVIDER\": \"ollama\",\n",
    "    \"USE_OPENCLAW\": \"false\",\n",
    "    \"CHROMA_URL\": \"http://localhost:8001\",\n",
    "    \"MINIO_ENDPOINT\": \"localhost:9000\",\n",
    "    \"MINIO_ACCESS_KEY\": \"minioadmin\",\n",
    "    \"MINIO_SECRET_KEY\": \"minioadmin\",\n",
    "    \"JWT_SECRET_KEY\": \"colab-dev-secret-key-change-in-production\",\n",
    "    \"ENVIRONMENT\": \"development\",\n",
    "    \"PYTHONPATH\": FRAMEWORK_DIR,\n",
    "    \"WORKSPACE_ROOT\": f\"{FRAMEWORK_DIR}/workspace\",\n",
    "    \"WEBSOCKET_ENABLED\": \"true\",\n",
    "    \"CODE_EXEC_SKILLS_DIRECTORY\": f\"{FRAMEWORK_DIR}/code-exec/skills\",\n",
    "}\n",
    "for key, value in env_vars.items():\n",
    "    os.environ[key] = value\n",
    "\n",
    "# Write .env file\n",
    "with open(f\"{FRAMEWORK_DIR}/.env\", \"w\") as f:\n",
    "    for key, value in env_vars.items():\n",
    "        f.write(f\"{key}={value}\\n\")\n",
    "\n",
    "# Create workspace directories\n",
    "os.makedirs(f\"{FRAMEWORK_DIR}/workspace/.copilot/memory/diary\", exist_ok=True)\n",
    "os.makedirs(f\"{FRAMEWORK_DIR}/workspace/.copilot/memory/reflections\", exist_ok=True)\n",
    "os.makedirs(f\"{FRAMEWORK_DIR}/workspace/ralph-work\", exist_ok=True)\n",
    "\n",
    "service_env = {**os.environ}\n",
    "\n",
    "# Start services in dependency order (foundational first)\n",
    "services = [\n",
    "    {\n",
    "        \"name\": \"Code Executor\",\n",
    "        \"cmd\": [sys.executable, \"-m\", \"uvicorn\", \"code_exec.service.main:app\", \"--host\", \"0.0.0.0\", \"--port\", \"8004\"],\n",
    "        \"port\": 8004,\n",
    "        \"log\": \"/tmp/code_exec.log\",\n",
    "        \"env_extra\": {\"REDIS_URL\": \"redis://localhost:6379/4\"},\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Memory Service\",\n",
    "        \"cmd\": [sys.executable, \"-m\", \"uvicorn\", \"memory_service.service.main:app\", \"--host\", \"0.0.0.0\", \"--port\", \"8002\"],\n",
    "        \"port\": 8002,\n",
    "        \"log\": \"/tmp/memory_service.log\",\n",
    "        \"env_extra\": {\"REDIS_URL\": \"redis://localhost:6379/2\"},\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"SubAgent Manager\",\n",
    "        \"cmd\": [sys.executable, \"-m\", \"uvicorn\", \"subagent_manager.service.main:app\", \"--host\", \"0.0.0.0\", \"--port\", \"8003\"],\n",
    "        \"port\": 8003,\n",
    "        \"log\": \"/tmp/subagent_manager.log\",\n",
    "        \"env_extra\": {\n",
    "            \"REDIS_URL\": \"redis://localhost:6379/1\",\n",
    "            \"SUBAGENT_USE_OPENCLAW\": \"false\",\n",
    "            \"SUBAGENT_LLM_PROVIDER\": \"ollama\",\n",
    "            \"SUBAGENT_LLM_MODEL\": \"deepseek-r1:14b\",\n",
    "            \"SUBAGENT_OLLAMA_ENDPOINT\": \"http://localhost:11434\",\n",
    "            \"SUBAGENT_PORT\": \"8003\",\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"MCP Gateway\",\n",
    "        \"cmd\": [sys.executable, \"-m\", \"uvicorn\", \"mcp_gateway.service.main:app\", \"--host\", \"0.0.0.0\", \"--port\", \"8080\"],\n",
    "        \"port\": 8080,\n",
    "        \"log\": \"/tmp/mcp_gateway.log\",\n",
    "        \"env_extra\": {\"REDIS_URL\": \"redis://localhost:6379/3\"},\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Orchestrator\",\n",
    "        \"cmd\": [sys.executable, \"-m\", \"uvicorn\", \"orchestrator.service.main:app\", \"--host\", \"0.0.0.0\", \"--port\", \"8000\"],\n",
    "        \"port\": 8000,\n",
    "        \"log\": \"/tmp/orchestrator.log\",\n",
    "        \"env_extra\": {},\n",
    "    },\n",
    "]\n",
    "\n",
    "for svc in services:\n",
    "    print(f\"  Starting {svc['name']} (port {svc['port']})...\", end=\" \", flush=True)\n",
    "    svc_env = {**service_env, **svc.get(\"env_extra\", {})}\n",
    "    proc = subprocess.Popen(\n",
    "        svc[\"cmd\"],\n",
    "        cwd=FRAMEWORK_DIR,\n",
    "        stdout=open(svc[\"log\"], \"w\"),\n",
    "        stderr=subprocess.STDOUT,\n",
    "        env=svc_env\n",
    "    )\n",
    "    time.sleep(3)\n",
    "    print(f\"[OK] PID {proc.pid}\")\n",
    "\n",
    "# Wait for services to initialize\n",
    "print(\"\\n  Waiting for services to initialize (20s)...\")\n",
    "time.sleep(20)\n",
    "\n",
    "# ============================================================\n",
    "# PHASE 7: Health Checks\n",
    "# ============================================================\n",
    "print(\"\\n\u2705 PHASE 7: Health Checks\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "health_endpoints = [\n",
    "    (\"Orchestrator\",     8000, \"http://localhost:8000/health\"),\n",
    "    (\"Memory Service\",   8002, \"http://localhost:8002/health\"),\n",
    "    (\"SubAgent Manager\", 8003, \"http://localhost:8003/health\"),\n",
    "    (\"MCP Gateway\",      8080, \"http://localhost:8080/health\"),\n",
    "    (\"Code Executor\",    8004, \"http://localhost:8004/health\"),\n",
    "    (\"Ollama\",           11434, \"http://localhost:11434/api/tags\"),\n",
    "    (\"ChromaDB\",         8001, \"http://localhost:8001/api/v1/heartbeat\"),\n",
    "]\n",
    "\n",
    "all_ok = True\n",
    "for name, port, url in health_endpoints:\n",
    "    try:\n",
    "        req = urllib.request.urlopen(url, timeout=5)\n",
    "        status = req.getcode()\n",
    "        print(f\"  {name:20s} : \u2705 OK ({status})\")\n",
    "    except Exception as e:\n",
    "        all_ok = False\n",
    "        err_msg = str(e)[:50]\n",
    "        print(f\"  {name:20s} : \u23f3 Starting... ({err_msg})\")\n",
    "        print(f\"    -> Log: tail -50 /tmp/{name.lower().replace(' ', '_')}.log\")\n",
    "\n",
    "# ============================================================\n",
    "# PHASE 8: Set up ngrok (optional external access)\n",
    "# ============================================================\n",
    "print(\"\\n\ud83c\udf10 PHASE 8: External Access (ngrok)\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "try:\n",
    "    from pyngrok import ngrok\n",
    "    api_tunnel = ngrok.connect(8000, \"http\")\n",
    "    api_url = api_tunnel.public_url\n",
    "    os.environ[\"COLAB_API_URL\"] = api_url\n",
    "    print(f\"  API URL:  {api_url}\")\n",
    "    print(f\"  API Docs: {api_url}/docs\")\n",
    "    print(f\"  Health:   {api_url}/health\")\n",
    "except Exception as e:\n",
    "    api_url = \"http://localhost:8000\"\n",
    "    print(f\"  [INFO] ngrok not available ({str(e)[:60]})\")\n",
    "    print(f\"  Set NGROK_AUTH_TOKEN for external access\")\n",
    "\n",
    "# ============================================================\n",
    "# FINAL SUMMARY\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "if all_ok:\n",
    "    print(\"\ud83c\udf89 DEPLOYMENT COMPLETE - ALL SERVICES RUNNING!\")\n",
    "else:\n",
    "    print(\"\ud83c\udf89 DEPLOYMENT COMPLETE - Some services still starting\")\n",
    "    print(\"   Re-check in 30s or view logs with: !tail -50 /tmp/<service>.log\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\"\"\n",
    "\ud83d\udce1 Service Endpoints:\n",
    "  Orchestrator:     http://localhost:8000  (main API)\n",
    "  Memory Service:   http://localhost:8002\n",
    "  SubAgent Manager: http://localhost:8003\n",
    "  Code Executor:    http://localhost:8004\n",
    "  MCP Gateway:      http://localhost:8080\n",
    "  Ollama (GPU LLM): http://localhost:11434\n",
    "  ChromaDB:         http://localhost:8001\n",
    "  PostgreSQL:       localhost:5432\n",
    "  Redis:            localhost:6379\n",
    "  MinIO:            localhost:9000\n",
    "\n",
    "\ud83e\uddea Quick Test:\n",
    "  curl http://localhost:8000/health\n",
    "  curl http://localhost:8000/docs\n",
    "\"\"\")\n",
    "print(\"=\" * 60)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}