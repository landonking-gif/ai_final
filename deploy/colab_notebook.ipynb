{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "name": "Agentic Framework - Deploy"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Agentic Framework - One-Click Colab Deployment\n",
        "\n",
        "**Prerequisites:** GPU runtime required (Runtime -> Change runtime type -> **T4 GPU**)\n",
        "\n",
        "| Step | Cell | What it does |\n",
        "|------|------|--------------|\n",
        "| 1 | **Deploy** | Clones repo, installs everything, starts all services, creates ngrok tunnels |\n",
        "| 2 | **Diagnostics** | On-demand health check of all services |\n",
        "| 3 | **Recovery** | Restart individual crashed services |\n",
        "| 4 | **Logs** | View service logs for debugging |\n",
        "\n",
        "**Just click Runtime -> Run all** and wait ~5 minutes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "deploy_cell"
      },
      "source": [
        "# ============================================================\n",
        "# CELL 1: FULL DEPLOYMENT (Run this - everything is automated)\n",
        "# ============================================================\n",
        "# This cell clones the repo, installs all dependencies, starts\n",
        "# all 5 microservices + Ollama + Dashboard, and creates ngrok\n",
        "# tunnels for external access. Takes ~5 minutes on a T4 GPU.\n",
        "#\n",
        "# After completion, the watchdog loop keeps services alive.\n",
        "# Your public URLs will be printed at the end.\n",
        "# ============================================================\n",
        "\n",
        "import os, subprocess, sys\n",
        "\n",
        "REPO_URL = \"https://github.com/landonking-gif/ai_final.git\"\n",
        "INSTALL_DIR = \"/content/ai_final\"\n",
        "\n",
        "# Clone or update repo\n",
        "if os.path.exists(INSTALL_DIR):\n",
        "    print(\"Repo exists - pulling latest...\")\n",
        "    subprocess.run([\"git\", \"-C\", INSTALL_DIR, \"pull\"], capture_output=False)\n",
        "else:\n",
        "    print(f\"Cloning {REPO_URL}...\")\n",
        "    subprocess.run([\"git\", \"clone\", REPO_URL, INSTALL_DIR], capture_output=False)\n",
        "\n",
        "# Add deploy/ to Python path so we can import from it later\n",
        "deploy_dir = f\"{INSTALL_DIR}/deploy\"\n",
        "if deploy_dir not in sys.path:\n",
        "    sys.path.insert(0, deploy_dir)\n",
        "\n",
        "# Run the deployment script\n",
        "os.chdir(deploy_dir)\n",
        "print(f\"\\nStarting deployment from {deploy_dir}...\\n\")\n",
        "!python colab_deploy.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "diagnostics_cell"
      },
      "source": [
        "# ============================================================\n",
        "# CELL 2: DIAGNOSTICS - Run anytime to check system health\n",
        "# ============================================================\n",
        "\n",
        "import sys\n",
        "if \"/content/ai_final/deploy\" not in sys.path:\n",
        "    sys.path.insert(0, \"/content/ai_final/deploy\")\n",
        "\n",
        "from colab_deploy import diagnose\n",
        "diagnose()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "recovery_cell"
      },
      "source": [
        "# ============================================================\n",
        "# CELL 3: RECOVERY - Restart a specific crashed service\n",
        "# ============================================================\n",
        "# Valid service keys:\n",
        "#   code_exec, memory_service, subagent_manager,\n",
        "#   mcp_gateway, orchestrator, ollama\n",
        "#\n",
        "# Uncomment the service you want to restart:\n",
        "\n",
        "import sys\n",
        "if \"/content/ai_final/deploy\" not in sys.path:\n",
        "    sys.path.insert(0, \"/content/ai_final/deploy\")\n",
        "\n",
        "from colab_deploy import recover_service\n",
        "\n",
        "# recover_service(\"orchestrator\")\n",
        "# recover_service(\"memory_service\")\n",
        "# recover_service(\"subagent_manager\")\n",
        "# recover_service(\"mcp_gateway\")\n",
        "# recover_service(\"code_exec\")\n",
        "# recover_service(\"ollama\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "logs_cell"
      },
      "source": [
        "# ============================================================\n",
        "# CELL 4: LOGS - View service logs for debugging\n",
        "# ============================================================\n",
        "# Usage:\n",
        "#   show_logs()                      -> master deployment log\n",
        "#   show_logs(\"orchestrator\")        -> specific service\n",
        "#   show_logs(\"orchestrator\", 100)   -> last 100 lines\n",
        "#\n",
        "# Valid keys: orchestrator, memory_service, subagent_manager,\n",
        "#   mcp_gateway, code_exec, ollama, chromadb, minio, dashboard\n",
        "\n",
        "import sys\n",
        "if \"/content/ai_final/deploy\" not in sys.path:\n",
        "    sys.path.insert(0, \"/content/ai_final/deploy\")\n",
        "\n",
        "from colab_deploy import show_logs\n",
        "\n",
        "# show_logs()                     # master log\n",
        "show_logs(\"orchestrator\", 50)     # orchestrator last 50 lines"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}